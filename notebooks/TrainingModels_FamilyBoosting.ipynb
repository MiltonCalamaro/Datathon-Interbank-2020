{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "material-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cognitive-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data'\n",
    "y_train = pd.read_csv(f'{path}/y_train.csv', index_col = 'key_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floppy-needle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind='pie', autopct='%1.0f%%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaningful-ozone",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1136), (396666, 1136))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "precise-chess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    1048\n",
       "int32        65\n",
       "int64        23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serious-yukon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.isna().sum().hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-wilderness",
   "metadata": {},
   "source": [
    "## Entrenando LGBM con hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "enhanced-attention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.856936\ttraining's binary_logloss: 0.292239\tvalid_1's auc: 0.84233\tvalid_1's binary_logloss: 0.303186\n",
      "[200]\ttraining's auc: 0.872172\ttraining's binary_logloss: 0.280473\tvalid_1's auc: 0.846739\tvalid_1's binary_logloss: 0.299657\n",
      "[300]\ttraining's auc: 0.882948\ttraining's binary_logloss: 0.271993\tvalid_1's auc: 0.847878\tvalid_1's binary_logloss: 0.298809\n",
      "Early stopping, best iteration is:\n",
      "[327]\ttraining's auc: 0.885625\ttraining's binary_logloss: 0.269881\tvalid_1's auc: 0.848044\tvalid_1's binary_logloss: 0.29871\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.856927\ttraining's binary_logloss: 0.292188\tvalid_1's auc: 0.841971\tvalid_1's binary_logloss: 0.303186\n",
      "[200]\ttraining's auc: 0.871942\ttraining's binary_logloss: 0.280424\tvalid_1's auc: 0.84622\tvalid_1's binary_logloss: 0.2999\n",
      "[300]\ttraining's auc: 0.882858\ttraining's binary_logloss: 0.271844\tvalid_1's auc: 0.84757\tvalid_1's binary_logloss: 0.298947\n",
      "Early stopping, best iteration is:\n",
      "[310]\ttraining's auc: 0.883729\ttraining's binary_logloss: 0.271099\tvalid_1's auc: 0.847702\tvalid_1's binary_logloss: 0.29885\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.85673\ttraining's binary_logloss: 0.292579\tvalid_1's auc: 0.844846\tvalid_1's binary_logloss: 0.300634\n",
      "[200]\ttraining's auc: 0.872067\ttraining's binary_logloss: 0.280914\tvalid_1's auc: 0.847835\tvalid_1's binary_logloss: 0.297685\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's auc: 0.874296\ttraining's binary_logloss: 0.279211\tvalid_1's auc: 0.848116\tvalid_1's binary_logloss: 0.29745\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.857096\ttraining's binary_logloss: 0.292583\tvalid_1's auc: 0.843642\tvalid_1's binary_logloss: 0.301419\n",
      "[200]\ttraining's auc: 0.872333\ttraining's binary_logloss: 0.280815\tvalid_1's auc: 0.847071\tvalid_1's binary_logloss: 0.298287\n",
      "Early stopping, best iteration is:\n",
      "[245]\ttraining's auc: 0.877526\ttraining's binary_logloss: 0.276769\tvalid_1's auc: 0.847589\tvalid_1's binary_logloss: 0.297824\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.85858\ttraining's binary_logloss: 0.291779\tvalid_1's auc: 0.836514\tvalid_1's binary_logloss: 0.303797\n",
      "[200]\ttraining's auc: 0.873879\ttraining's binary_logloss: 0.27987\tvalid_1's auc: 0.84024\tvalid_1's binary_logloss: 0.300924\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's auc: 0.875898\ttraining's binary_logloss: 0.278344\tvalid_1's auc: 0.840485\tvalid_1's binary_logloss: 0.300718\n",
      "*********************\n",
      "roc auc estimado:  0.8464020583544389\n",
      "roc auc varianza:  0.0007231250807578067\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = LGBMClassifier(n_estimators=1000, boosting_type='gbdt',min_child_samples=1500, colsample_bytree=0.8,\n",
    "                   subsample=0.8, max_bin=200, learning_rate=0.1)\n",
    "    \n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sixth-detection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIESGO_DIRECTO_1_saldoUnique_ult1meses               0.012606\n",
       "cod_instit_financiera_max_ult1mes                    0.011581\n",
       "edad                                                 0.010365\n",
       "RIESGO_DIRECTO_1_saldoStd_ult1meses                  0.008857\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.008844\n",
       "ubigeo_mode                                          0.008489\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult12meses             0.008307\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.008029\n",
       "cod_instit_financiera_mode_ult1mes                   0.006738\n",
       "RIESGO_DIRECTO_1_saldoMin_ult1meses                  0.006509\n",
       "cod_instit_financiera_min_ult1mes                    0.006308\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.006118\n",
       "tipo_credito_11_saldoStd_ult1meses                   0.005895\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult1meses               0.005428\n",
       "sexo_0                                               0.005401\n",
       "condicion_0_saldoUnique_ult12meses                   0.005325\n",
       "ciiu_mode                                            0.005200\n",
       "tipo_credito_11_saldoUnique_ult12meses               0.005105\n",
       "RIESGO_DIRECTO_1_saldoMax_ult12meses                 0.004962\n",
       "estadocontribuyente_0                                0.004902\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult3meses               0.004757\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult2meses               0.004525\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult12meses              0.004488\n",
       "tipo_credito_11_saldoMin_ult1meses                   0.004330\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.004328\n",
       "tipo_credito_12_saldoMin_ult1meses                   0.004244\n",
       "tipo_credito_12_saldoUnique_ult12meses               0.004198\n",
       "RIESGO_DIRECTO_1_saldoMax_ult1meses                  0.004181\n",
       "tipo_credito_12_saldoSum_ult1meses                   0.004103\n",
       "RIESGO_DIRECTO_1_saldoMin_ult2meses                  0.004100\n",
       "fecalta_min                                          0.004082\n",
       "RIESGO_DIRECTO_1_saldoStd_ult12meses                 0.003930\n",
       "RIESGO_DIRECTO_1_saldoMean_ult1meses                 0.003851\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult3meses              0.003778\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.003726\n",
       "RIESGO_DIRECTO_1_saldoStd_ult2meses                  0.003717\n",
       "RIESGO_DIRECTO_1_saldoMin_ult12meses                 0.003564\n",
       "fecalta_mean                                         0.003515\n",
       "tipo_credito_11_saldoSum_ult1meses                   0.003468\n",
       "cod_instit_financiera_mode_ult12mes                  0.003386\n",
       "cod_instit_financiera_max_ult12mes                   0.003336\n",
       "codzona_mode                                         0.003275\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult12meses              0.003255\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult2meses               0.003243\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult12meses                0.003188\n",
       "tipo_credito_12_saldoUnique_ult1meses                0.003186\n",
       "RIESGO_DIRECTO_1_saldoMin_ult3meses                  0.003091\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMin_ult1meses        0.003048\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult2meses                 0.003034\n",
       "tipo_credito_12_saldoMedian_ult1meses                0.002995\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genetic-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exceptional-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_lightgbm = train_probs\n",
    "test_probs_lightgbm = test_probs\n",
    "train_probs_lightgbm.to_pickle('train_probs_lightgbm.pkl')\n",
    "test_probs_lightgbm.to_pickle('test_probs_lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-cycle",
   "metadata": {},
   "source": [
    "## Entrenando CatBoost con hiperparámetros\n",
    "### CatBoostClassifier(boosting_type = 'Plain', n_estimators=1000, eval_metric = 'AUC', colsample_bylevel=1, subsample=1, learning_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thermal-secondary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "0:\ttest: 0.7093593\ttest1: 0.7108453\tbest: 0.7108453 (0)\ttotal: 689ms\tremaining: 11m 28s\n",
      "100:\ttest: 0.8504688\ttest1: 0.8395184\tbest: 0.8396107 (98)\ttotal: 1m 10s\tremaining: 10m 24s\n",
      "200:\ttest: 0.8647001\ttest1: 0.8428050\tbest: 0.8428050 (200)\ttotal: 2m 19s\tremaining: 9m 16s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8431052276\n",
      "bestIteration = 212\n",
      "\n",
      "Shrink model to first 213 iterations.\n",
      "********** 1 **********\n",
      "0:\ttest: 0.7269500\ttest1: 0.7250728\tbest: 0.7250728 (0)\ttotal: 736ms\tremaining: 12m 15s\n",
      "100:\ttest: 0.8508043\ttest1: 0.8398558\tbest: 0.8399836 (97)\ttotal: 1m 18s\tremaining: 11m 43s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8420045373\n",
      "bestIteration = 146\n",
      "\n",
      "Shrink model to first 147 iterations.\n",
      "********** 2 **********\n",
      "0:\ttest: 0.7064753\ttest1: 0.7146973\tbest: 0.7146973 (0)\ttotal: 620ms\tremaining: 10m 19s\n",
      "100:\ttest: 0.8505039\ttest1: 0.8429398\tbest: 0.8429398 (100)\ttotal: 1m 15s\tremaining: 11m 16s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8448974512\n",
      "bestIteration = 146\n",
      "\n",
      "Shrink model to first 147 iterations.\n",
      "********** 3 **********\n",
      "0:\ttest: 0.7075185\ttest1: 0.7095663\tbest: 0.7095663 (0)\ttotal: 615ms\tremaining: 10m 14s\n",
      "100:\ttest: 0.8505363\ttest1: 0.8413386\tbest: 0.8414307 (94)\ttotal: 1m 18s\tremaining: 11m 42s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8433514985\n",
      "bestIteration = 168\n",
      "\n",
      "Shrink model to first 169 iterations.\n",
      "********** 4 **********\n",
      "0:\ttest: 0.7129356\ttest1: 0.6952613\tbest: 0.6952613 (0)\ttotal: 650ms\tremaining: 10m 49s\n",
      "100:\ttest: 0.8523021\ttest1: 0.8329464\tbest: 0.8329464 (100)\ttotal: 1m 18s\tremaining: 11m 34s\n",
      "200:\ttest: 0.8671920\ttest1: 0.8359630\tbest: 0.8360821 (193)\ttotal: 2m 31s\tremaining: 10m 2s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8360820546\n",
      "bestIteration = 193\n",
      "\n",
      "Shrink model to first 194 iterations.\n",
      "*********************\n",
      "roc auc estimado:  0.841912311266414\n",
      "roc auc varianza:  0.0007394122710751897\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index]\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index]\n",
    "\n",
    "    learner = CatBoostClassifier(boosting_type = 'Plain', n_estimators=1000, eval_metric = 'AUC',\n",
    "                   colsample_bylevel=1, subsample=1, learning_rate=0.3)\n",
    "    \n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, \n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "closing-heading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COD_CLASIFICACION_DEUDOR_5_saldoMin_ult1meses        0.186305\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoUnique_ult5meses     0.024312\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.020085\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult1meses               0.017645\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.017080\n",
       "RIESGO_DIRECTO_2_saldoSum_ult1meses                  0.014715\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoUnique_ult1meses     0.013940\n",
       "RIESGO_DIRECTO_-1_saldoMean_ult2meses                0.013577\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoUnique_ult2meses     0.013110\n",
       "edad                                                 0.012706\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.012445\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoMedian_ult4meses     0.011704\n",
       "cod_instit_financiera_mode_ult1mes                   0.009994\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.009545\n",
       "condicion_0_saldoUnique_ult12meses                   0.009164\n",
       "cod_instit_financiera_max_ult1mes                    0.008974\n",
       "sexo_0                                               0.008892\n",
       "cod_instit_financiera_max_ult4mes                    0.007785\n",
       "RIESGO_DIRECTO_1_saldoMin_ult1meses                  0.006830\n",
       "tipo_credito_11_saldoSum_ult12meses                  0.006678\n",
       "cod_instit_financiera_min_ult1mes                    0.006206\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult12meses             0.006015\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMax_ult1meses        0.005825\n",
       "PRODUCTO_max_ult1mes                                 0.005580\n",
       "PRODUCTO_min_ult9mes                                 0.005383\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoSum_ult1meses        0.005251\n",
       "cod_instit_financiera_nunique_ult1mes                0.005199\n",
       "condicion_0_saldoSum_ult1meses                       0.005151\n",
       "PRODUCTO_min_ult8mes                                 0.005135\n",
       "tipo_credito_11_saldoStd_ult1meses                   0.005058\n",
       "tipo_credito_12_saldoUnique_ult1meses                0.005036\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult11meses    0.004976\n",
       "ctd_veh                                              0.004831\n",
       "RIESGO_DIRECTO_1_saldoMax_ult12meses                 0.004790\n",
       "cod_instit_financiera_max_ult3mes                    0.004445\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.004274\n",
       "RIESGO_DIRECTO_1_saldoMean_ult1meses                 0.004247\n",
       "RIESGO_DIRECTO_2_saldoMax_ult4meses                  0.004184\n",
       "estadocontribuyente_0                                0.004126\n",
       "PRODUCTO_min_ult2mes                                 0.004077\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult12meses              0.004064\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoStd_ult2meses        0.003991\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult5meses              0.003974\n",
       "tipo_credito_11_saldoMean_ult2meses                  0.003970\n",
       "cod_instit_financiera_max_ult8mes                    0.003911\n",
       "condicion_1_saldoMean_ult1meses                      0.003830\n",
       "COD_CLASIFICACION_DEUDOR_4_saldoMin_ult1meses        0.003714\n",
       "RIESGO_DIRECTO_1_saldoMax_ult1meses                  0.003640\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult5meses        0.003637\n",
       "PRODUCTO_min_ult1mes                                 0.003543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pacific-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "representative-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_catboost = train_probs\n",
    "test_probs_catboost = test_probs\n",
    "train_probs_catboost.to_pickle('train_probs_catboost.pkl')\n",
    "test_probs_catboost.to_pickle('test_probs_catboost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-certificate",
   "metadata": {},
   "source": [
    "## Catboost con parametros casi estandares\n",
    "### CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "synthetic-lighter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1136), (396666, 1136))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "irish-gravity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7347704\ttest1: 0.7368052\tbest: 0.7368052 (0)\ttotal: 676ms\tremaining: 11m 15s\n",
      "100:\ttest: 0.8376572\ttest1: 0.8333426\tbest: 0.8333464 (99)\ttotal: 56.9s\tremaining: 8m 26s\n",
      "200:\ttest: 0.8495404\ttest1: 0.8404734\tbest: 0.8404734 (200)\ttotal: 1m 52s\tremaining: 7m 29s\n",
      "300:\ttest: 0.8575553\ttest1: 0.8432793\tbest: 0.8432793 (300)\ttotal: 2m 48s\tremaining: 6m 30s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8442065855\n",
      "bestIteration = 374\n",
      "\n",
      "Shrink model to first 375 iterations.\n",
      "********** 1 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7303746\ttest1: 0.7309521\tbest: 0.7309521 (0)\ttotal: 525ms\tremaining: 8m 44s\n",
      "100:\ttest: 0.8379339\ttest1: 0.8334550\tbest: 0.8334550 (100)\ttotal: 1m 2s\tremaining: 9m 12s\n",
      "200:\ttest: 0.8499308\ttest1: 0.8402348\tbest: 0.8402348 (200)\ttotal: 1m 48s\tremaining: 7m 11s\n",
      "300:\ttest: 0.8571040\ttest1: 0.8426885\tbest: 0.8426885 (300)\ttotal: 2m 33s\tremaining: 5m 57s\n",
      "400:\ttest: 0.8632856\ttest1: 0.8442506\tbest: 0.8442506 (400)\ttotal: 3m 19s\tremaining: 4m 58s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.844751766\n",
      "bestIteration = 451\n",
      "\n",
      "Shrink model to first 452 iterations.\n",
      "********** 2 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7433426\ttest1: 0.7503628\tbest: 0.7503628 (0)\ttotal: 677ms\tremaining: 11m 15s\n",
      "100:\ttest: 0.8368349\ttest1: 0.8358631\tbest: 0.8358631 (100)\ttotal: 51.4s\tremaining: 7m 37s\n",
      "200:\ttest: 0.8493576\ttest1: 0.8429917\tbest: 0.8429917 (200)\ttotal: 1m 41s\tremaining: 6m 45s\n",
      "300:\ttest: 0.8566884\ttest1: 0.8451583\tbest: 0.8451583 (300)\ttotal: 2m 32s\tremaining: 5m 54s\n",
      "400:\ttest: 0.8632351\ttest1: 0.8466394\tbest: 0.8466394 (400)\ttotal: 3m 25s\tremaining: 5m 6s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8472577634\n",
      "bestIteration = 456\n",
      "\n",
      "Shrink model to first 457 iterations.\n",
      "********** 3 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7439433\ttest1: 0.7471180\tbest: 0.7471180 (0)\ttotal: 801ms\tremaining: 13m 20s\n",
      "100:\ttest: 0.8368129\ttest1: 0.8344431\tbest: 0.8344431 (100)\ttotal: 1m 4s\tremaining: 9m 32s\n",
      "200:\ttest: 0.8491073\ttest1: 0.8410273\tbest: 0.8410273 (200)\ttotal: 2m 4s\tremaining: 8m 13s\n",
      "300:\ttest: 0.8567255\ttest1: 0.8439754\tbest: 0.8439754 (300)\ttotal: 3m 5s\tremaining: 7m 11s\n",
      "400:\ttest: 0.8628725\ttest1: 0.8454441\tbest: 0.8454441 (400)\ttotal: 4m 9s\tremaining: 6m 13s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8458306323\n",
      "bestIteration = 438\n",
      "\n",
      "Shrink model to first 439 iterations.\n",
      "********** 4 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7392816\ttest1: 0.7291512\tbest: 0.7291512 (0)\ttotal: 752ms\tremaining: 12m 30s\n",
      "100:\ttest: 0.8391224\ttest1: 0.8276477\tbest: 0.8276477 (100)\ttotal: 1m 2s\tremaining: 9m 16s\n",
      "200:\ttest: 0.8509937\ttest1: 0.8341774\tbest: 0.8341774 (200)\ttotal: 2m 3s\tremaining: 8m 9s\n",
      "300:\ttest: 0.8586089\ttest1: 0.8364315\tbest: 0.8364315 (300)\ttotal: 2m 57s\tremaining: 6m 52s\n",
      "400:\ttest: 0.8650510\ttest1: 0.8375037\tbest: 0.8375037 (400)\ttotal: 3m 57s\tremaining: 5m 54s\n",
      "500:\ttest: 0.8703538\ttest1: 0.8383347\tbest: 0.8383347 (500)\ttotal: 4m 54s\tremaining: 4m 52s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8388775451\n",
      "bestIteration = 566\n",
      "\n",
      "Shrink model to first 567 iterations.\n",
      "*********************\n",
      "roc auc estimado:  0.8442141070456262\n",
      "roc auc varianza:  0.0006978018667889711\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index]\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index]\n",
    "\n",
    "    learner = CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth=6)\n",
    "    \n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, \n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "missing-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_catboost_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "psychological-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_catboost = train_probs\n",
    "test_probs_catboost = test_probs\n",
    "train_probs_catboost.to_pickle('train_probs_catboost_v2.pkl')\n",
    "test_probs_catboost.to_pickle('test_probs_catboost_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-vertex",
   "metadata": {},
   "source": [
    "## LGBM con Categorical_Feature con hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hairy-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mode = [ i for i in train.columns if 'mode' in i ]\n",
    "for i in var_mode:\n",
    "    train[i] = train[i].astype('category')\n",
    "    test[i] = test[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "understanding-friendly",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\venv_datathon\\lib\\site-packages\\lightgbm\\basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\usuario\\anaconda3\\envs\\venv_datathon\\lib\\site-packages\\lightgbm\\basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.853018\ttraining's binary_logloss: 0.297856\tvalid_1's auc: 0.83479\tvalid_1's binary_logloss: 0.309108\n",
      "[100]\ttraining's auc: 0.86851\ttraining's binary_logloss: 0.284755\tvalid_1's auc: 0.841822\tvalid_1's binary_logloss: 0.303217\n",
      "[150]\ttraining's auc: 0.878911\ttraining's binary_logloss: 0.276473\tvalid_1's auc: 0.844192\tvalid_1's binary_logloss: 0.301272\n",
      "[200]\ttraining's auc: 0.887114\ttraining's binary_logloss: 0.269921\tvalid_1's auc: 0.84546\tvalid_1's binary_logloss: 0.300323\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's auc: 0.887114\ttraining's binary_logloss: 0.269921\tvalid_1's auc: 0.84546\tvalid_1's binary_logloss: 0.300323\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.853105\ttraining's binary_logloss: 0.297583\tvalid_1's auc: 0.83342\tvalid_1's binary_logloss: 0.309619\n",
      "[100]\ttraining's auc: 0.868977\ttraining's binary_logloss: 0.284423\tvalid_1's auc: 0.840708\tvalid_1's binary_logloss: 0.303684\n",
      "[150]\ttraining's auc: 0.879226\ttraining's binary_logloss: 0.276143\tvalid_1's auc: 0.842828\tvalid_1's binary_logloss: 0.302094\n",
      "[200]\ttraining's auc: 0.887353\ttraining's binary_logloss: 0.269529\tvalid_1's auc: 0.843784\tvalid_1's binary_logloss: 0.301376\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's auc: 0.888642\ttraining's binary_logloss: 0.268481\tvalid_1's auc: 0.843867\tvalid_1's binary_logloss: 0.301294\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852586\ttraining's binary_logloss: 0.298265\tvalid_1's auc: 0.837541\tvalid_1's binary_logloss: 0.306826\n",
      "[100]\ttraining's auc: 0.868712\ttraining's binary_logloss: 0.285091\tvalid_1's auc: 0.844201\tvalid_1's binary_logloss: 0.30097\n",
      "[150]\ttraining's auc: 0.878917\ttraining's binary_logloss: 0.27691\tvalid_1's auc: 0.846163\tvalid_1's binary_logloss: 0.299236\n",
      "[200]\ttraining's auc: 0.886899\ttraining's binary_logloss: 0.270421\tvalid_1's auc: 0.846798\tvalid_1's binary_logloss: 0.298529\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's auc: 0.887798\ttraining's binary_logloss: 0.269726\tvalid_1's auc: 0.846869\tvalid_1's binary_logloss: 0.298466\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852695\ttraining's binary_logloss: 0.298272\tvalid_1's auc: 0.834694\tvalid_1's binary_logloss: 0.308175\n",
      "[100]\ttraining's auc: 0.869093\ttraining's binary_logloss: 0.28497\tvalid_1's auc: 0.842292\tvalid_1's binary_logloss: 0.301997\n",
      "[150]\ttraining's auc: 0.879372\ttraining's binary_logloss: 0.276697\tvalid_1's auc: 0.844623\tvalid_1's binary_logloss: 0.300001\n",
      "[200]\ttraining's auc: 0.887344\ttraining's binary_logloss: 0.270172\tvalid_1's auc: 0.845315\tvalid_1's binary_logloss: 0.299225\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's auc: 0.886405\ttraining's binary_logloss: 0.27101\tvalid_1's auc: 0.845389\tvalid_1's binary_logloss: 0.2992\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.853841\ttraining's binary_logloss: 0.297929\tvalid_1's auc: 0.830913\tvalid_1's binary_logloss: 0.308849\n",
      "[100]\ttraining's auc: 0.869867\ttraining's binary_logloss: 0.284511\tvalid_1's auc: 0.837493\tvalid_1's binary_logloss: 0.303402\n",
      "[150]\ttraining's auc: 0.880271\ttraining's binary_logloss: 0.276167\tvalid_1's auc: 0.839663\tvalid_1's binary_logloss: 0.301673\n",
      "[200]\ttraining's auc: 0.888299\ttraining's binary_logloss: 0.269601\tvalid_1's auc: 0.840531\tvalid_1's binary_logloss: 0.300949\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's auc: 0.887494\ttraining's binary_logloss: 0.27023\tvalid_1's auc: 0.840631\tvalid_1's binary_logloss: 0.300929\n",
      "*********************\n",
      "roc auc estimado:  0.8444576207545462\n",
      "roc auc varianza:  0.0005225965817099837\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = LGBMClassifier(n_estimators=1000, boosting_type='gbdt',min_child_samples=1500, \n",
    "                             colsample_bytree=0.8,subsample=0.8, max_bin=200, learning_rate=0.1)\n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=50) \n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expanded-engine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ciiu_mode                                            0.113727\n",
       "cod_instit_financiera_mode_ult1mes                   0.048391\n",
       "ubigeo_mode                                          0.047601\n",
       "cod_instit_financiera_mode_ult12mes                  0.028814\n",
       "cod_instit_financiera_mode_ult2mes                   0.026436\n",
       "cod_instit_financiera_mode_ult3mes                   0.019045\n",
       "cod_instit_financiera_mode_ult11mes                  0.018853\n",
       "cod_instit_financiera_mode_ult4mes                   0.016344\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult1meses               0.014236\n",
       "cod_instit_financiera_mode_ult10mes                  0.013086\n",
       "cod_instit_financiera_mode_ult5mes                   0.013068\n",
       "cod_instit_financiera_mode_ult8mes                   0.012467\n",
       "cod_instit_financiera_mode_ult6mes                   0.011805\n",
       "cod_instit_financiera_mode_ult9mes                   0.011791\n",
       "cod_instit_financiera_mode_ult7mes                   0.011316\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.009576\n",
       "edad                                                 0.009022\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.007951\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult12meses             0.007287\n",
       "RIESGO_DIRECTO_1_saldoStd_ult1meses                  0.006941\n",
       "codzona_mode                                         0.006904\n",
       "condicion_0_saldoUnique_ult12meses                   0.006230\n",
       "sexo_0                                               0.006089\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.005087\n",
       "PRODUCTO_mode_ult1mes                                0.004944\n",
       "RIESGO_DIRECTO_1_saldoMin_ult1meses                  0.004633\n",
       "tipo_credito_11_saldoUnique_ult12meses               0.004587\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult12meses              0.004584\n",
       "estadocontribuyente_0                                0.004457\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult2meses               0.004409\n",
       "RIESGO_DIRECTO_1_saldoMax_ult12meses                 0.004382\n",
       "cod_instit_financiera_max_ult1mes                    0.004270\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult3meses               0.003700\n",
       "RIESGO_DIRECTO_1_saldoMax_ult1meses                  0.003584\n",
       "tipo_credito_11_saldoStd_ult1meses                   0.003523\n",
       "ctd_veh                                              0.003358\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.003331\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMin_ult1meses        0.003260\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult1meses               0.003184\n",
       "RIESGO_DIRECTO_1_saldoStd_ult12meses                 0.003102\n",
       "PRODUCTO_min_ult1mes                                 0.002994\n",
       "tipo_credito_12_saldoUnique_ult1meses                0.002970\n",
       "PRODUCTO_mode_ult12mes                               0.002957\n",
       "PRODUCTO_mode_ult4mes                                0.002938\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.002824\n",
       "RIESGO_DIRECTO_1_saldoMin_ult2meses                  0.002711\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMax_ult1meses        0.002688\n",
       "RIESGO_DIRECTO_1_saldoStd_ult2meses                  0.002670\n",
       "RIESGO_DIRECTO_1_saldoMean_ult1meses                 0.002622\n",
       "RIESGO_DIRECTO_1_saldoMin_ult12meses                 0.002619\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "comic-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_lightgbm_cf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "large-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_lightgbm_cf = train_probs\n",
    "test_probs_lightgbm_cf= test_probs\n",
    "train_probs_lightgbm_cf.to_pickle('train_probs_lightgbm_cf.pkl')\n",
    "test_probs_lightgbm_cf.to_pickle('test_probs_lightgbm_cf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-contact",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelo XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "speaking-prize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1136), (396666, 1136))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suitable-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\venv_datathon\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.71377\tvalidation_1-auc:0.71278\n",
      "[100]\tvalidation_0-auc:0.85797\tvalidation_1-auc:0.84055\n",
      "[166]\tvalidation_0-auc:0.86916\tvalidation_1-auc:0.84218\n",
      "********** 1 **********\n",
      "[0]\tvalidation_0-auc:0.71254\tvalidation_1-auc:0.71216\n",
      "[100]\tvalidation_0-auc:0.85818\tvalidation_1-auc:0.84030\n",
      "[141]\tvalidation_0-auc:0.86585\tvalidation_1-auc:0.84120\n",
      "********** 2 **********\n",
      "[0]\tvalidation_0-auc:0.71196\tvalidation_1-auc:0.71516\n",
      "[100]\tvalidation_0-auc:0.85856\tvalidation_1-auc:0.84255\n",
      "[123]\tvalidation_0-auc:0.86263\tvalidation_1-auc:0.84295\n",
      "********** 3 **********\n",
      "[0]\tvalidation_0-auc:0.71033\tvalidation_1-auc:0.71230\n",
      "[100]\tvalidation_0-auc:0.85799\tvalidation_1-auc:0.84265\n",
      "[160]\tvalidation_0-auc:0.86852\tvalidation_1-auc:0.84364\n",
      "********** 4 **********\n",
      "[0]\tvalidation_0-auc:0.71385\tvalidation_1-auc:0.69850\n",
      "[100]\tvalidation_0-auc:0.85998\tvalidation_1-auc:0.83431\n",
      "[109]\tvalidation_0-auc:0.86164\tvalidation_1-auc:0.83415\n",
      "*********************\n",
      "roc auc estimado:  0.8409848198898145\n",
      "roc auc varianza:  0.0008274475527697357\n"
     ]
    }
   ],
   "source": [
    "from xgboost  import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = XGBClassifier(n_estimators=1000, booster='gbtree', colsample_bytree=0.8, \n",
    "                            subsample = 0.8, max_depth=4,  learning_rate=0.3)\n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sporting-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lonely-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_lightgbm_cf = train_probs\n",
    "test_probs_lightgbm_cf= test_probs\n",
    "train_probs_lightgbm_cf.to_pickle('train_probs_xgb.pkl')\n",
    "test_probs_lightgbm_cf.to_pickle('test_probs_xgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-bedroom",
   "metadata": {},
   "source": [
    "## Entrenando Neural Network Artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ignored-community",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1136), (396666, 1136))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl')\n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modern-might",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 783), (396666, 783))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### eliminar variable cuyo porcentaje de valores nulos es mayor al 90%\n",
    "aux = train.isna().sum()/len(train)\n",
    "drop_columns = list(aux[aux>=0.9].index)\n",
    "train.drop(drop_columns, axis=1, inplace=True)\n",
    "test.drop(drop_columns, axis=1, inplace=True)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressing-continuity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840152977675237"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.read_pickle('fi_lightgbm.pkl')\n",
    "fi.loc[train.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artificial-lindsay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_missing_values = list(train.isna().sum()[train.isna().sum()>0].index)\n",
    "len(var_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "right-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 88, 97, 81, 84, 82, 78, 70)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_mode =[i for i in var_missing_values if \"mode\" in i]\n",
    "var_std =[i for i in var_missing_values if \"Std\" in i or \"std\" in i]\n",
    "var_unique =[i for i in var_missing_values if \"Unique\" in i or \"unique\" in i ]\n",
    "var_mean =[i for i in var_missing_values if \"Mean\" in i or \"mean\" in i]\n",
    "var_median =[i for i in var_missing_values if \"Median\" in i or \"median\" in i]\n",
    "var_sum =[i for i in var_missing_values if \"Sum\" in i or \"sum\" in i]\n",
    "var_max =[i for i in var_missing_values if \"Max\" in i or \"max\" in i]\n",
    "var_min =[i for i in var_missing_values if \"Min\" in i or \"min\" in i]\n",
    "len(var_mode), len(var_std), len(var_unique), len(var_mean), len(var_median), len(var_sum),len(var_max), len(var_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instant-malpractice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 31)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_total = var_mode+var_std+var_unique+var_mean+var_median+var_sum+var_max+var_min\n",
    "var_rest = list(set(var_missing_values).difference(var_total))\n",
    "len(set(var_total)), len(set(var_rest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-highland",
   "metadata": {},
   "source": [
    "#### imputacion tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "precious-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in var_mode:\n",
    "    train[i] = train[i].fillna(train[i].value_counts().index[0])\n",
    "    test[i] = test[i].fillna(train[i].value_counts().index[0])\n",
    "for i in var_std:\n",
    "    train[i] = train[i].fillna(0)   \n",
    "    test[i] = test[i].fillna(0)   \n",
    "for i in var_unique:\n",
    "    train[i] = train[i].fillna(0)   \n",
    "    test[i] = test[i].fillna(0)   \n",
    "for i in var_mean:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_median:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_sum:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_max:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_min:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_rest:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "least-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "homeless-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(y_train):\n",
    "    one_hot =[]\n",
    "    for i in y_train.values:\n",
    "        aux=[]\n",
    "        for j in [0,1]:\n",
    "            if i==j:\n",
    "                aux.append(1)\n",
    "            else:\n",
    "                aux.append(0)\n",
    "        one_hot.append(aux)\n",
    "    return  np.array(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "identical-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_keras(one_hot):\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(Dense(128,input_dim=len(train.columns),activation=\"relu\"))\n",
    "    model_rnn.add(Dropout(0.5))\n",
    "    model_rnn.add(Dense(len(one_hot[0]),activation=\"sigmoid\")) # sigmoid\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#     sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    model_rnn.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['AUC'])\n",
    "    return model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "structural-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "charming-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_scaled, index=train.index, columns=train.columns)\n",
    "test = pd.DataFrame(test_scaled, index=test.index, columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "corresponding-attraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.4339 - auc: 0.8822\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3446 - auc: 0.9259\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3365 - auc: 0.9287\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3329 - auc: 0.9298\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3307 - auc: 0.9310\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3291 - auc: 0.9322\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3294 - auc: 0.9321\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3261 - auc: 0.9328\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3241 - auc: 0.9334\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3219 - auc: 0.9342\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3223 - auc: 0.9342\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3238 - auc: 0.9340\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3232 - auc: 0.9342\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3241 - auc: 0.9343\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3218 - auc: 0.9347\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3230 - auc: 0.9347\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3198 - auc: 0.9353\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3194 - auc: 0.9354\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3181 - auc: 0.9360\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3216 - auc: 0.9355\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3195 - auc: 0.9358\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3190 - auc: 0.9358\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3241 - auc: 0.9350\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3200 - auc: 0.9359\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3154 - auc: 0.9369\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3186 - auc: 0.9360\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3189 - auc: 0.9368\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3172 - auc: 0.9368\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3197 - auc: 0.9360\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3232 - auc: 0.9359\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3163 - auc: 0.9366\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3159 - auc: 0.9369\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3190 - auc: 0.9368\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3186 - auc: 0.9366\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3162 - auc: 0.9375\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3178 - auc: 0.9373\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3158 - auc: 0.9372\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3184 - auc: 0.9366\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3166 - auc: 0.9376\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3170 - auc: 0.9370\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3165 - auc: 0.9375\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3172 - auc: 0.9369\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3142 - auc: 0.9381\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3152 - auc: 0.9377\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3185 - auc: 0.9368\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3154 - auc: 0.9379\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3154 - auc: 0.9375\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3153 - auc: 0.9375\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3133 - auc: 0.9382\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3163 - auc: 0.9375\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3134 - auc: 0.9385\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3131 - auc: 0.9384\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3151 - auc: 0.9381\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3154 - auc: 0.9379\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3133 - auc: 0.9386\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3164 - auc: 0.9376\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3129 - auc: 0.9384\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3138 - auc: 0.9382\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3140 - auc: 0.9382\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3137 - auc: 0.9386\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3115 - auc: 0.9393\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3161 - auc: 0.9382\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3116 - auc: 0.9392\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3116 - auc: 0.9393\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3160 - auc: 0.9378\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3138 - auc: 0.9390\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3139 - auc: 0.9384\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3117 - auc: 0.9388\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3171 - auc: 0.9378\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3135 - auc: 0.9384\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3097 - auc: 0.9395\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3142 - auc: 0.9385\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3160 - auc: 0.9384\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3130 - auc: 0.9390\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3117 - auc: 0.9399: 1s - loss: \n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3122 - auc: 0.9391\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3100 - auc: 0.9401\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3175 - auc: 0.9391\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3186 - auc: 0.9389\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3105 - auc: 0.9398\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3116 - auc: 0.9397\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3146 - auc: 0.9388\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3105 - auc: 0.9398\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3131 - auc: 0.9391\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3155 - auc: 0.9382\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3182 - auc: 0.9388\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3155 - auc: 0.9383\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3112 - auc: 0.9396\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3143 - auc: 0.9391\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3110 - auc: 0.9393\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3157 - auc: 0.9387\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3107 - auc: 0.9392\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3110 - auc: 0.9394\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3121 - auc: 0.9397\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3195 - auc: 0.9391\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3137 - auc: 0.9391\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3131 - auc: 0.9394\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3125 - auc: 0.9396\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3149 - auc: 0.9390\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3127 - auc: 0.9397\n",
      "roc_auc estimado en fold 0 : 0.8328156841750685\n",
      "********** 1 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.4123 - auc: 0.8963\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3439 - auc: 0.9260\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3379 - auc: 0.9286\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3344 - auc: 0.9301\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3289 - auc: 0.9320\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3274 - auc: 0.9327\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3296 - auc: 0.9323\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3276 - auc: 0.9332\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3256 - auc: 0.9338\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3266 - auc: 0.9333\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3247 - auc: 0.9340\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3201 - auc: 0.9355\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3241 - auc: 0.9347\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3235 - auc: 0.9346\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3253 - auc: 0.9345\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3221 - auc: 0.9353\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3231 - auc: 0.9349\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3223 - auc: 0.9355\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3209 - auc: 0.9363\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3210 - auc: 0.9351\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3213 - auc: 0.9364\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3202 - auc: 0.9355\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3198 - auc: 0.9360\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3197 - auc: 0.9363\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3191 - auc: 0.9366\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3198 - auc: 0.9363\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3185 - auc: 0.9364\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3166 - auc: 0.9372\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3176 - auc: 0.9374\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3177 - auc: 0.9373\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3172 - auc: 0.9369\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3185 - auc: 0.9367\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3186 - auc: 0.9370\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3235 - auc: 0.9370\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3194 - auc: 0.9371\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3195 - auc: 0.9373\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3235 - auc: 0.9364\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3167 - auc: 0.9374\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3183 - auc: 0.9371\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3204 - auc: 0.9363\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3159 - auc: 0.9381\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3198 - auc: 0.9378\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3197 - auc: 0.9378\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3162 - auc: 0.9379\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3168 - auc: 0.9379\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3190 - auc: 0.9380\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3163 - auc: 0.9380\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3191 - auc: 0.9380\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3175 - auc: 0.9376\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3195 - auc: 0.9368\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3176 - auc: 0.9375\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3162 - auc: 0.9381\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3190 - auc: 0.9376\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3171 - auc: 0.9384\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3142 - auc: 0.9386\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3186 - auc: 0.9382\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3182 - auc: 0.9381\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3194 - auc: 0.9376\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3209 - auc: 0.9379\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3215 - auc: 0.9377\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3139 - auc: 0.9388\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3154 - auc: 0.9388\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3162 - auc: 0.9381\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3185 - auc: 0.9389\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3169 - auc: 0.9391\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3210 - auc: 0.9386\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3142 - auc: 0.9387\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3130 - auc: 0.9391\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3142 - auc: 0.9388\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3180 - auc: 0.9383\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3112 - auc: 0.9397\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3171 - auc: 0.9377\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3136 - auc: 0.9388\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3135 - auc: 0.9394\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3184 - auc: 0.9384\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3216 - auc: 0.9395\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3219 - auc: 0.9382\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3145 - auc: 0.9387\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3131 - auc: 0.9397\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3145 - auc: 0.9393\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3162 - auc: 0.9391\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3210 - auc: 0.9390\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3140 - auc: 0.9386\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3129 - auc: 0.9387\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3147 - auc: 0.9390\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3158 - auc: 0.9382\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3150 - auc: 0.9390\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3173 - auc: 0.9385\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3195 - auc: 0.9397\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3142 - auc: 0.9392\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3151 - auc: 0.9397\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3127 - auc: 0.9385\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3144 - auc: 0.9395\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3123 - auc: 0.9399\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3162 - auc: 0.9390\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3167 - auc: 0.9395\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3189 - auc: 0.9395\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3130 - auc: 0.9396\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3252 - auc: 0.9387\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3103 - auc: 0.9402\n",
      "roc_auc estimado en fold 1 : 0.8284837864921992\n",
      "********** 2 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.4150 - auc: 0.8942\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3467 - auc: 0.9253\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3379 - auc: 0.9291\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3335 - auc: 0.9306\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3328 - auc: 0.9305\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3290 - auc: 0.9323\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3305 - auc: 0.9317\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3268 - auc: 0.9333\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3279 - auc: 0.9336\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3268 - auc: 0.9328\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3267 - auc: 0.9332\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3261 - auc: 0.9339\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3258 - auc: 0.9334\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3240 - auc: 0.9348\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3274 - auc: 0.9344\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3227 - auc: 0.9349\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3221 - auc: 0.9354\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3263 - auc: 0.9345\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3215 - auc: 0.9355\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3221 - auc: 0.9350\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3229 - auc: 0.9353\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3212 - auc: 0.9354\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3195 - auc: 0.9358\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3203 - auc: 0.9362\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3180 - auc: 0.9365\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3254 - auc: 0.9353\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3192 - auc: 0.9358\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3202 - auc: 0.9359\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3175 - auc: 0.9372\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3211 - auc: 0.9361\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3170 - auc: 0.9372\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3184 - auc: 0.9367\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3216 - auc: 0.9355\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3174 - auc: 0.9367\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3181 - auc: 0.9364\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3184 - auc: 0.9372\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3187 - auc: 0.9369\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3187 - auc: 0.9367\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3182 - auc: 0.9374\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3160 - auc: 0.9375\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3197 - auc: 0.9367\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3202 - auc: 0.9365\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3162 - auc: 0.9376\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3200 - auc: 0.9368\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3170 - auc: 0.9371\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3181 - auc: 0.9375\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3161 - auc: 0.9378\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3182 - auc: 0.9371\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3182 - auc: 0.9384\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3239 - auc: 0.9365\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3168 - auc: 0.9381\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3208 - auc: 0.9384\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3174 - auc: 0.9377\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3139 - auc: 0.9378\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3201 - auc: 0.9372\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3149 - auc: 0.9380\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3152 - auc: 0.9382\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3194 - auc: 0.9380\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3164 - auc: 0.9379\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3219 - auc: 0.9377\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3188 - auc: 0.9380\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3151 - auc: 0.9384\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3156 - auc: 0.9381\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3156 - auc: 0.9388\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3180 - auc: 0.9382\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3189 - auc: 0.9381\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3147 - auc: 0.9383\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3125 - auc: 0.9393\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3215 - auc: 0.9375\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3168 - auc: 0.9385\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3171 - auc: 0.9383\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3135 - auc: 0.9387\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3137 - auc: 0.9390\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3190 - auc: 0.9380\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3170 - auc: 0.9383\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3195 - auc: 0.9379\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3167 - auc: 0.9390\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3145 - auc: 0.9384\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3144 - auc: 0.9381\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3163 - auc: 0.9386\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3159 - auc: 0.9383\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3127 - auc: 0.9389\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3153 - auc: 0.9385\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3187 - auc: 0.9386\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3195 - auc: 0.9394\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3147 - auc: 0.9392\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3147 - auc: 0.9389\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3197 - auc: 0.9384\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3119 - auc: 0.9395\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3154 - auc: 0.9389\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3161 - auc: 0.9389\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3136 - auc: 0.9390\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3138 - auc: 0.9395\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3150 - auc: 0.9384\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3209 - auc: 0.9385\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3162 - auc: 0.9393\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3144 - auc: 0.9388\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3107 - auc: 0.9397\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3149 - auc: 0.9396\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3170 - auc: 0.9385\n",
      "roc_auc estimado en fold 2 : 0.8339549812306826\n",
      "********** 3 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 4s 11ms/step - loss: 0.4039 - auc: 0.9000: 2s - loss: 0.4874 - au -  - ETA: 0s - loss: 0.4076 - auc:\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3454 - auc: 0.9260\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3395 - auc: 0.9278\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3338 - auc: 0.9305\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3313 - auc: 0.9309\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3280 - auc: 0.9326\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3286 - auc: 0.9322\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3284 - auc: 0.9324\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3266 - auc: 0.9331\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3346 - auc: 0.9327\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3277 - auc: 0.9337\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3275 - auc: 0.9338\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3283 - auc: 0.9343\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3221 - auc: 0.9349\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3223 - auc: 0.9350\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3237 - auc: 0.9346\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3214 - auc: 0.9353\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3224 - auc: 0.9350\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3229 - auc: 0.9354\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3213 - auc: 0.9354\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3230 - auc: 0.9349\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3212 - auc: 0.9355\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3231 - auc: 0.9358\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3244 - auc: 0.9358\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3197 - auc: 0.9363\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3248 - auc: 0.9361\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3235 - auc: 0.9361\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3193 - auc: 0.9360\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3207 - auc: 0.9362\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3218 - auc: 0.9360\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3189 - auc: 0.9364\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3200 - auc: 0.9364\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3194 - auc: 0.9367\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3212 - auc: 0.9369\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3207 - auc: 0.9373\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3165 - auc: 0.9377\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3217 - auc: 0.9366\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3160 - auc: 0.9377\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3162 - auc: 0.9377\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3215 - auc: 0.9364\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3255 - auc: 0.9373\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3191 - auc: 0.9364\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3172 - auc: 0.9366\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3179 - auc: 0.9372\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3215 - auc: 0.9374\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3161 - auc: 0.9380\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3172 - auc: 0.9375\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3211 - auc: 0.9374\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3166 - auc: 0.9373\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3170 - auc: 0.9373\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3181 - auc: 0.9376\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3164 - auc: 0.9374\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3208 - auc: 0.9373\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3185 - auc: 0.9372\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3158 - auc: 0.9377\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3142 - auc: 0.9385\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3254 - auc: 0.9377\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3175 - auc: 0.9379\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3131 - auc: 0.9383\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3141 - auc: 0.9383\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3174 - auc: 0.9378\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3181 - auc: 0.9375\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3175 - auc: 0.9387\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3234 - auc: 0.9376\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3153 - auc: 0.9384\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3183 - auc: 0.9378\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3162 - auc: 0.9382\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3169 - auc: 0.9384\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3193 - auc: 0.9379\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3221 - auc: 0.9386\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3191 - auc: 0.9371\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3303 - auc: 0.9378\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3167 - auc: 0.9386\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3167 - auc: 0.9390\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3195 - auc: 0.9380\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3147 - auc: 0.9383\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3145 - auc: 0.9389\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3165 - auc: 0.9383\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3182 - auc: 0.9387\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3156 - auc: 0.9378\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3131 - auc: 0.9392\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3134 - auc: 0.9390\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3142 - auc: 0.9386\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3159 - auc: 0.9391\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3191 - auc: 0.9379\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3118 - auc: 0.9391\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3146 - auc: 0.9384\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3135 - auc: 0.9386\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3151 - auc: 0.9396\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3219 - auc: 0.9382\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3150 - auc: 0.9380\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3145 - auc: 0.9391\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3209 - auc: 0.9374\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3252 - auc: 0.9388\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3179 - auc: 0.9390\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3164 - auc: 0.9396\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3201 - auc: 0.9375\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3118 - auc: 0.9390\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3145 - auc: 0.9390\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3216 - auc: 0.9387\n",
      "roc_auc estimado en fold 3 : 0.8325131703916002\n",
      "********** 4 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.4059 - auc: 0.8984\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3441 - auc: 0.9265\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3357 - auc: 0.9293\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3335 - auc: 0.9302\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3288 - auc: 0.9322\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3306 - auc: 0.9317\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3297 - auc: 0.9318\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3285 - auc: 0.9323\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3261 - auc: 0.9335\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3293 - auc: 0.9336\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3268 - auc: 0.9343\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3235 - auc: 0.9346\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3238 - auc: 0.9341\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3194 - auc: 0.9357\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3251 - auc: 0.9345\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3264 - auc: 0.9348\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3218 - auc: 0.9352\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3222 - auc: 0.9361\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3210 - auc: 0.9358\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3253 - auc: 0.9356\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3167 - auc: 0.9370\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3185 - auc: 0.9364\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3190 - auc: 0.9365\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3201 - auc: 0.9369\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3221 - auc: 0.9362\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3185 - auc: 0.9365\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3198 - auc: 0.9367\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3205 - auc: 0.9372\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3227 - auc: 0.9368\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3210 - auc: 0.9368\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3198 - auc: 0.9373\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3172 - auc: 0.9371\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3223 - auc: 0.9371\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3213 - auc: 0.9371\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3202 - auc: 0.9368\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3186 - auc: 0.9378\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3263 - auc: 0.9376\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3185 - auc: 0.9374\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3170 - auc: 0.9383\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3152 - auc: 0.9376\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3160 - auc: 0.9380\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3170 - auc: 0.9374\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3154 - auc: 0.9377\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3181 - auc: 0.9373\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3168 - auc: 0.9385\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3187 - auc: 0.9381\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3135 - auc: 0.9385\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3190 - auc: 0.9385\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3172 - auc: 0.9379\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3177 - auc: 0.9385\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3137 - auc: 0.9386\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3143 - auc: 0.9385\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3162 - auc: 0.9387\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3180 - auc: 0.9375\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3204 - auc: 0.9383\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3165 - auc: 0.9374\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3215 - auc: 0.9384\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3157 - auc: 0.9387\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3144 - auc: 0.9385\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3132 - auc: 0.9393\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3179 - auc: 0.9383\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3132 - auc: 0.9389\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3204 - auc: 0.9385\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3130 - auc: 0.9390\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3250 - auc: 0.9383\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3207 - auc: 0.9384\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3150 - auc: 0.9386\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3140 - auc: 0.9388\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3166 - auc: 0.9387\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3164 - auc: 0.9384\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3202 - auc: 0.9389\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3204 - auc: 0.9386\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3155 - auc: 0.9393\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3151 - auc: 0.9392\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3157 - auc: 0.9382\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3176 - auc: 0.9391\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3155 - auc: 0.9394\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3122 - auc: 0.9391\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3164 - auc: 0.9398\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3160 - auc: 0.9389\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3131 - auc: 0.9390\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3168 - auc: 0.9390\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3142 - auc: 0.9392\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3106 - auc: 0.9399\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3143 - auc: 0.9393\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3107 - auc: 0.9397\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3131 - auc: 0.9396\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3215 - auc: 0.9394\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3118 - auc: 0.9394\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3112 - auc: 0.9394\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3145 - auc: 0.9392\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3140 - auc: 0.9395\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3146 - auc: 0.9386\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3230 - auc: 0.9401\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3122 - auc: 0.9399\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3164 - auc: 0.9394\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3145 - auc: 0.9397\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3124 - auc: 0.9393\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3160 - auc: 0.9400\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3110 - auc: 0.9401\n",
      "roc_auc estimado en fold 4 : 0.8255343171594599\n",
      "*********************\n",
      "roc auc estimado:  0.8298009311291774\n",
      "roc auc varianza:  0.0009551435622209993\n"
     ]
    }
   ],
   "source": [
    "# https://keras.rstudio.com/reference/fit.html\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index]\n",
    "    yt = get_one_hot(yt)\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index]\n",
    "    yv = get_one_hot(yv)\n",
    "    \n",
    "    learner = get_model_keras(yv)\n",
    "    \n",
    "    num_epochs = 100\n",
    "    num_batch_size = 1024\n",
    "#     num_steps_per_epoch = len(Xt)//batch_size      steps_per_epoch = num_steps_per_epoch\n",
    "    num_validation_steps = 10\n",
    "    learner.fit(Xt, yt ,epochs=num_epochs, batch_size=num_batch_size, \n",
    "                        validation_steps=num_validation_steps)    \n",
    "    \n",
    "    test_probs.append(pd.Series(learner.predict(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    print(f'roc_auc estimado en fold {i} : {roc_auc_score(yv[:,-1],learner.predict(Xv)[:,-1])}')\n",
    "#     fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "# fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "########     num_batch_size = 512   \n",
    "###  num_epochs = 7   0.818\n",
    "###  num_epochs = 15  0.82300\n",
    "###  num_epochs = 30  0.82598\n",
    "###  num_epochs = 50  0.82720 , num_batch_size = 1028 \n",
    "###  num_epochs = 50   0.829800 , num_batch_size = 1028 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "subsequent-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_rnn = train_probs\n",
    "test_probs_rnn = test_probs\n",
    "train_probs_rnn.to_pickle('train_probs_rnn.pkl')\n",
    "test_probs_rnn.to_pickle('test_probs_rnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-heating",
   "metadata": {},
   "source": [
    "## Entrenando RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "mechanical-headline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1136), (396666, 1136))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl')\n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fiscal-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### eliminar variable cuyo porcentaje de valores nulos es mayor al 90%\n",
    "# aux = train.isna().sum()/len(train)\n",
    "# drop_columns = list(aux[aux>=0.9].index)\n",
    "# train.drop(drop_columns, axis=1, inplace=True)\n",
    "# test.drop(drop_columns, axis=1, inplace=True)\n",
    "# train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "helpful-double",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_missing_values = list(train.isna().sum()[train.isna().sum()>0].index)\n",
    "len(var_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adopted-guitar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 144, 134, 122, 136, 141, 118, 138)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_mode =[i for i in var_missing_values if \"mode\" in i]\n",
    "var_std =[i for i in var_missing_values if \"Std\" in i or \"std\" in i]\n",
    "var_unique =[i for i in var_missing_values if \"Unique\" in i or \"unique\" in i ]\n",
    "var_mean =[i for i in var_missing_values if \"Mean\" in i or \"mean\" in i]\n",
    "var_median =[i for i in var_missing_values if \"Median\" in i or \"median\" in i]\n",
    "var_sum =[i for i in var_missing_values if \"Sum\" in i or \"sum\" in i]\n",
    "var_max =[i for i in var_missing_values if \"Max\" in i or \"max\" in i]\n",
    "var_min =[i for i in var_missing_values if \"Min\" in i or \"min\" in i]\n",
    "len(var_mode), len(var_std), len(var_unique), len(var_mean), len(var_median), len(var_sum),len(var_max), len(var_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "current-county",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947, 31)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_total = var_mode+var_std+var_unique+var_mean+var_median+var_sum+var_max+var_min\n",
    "var_rest = list(set(var_missing_values).difference(var_total))\n",
    "len(set(var_total)), len(set(var_rest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-florence",
   "metadata": {},
   "source": [
    "#### imputacion tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "phantom-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in var_mode:\n",
    "    train[i] = train[i].fillna(train[i].value_counts().index[0])\n",
    "    test[i] = test[i].fillna(train[i].value_counts().index[0])\n",
    "for i in var_std:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_unique:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_mean:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_median:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_sum:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_max:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_min:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_rest:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acting-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "civil-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_scaled, index=train.index, columns=train.columns)\n",
    "test = pd.DataFrame(test_scaled, index=test.index, columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "regular-compatibility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 31.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   17.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_estimado de : 0.8160446309003905\n",
      "********** 1 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 34.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   16.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_estimado de : 0.8128923379282575\n",
      "********** 2 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 33.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   16.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_estimado de : 0.8158224697753691\n",
      "********** 3 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 33.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   17.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_estimado de : 0.8164068895782973\n",
      "********** 4 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 750 out of 750 | elapsed: 33.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done 750 out of 750 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_estimado de : 0.8066047995445774\n",
      "*********************\n",
      "roc auc estimado:  0.8135739969441819\n",
      "roc auc varianza:  0.0009086492987086464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = RandomForestClassifier(n_estimators=750, criterion='gini', n_jobs=-1, verbose=True,\n",
    "             random_state=407)  # min_impurity_decrease=0.0000007  oob_score=True\n",
    "\n",
    "    learner.fit(Xt, yt)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "    print('roc_auc_estimado de : ' + str(roc_auc_score(yv, pd.Series(learner.predict_proba(Xv)[:, -1]))))    \n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### n_estimators=500 con 900 features  ---- score 0.8009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fancy-birth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COD_CLASIFICACION_DEUDOR_5_saldoMin_ult1meses        0.007028\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMedian_ult1meses     0.006970\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult2meses        0.006694\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMax_ult1meses        0.006215\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult7meses        0.005983\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMean_ult1meses       0.005741\n",
       "condicion_9_saldoSum_ult1meses                       0.005584\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult6meses        0.005193\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult8meses        0.005022\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoUnique_ult11meses    0.004465\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMean_ult9meses       0.004291\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult9meses        0.004055\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoUnique_ult10meses    0.003962\n",
       "edad                                                 0.003924\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult4meses        0.003374\n",
       "condicion_9_saldoMin_ult9meses                       0.003334\n",
       "condicion_9_saldoSum_ult12meses                      0.003158\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.002957\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult12meses       0.002946\n",
       "condicion_9_saldoMin_ult12meses                      0.002668\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoMin_ult4meses        0.002645\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.002618\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoSum_ult1meses        0.002617\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult5meses        0.002573\n",
       "tipo_credito_12_saldoSum_ult1meses                   0.002518\n",
       "condicion_9_saldoMedian_ult10meses                   0.002461\n",
       "cod_instit_financiera_max_ult1mes                    0.002363\n",
       "condicion_0_saldoSum_ult1meses                       0.002356\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.002343\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.002327\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoSum_ult9meses        0.002242\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult3meses              0.002195\n",
       "RIESGO_DIRECTO_1_saldoSum_ult2meses                  0.002156\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoMedian_ult4meses     0.002073\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoMean_ult9meses       0.002046\n",
       "condicion_9_saldoMedian_ult12meses                   0.002043\n",
       "RIESGO_DIRECTO_2_saldoMax_ult5meses                  0.002039\n",
       "cod_instit_financiera_max_ult3mes                    0.002017\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoSum_ult2meses        0.001982\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult4meses              0.001972\n",
       "cod_instit_financiera_max_ult2mes                    0.001945\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult2meses                 0.001940\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoUnique_ult10meses    0.001915\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult12meses                0.001905\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMin_ult2meses        0.001897\n",
       "RIESGO_DIRECTO_2_saldoMax_ult6meses                  0.001896\n",
       "condicion_0_saldoSum_ult2meses                       0.001888\n",
       "ubigeo_mode                                          0.001883\n",
       "condicion_9_saldoStd_ult4meses                       0.001868\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult5meses              0.001832\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "suspended-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_randomforrest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "filled-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_randomforrest = train_probs\n",
    "test_probs_randomforrest = test_probs\n",
    "train_probs_randomforrest.to_pickle('train_probs_randomforrest.pkl')\n",
    "test_probs_randomforrest.to_pickle('test_probs_randomforrest.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-actress",
   "metadata": {},
   "source": [
    "## Entrenando GradientBosstingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "earlier-spoke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7714           0.0982          349.74m\n",
      "         2           0.7362           0.0364          349.16m\n",
      "         3           0.7133           0.0225          344.50m\n",
      "         4           0.6951           0.0157          453.53m\n",
      "         5           0.6834           0.0139          426.68m\n",
      "         6           0.6723           0.0082          407.32m\n",
      "         7           0.6628           0.0067          396.58m\n",
      "         8           0.6526           0.0084          385.60m\n",
      "         9           0.6486           0.0044          378.98m\n",
      "        10           0.6443           0.0036          373.23m\n",
      "        20           0.6153           0.0008          353.48m\n",
      "********** 1 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7734           0.0983          323.37m\n",
      "         2           0.7430           0.0309          343.31m\n",
      "         3           0.7096           0.0280          348.08m\n",
      "         4           0.6960           0.0134          350.43m\n",
      "         5           0.6850           0.0140          351.57m\n",
      "         6           0.6724           0.0094          352.29m\n",
      "         7           0.6609           0.0068          355.79m\n",
      "         8           0.6572           0.0048          354.96m\n",
      "         9           0.6524           0.0036          354.29m\n",
      "        10           0.6498           0.0041          353.38m\n",
      "        20           0.6193           0.0013          356.39m\n",
      "********** 2 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7712           0.0981          376.19m\n",
      "         2           0.7390           0.0352          380.55m\n",
      "         3           0.7154           0.0223          372.70m\n",
      "         4           0.6968           0.0157          366.00m\n",
      "         5           0.6819           0.0160          362.41m\n",
      "         6           0.6725           0.0080          360.64m\n",
      "         7           0.6645           0.0056          361.23m\n",
      "         8           0.6595           0.0055          361.94m\n",
      "         9           0.6547           0.0037          360.46m\n",
      "        10           0.6512           0.0051          359.90m\n",
      "        20           0.6210           0.0010          353.77m\n",
      "********** 3 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7770           0.0930          372.37m\n",
      "         2           0.7419           0.0366          371.78m\n",
      "         3           0.7130           0.0269          366.52m\n",
      "         4           0.6908           0.0206          361.15m\n",
      "         5           0.6820           0.0105          361.37m\n",
      "         6           0.6680           0.0104          361.76m\n",
      "         7           0.6596           0.0077          361.88m\n",
      "         8           0.6547           0.0040          362.67m\n",
      "         9           0.6533           0.0034          363.36m\n",
      "        10           0.6470           0.0058          362.44m\n",
      "        20           0.6162           0.0009          353.87m\n",
      "********** 4 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7744           0.0998          385.89m\n",
      "         2           0.7371           0.0378          376.67m\n",
      "         3           0.7144           0.0232          373.53m\n",
      "         4           0.6952           0.0170          372.48m\n",
      "         5           0.6836           0.0123          366.39m\n",
      "         6           0.6721           0.0112          365.55m\n",
      "         7           0.6648           0.0056          364.51m\n",
      "         8           0.6581           0.0056          363.34m\n",
      "         9           0.6489           0.0069          360.58m\n",
      "        10           0.6441           0.0028          358.78m\n",
      "        20           0.6187           0.0005          351.11m\n",
      "*********************\n",
      "roc auc estimado:  0.8256986744700825\n",
      "roc auc varianza:  0.000731705827656202\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.fit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = GradientBoostingClassifier(n_estimators=500, learning_rate=0.3, subsample=0.8,\n",
    "                                         max_depth=5, verbose=1, max_features=0.82, random_state=407,\n",
    "                                         n_iter_no_change = 10, tol=0.01, validation_fraction = 0.2)\n",
    "   \n",
    "    learner.fit(Xt, yt)        \n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "interstate-organizer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult8meses        0.125724\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult2meses        0.074237\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoUnique_ult10meses    0.056049\n",
       "RIESGO_DIRECTO_2_saldoSum_ult2meses                  0.052940\n",
       "cod_instit_financiera_max_ult1mes                    0.041486\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMean_ult1meses       0.032583\n",
       "condicion_9_saldoSum_ult1meses                       0.028828\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMin_ult2meses        0.024664\n",
       "tipo_credito_11_saldoUnique_ult12meses               0.021405\n",
       "tipo_credito_12_saldoSum_ult1meses                   0.017341\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.016801\n",
       "tipo_credito_11_saldoMean_ult1meses                  0.016445\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult12meses       0.014104\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMin_ult3meses        0.014000\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoSum_ult2meses        0.013903\n",
       "cod_instit_financiera_nunique_ult1mes                0.012449\n",
       "RIESGO_DIRECTO_2_saldoSum_ult4meses                  0.012078\n",
       "PRODUCTO_min_ult1mes                                 0.011692\n",
       "cod_instit_financiera_mode_ult1mes                   0.010797\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoUnique_ult11meses    0.009314\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.009041\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.008492\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMedian_ult1meses     0.007700\n",
       "condicion_0_saldoUnique_ult12meses                   0.007555\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult1meses               0.007438\n",
       "RIESGO_DIRECTO_2_saldoMax_ult5meses                  0.007121\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.007104\n",
       "edad                                                 0.007071\n",
       "cod_instit_financiera_min_ult12mes                   0.006367\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult1meses     0.006326\n",
       "PRODUCTO_nunique_ult3mes                             0.005951\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoSum_ult6meses        0.005504\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult5meses        0.005459\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult12meses             0.005071\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoSum_ult1meses        0.005026\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoUnique_ult3meses     0.004970\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMax_ult1meses        0.004749\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.004659\n",
       "RIESGO_DIRECTO_2_saldoMax_ult6meses                  0.004597\n",
       "condicion_9_saldoSum_ult12meses                      0.004360\n",
       "condicion_2_saldoMax_ult4meses                       0.004319\n",
       "sexo_0                                               0.004295\n",
       "RIESGO_DIRECTO_2_saldoMax_ult4meses                  0.004175\n",
       "condicion_1_saldoMean_ult3meses                      0.004058\n",
       "tipo_credito_11_saldoSum_ult1meses                   0.003986\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoMean_ult1meses       0.003914\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoSum_ult12meses       0.003798\n",
       "tipo_credito_11_saldoMean_ult2meses                  0.003791\n",
       "condicion_1_saldoMin_ult2meses                       0.003691\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoUnique_ult2meses     0.003663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "subjective-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_gbc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "driving-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_gbc = train_probs\n",
    "test_probs_gbc = test_probs\n",
    "train_probs_gbc.to_pickle('train_probs_gbc.pkl')\n",
    "test_probs_gbc.to_pickle('test_probs_gbc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "precise-paragraph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    1136\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
