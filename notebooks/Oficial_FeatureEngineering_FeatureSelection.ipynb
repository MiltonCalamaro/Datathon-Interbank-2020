{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behind-darwin",
   "metadata": {},
   "source": [
    "## Importar Librerías Estándares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atmospheric-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-raising",
   "metadata": {},
   "source": [
    "## Declarar Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solar-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mode(x):\n",
    "    try:\n",
    "        moda=stat.mode(x)\n",
    "    except:\n",
    "        moda=np.nan\n",
    "    return moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conditional-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unstack(df, feature, desde, n, func):\n",
    "    print(f'haciendo unstack de {feature} desde {desde} con la funcion de agregacion {func}')\n",
    "    if func =='Sum':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.sum().unstack(level = 1, fill_value=np.nan)\n",
    "    if func == 'Unique':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.size().unstack(level = 1, fill_value=np.nan)\n",
    "    if func == 'Min':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.min().unstack(level = 1, fill_value=np.nan)\n",
    "    if func == 'Max':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.max().unstack(level = 1, fill_value=np.nan)\n",
    "    if func == 'Std':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.std().unstack(level = 1, fill_value=np.nan)\n",
    "    if func == 'Mean':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.mean().unstack(level = 1, fill_value=np.nan)\n",
    "    if func == 'Median':\n",
    "        df_result = df[df.codmes>=desde].groupby(['key_value', feature]).saldo.median().unstack(level = 1, fill_value=np.nan)\n",
    "    df_result.columns = [f'{df_result.columns.name}_{value}_saldo{func}_ult{n+1}meses' for value in df_result.columns]\n",
    "    gc.collect()      \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "objective-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keep_columns(train, test):\n",
    "    print(train.shape, test.shape)\n",
    "    keep_columns = list(set(train.columns).intersection(test.columns))\n",
    "    train = train[keep_columns]\n",
    "    test = test[keep_columns]\n",
    "    print(train.shape, test.shape)\n",
    "    return  train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "foreign-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validation_lightgbm(train, y_train, test):\n",
    "    folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "    test_probs = []\n",
    "    train_probs = []\n",
    "    fi = []\n",
    "    for i, idx in enumerate(folds):\n",
    "        print(\"*\"*10, i, \"*\"*10)\n",
    "        Xt = train.loc[idx]\n",
    "        yt = y_train.loc[Xt.index].target\n",
    "\n",
    "        Xv = train.drop(Xt.index)\n",
    "        yv = y_train.loc[Xv.index].target\n",
    "\n",
    "        learner = LGBMClassifier(n_estimators=1000, boosting_type='gbdt',min_child_samples=1500, \n",
    "                       colsample_bytree=0.8,subsample=0.8, max_bin=200, learning_rate=0.1)\n",
    "        learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                    eval_set=[(Xt, yt), (Xv, yv)], verbose=50)\n",
    "        test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "        train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "        fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "    test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "    train_probs = pd.concat(train_probs)\n",
    "    fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "    print(\"*\" * 21)\n",
    "    print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "    print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))])) \n",
    "    return test_probs, fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "global-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_selection(fi):\n",
    "    zero_importance = fi[fi==0]\n",
    "    aux = fi[fi>0].sort_values(ascending=False)\n",
    "    keep_columns = []\n",
    "    count = 0\n",
    "    for feature,values in zip(aux.index, aux.values):\n",
    "        count+=values\n",
    "        if count<=0.99:\n",
    "            keep_columns.append(feature)\n",
    "            \n",
    "    print(f'total de variables : {len(fi)}')\n",
    "    print(f'variables con importancia acumulada al 99% : {len(keep_columns)}')\n",
    "    print(f'variables con zero importancia : {len(zero_importance)}')\n",
    "    return keep_columns, zero_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "threatened-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(df, feature):\n",
    "    one_hot = pd.get_dummies(df[feature])\n",
    "    one_hot.columns = [feature+'_'+str(i) for i in one_hot.columns]\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "plastic-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crosstab(df, index, feature):\n",
    "    df = pd.crosstab(df[index], df[feature])\n",
    "    df.columns = [f'{df.columns.name}_{i}' for i in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-checkout",
   "metadata": {},
   "source": [
    "## Cargar la variable Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supported-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data'\n",
    "y_train = pd.read_csv(f'{path}/y_train.csv', index_col = 'key_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "liable-clear",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind='pie', autopct='%1.0f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-absence",
   "metadata": {},
   "source": [
    "## Procesar RCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minimal-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc_train = pd.read_csv(f'{path}/rcc_train.csv')\n",
    "rcc_test = pd.read_csv(f'{path}/rcc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informed-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### inputar datos faltantes en la base de rcc_test\n",
    "rcc_test['cod_instit_financiera'].fillna(rcc_test['cod_instit_financiera'].value_counts().index[0], inplace=True)\n",
    "rcc_test['PRODUCTO'].fillna(rcc_test['PRODUCTO'].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "funky-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'codmes': 'int32',\n",
    " 'key_value': 'int32',\n",
    " 'condicion': 'int32',\n",
    " 'tipo_credito': 'int32',\n",
    " 'cod_instit_financiera': 'int32',\n",
    " 'PRODUCTO': 'int32',\n",
    " 'RIESGO_DIRECTO': 'int32',\n",
    " 'COD_CLASIFICACION_DEUDOR': 'int32'}\n",
    "rcc_train = rcc_train.astype(dict_)\n",
    "rcc_test = rcc_test.astype(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "norwegian-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### categorizar la variable condicion\n",
    "bins = [-1, 0, 10, 20, 30, 60, 90, 180, 360, 720, float(\"inf\")]\n",
    "rcc_train[\"condicion\"] = pd.cut(rcc_train.condicion, bins)\n",
    "rcc_train[\"condicion\"] = rcc_train[\"condicion\"].cat.codes\n",
    "rcc_test[\"condicion\"] = pd.cut(rcc_test.condicion, bins)\n",
    "rcc_test[\"condicion\"] = rcc_test[\"condicion\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organized-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "### definir las variables que seran agregadas\n",
    "moda=lambda x: calculate_mode(x)\n",
    "moda.__name__='mode'\n",
    "agg_rcc = {'cod_instit_financiera':['nunique','min','max',moda],\n",
    "           'PRODUCTO':['nunique','min','max',moda],}\n",
    "def get_aggregate(df, desde,n):\n",
    "    print(f'haciendo aggregate de cod_instit_financiera y Producto desde {desde}')\n",
    "    df_result = df[df.codmes>=desde].groupby('key_value').agg(agg_rcc)\n",
    "    df_result.columns = [feature+'_'+agg+f'_ult{n+1}mes' for feature, agg in df_result.columns]    \n",
    "    gc.collect()  \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "korean-village",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201802 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201802 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201802 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201802 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201802\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201801 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201801 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201801 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201801 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201801\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201712 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201712 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201712 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201712 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201712\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201711 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de RIESGO_DIRECTO desde 201711 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201711 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201711 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201711\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201710 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201710 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201710 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201710 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201710\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201709 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201709 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201709 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201709 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201709\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201708 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201708 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201708 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201708 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201708\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201707 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201707 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201707 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201707 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201707\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201706 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201706 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201706 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201706 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201706\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201705 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201705 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201705 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201705 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201705\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201704 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201704 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201704 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201704 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201704\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201703 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201703 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201703 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201703 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201703\n"
     ]
    }
   ],
   "source": [
    "rcc_train_list=[]\n",
    "for n,desde in enumerate(sorted(set(rcc_train.codmes),reverse=True)):\n",
    "    for feature in ['tipo_credito','RIESGO_DIRECTO','COD_CLASIFICACION_DEUDOR','condicion']:\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Sum'))\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Unique'))\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Min'))\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Max'))\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Std'))\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Mean'))\n",
    "        rcc_train_list.append(get_unstack(rcc_train, feature, desde, n, 'Median'))\n",
    "    rcc_train_list.append(get_aggregate(rcc_train, desde,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "packed-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc_train = pd.concat(rcc_train_list, axis=1)\n",
    "del rcc_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quiet-synthetic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201902 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201902 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201902 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201902 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201902\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201901 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201901 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201901 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201901 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201901\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201812 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201812 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201812 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201812 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201812\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201811 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de RIESGO_DIRECTO desde 201811 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201811 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201811 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201811\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201810 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201810 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201810 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201810 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201810\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201809 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201809 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201809 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201809 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201809\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201808 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201808 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201808 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201808 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201808\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201807 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201807 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201807 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201807 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201807\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201806 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201806 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201806 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201806 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201806\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201805 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201805 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201805 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201805 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201805\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201804 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201804 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201804 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201804 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201804\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Sum\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Unique\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Min\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Max\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Std\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Mean\n",
      "haciendo unstack de tipo_credito desde 201803 con la funcion de agregacion Median\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Sum\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Unique\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Min\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Max\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Std\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Mean\n",
      "haciendo unstack de RIESGO_DIRECTO desde 201803 con la funcion de agregacion Median\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Sum\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Unique\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Min\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Max\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Std\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Mean\n",
      "haciendo unstack de COD_CLASIFICACION_DEUDOR desde 201803 con la funcion de agregacion Median\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Sum\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Unique\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Min\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Max\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Std\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Mean\n",
      "haciendo unstack de condicion desde 201803 con la funcion de agregacion Median\n",
      "haciendo aggregate de cod_instit_financiera y Producto desde 201803\n"
     ]
    }
   ],
   "source": [
    "rcc_test_list=[]\n",
    "for n,desde in enumerate(sorted(set(rcc_test.codmes),reverse=True)):\n",
    "    for feature in ['tipo_credito','RIESGO_DIRECTO','COD_CLASIFICACION_DEUDOR','condicion']:\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Sum'))\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Unique'))\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Min'))\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Max'))\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Std'))\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Mean'))\n",
    "        rcc_test_list.append(get_unstack(rcc_test, feature, desde, n, 'Median'))\n",
    "    rcc_test_list.append(get_aggregate(rcc_test, desde,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "great-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc_test = pd.concat(rcc_test_list, axis=1)\n",
    "del rcc_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "entire-andrews",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358487, 2532) (396666, 2616)\n",
      "(358487, 2532) (396666, 2532)\n"
     ]
    }
   ],
   "source": [
    "rcc_train, rcc_test = get_keep_columns(rcc_train, rcc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cross-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "### unir RCC en la base final\n",
    "train = rcc_train\n",
    "test = rcc_test\n",
    "del rcc_train, rcc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stopped-olive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838761\ttraining's binary_logloss: 0.30485\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.310894\n",
      "[100]\ttraining's auc: 0.851395\ttraining's binary_logloss: 0.295446\tvalid_1's auc: 0.837102\tvalid_1's binary_logloss: 0.30602\n",
      "[150]\ttraining's auc: 0.859498\ttraining's binary_logloss: 0.289473\tvalid_1's auc: 0.83939\tvalid_1's binary_logloss: 0.304297\n",
      "[200]\ttraining's auc: 0.8658\ttraining's binary_logloss: 0.284764\tvalid_1's auc: 0.840575\tvalid_1's binary_logloss: 0.303488\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's auc: 0.868473\ttraining's binary_logloss: 0.282752\tvalid_1's auc: 0.84075\tvalid_1's binary_logloss: 0.303343\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.8384\ttraining's binary_logloss: 0.30498\tvalid_1's auc: 0.829638\tvalid_1's binary_logloss: 0.31107\n",
      "[100]\ttraining's auc: 0.851342\ttraining's binary_logloss: 0.295405\tvalid_1's auc: 0.836875\tvalid_1's binary_logloss: 0.305864\n",
      "[150]\ttraining's auc: 0.859372\ttraining's binary_logloss: 0.289495\tvalid_1's auc: 0.83894\tvalid_1's binary_logloss: 0.304285\n",
      "[200]\ttraining's auc: 0.865639\ttraining's binary_logloss: 0.284775\tvalid_1's auc: 0.839589\tvalid_1's binary_logloss: 0.30367\n",
      "[250]\ttraining's auc: 0.871017\ttraining's binary_logloss: 0.280714\tvalid_1's auc: 0.840133\tvalid_1's binary_logloss: 0.303314\n",
      "Early stopping, best iteration is:\n",
      "[273]\ttraining's auc: 0.873368\ttraining's binary_logloss: 0.278945\tvalid_1's auc: 0.840295\tvalid_1's binary_logloss: 0.303209\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.83813\ttraining's binary_logloss: 0.305452\tvalid_1's auc: 0.833161\tvalid_1's binary_logloss: 0.308845\n",
      "[100]\ttraining's auc: 0.850721\ttraining's binary_logloss: 0.296013\tvalid_1's auc: 0.839065\tvalid_1's binary_logloss: 0.303887\n",
      "[150]\ttraining's auc: 0.85876\ttraining's binary_logloss: 0.290227\tvalid_1's auc: 0.840874\tvalid_1's binary_logloss: 0.302232\n",
      "[200]\ttraining's auc: 0.864757\ttraining's binary_logloss: 0.285665\tvalid_1's auc: 0.841766\tvalid_1's binary_logloss: 0.301452\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's auc: 0.868881\ttraining's binary_logloss: 0.282691\tvalid_1's auc: 0.842254\tvalid_1's binary_logloss: 0.301091\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838498\ttraining's binary_logloss: 0.305334\tvalid_1's auc: 0.83173\tvalid_1's binary_logloss: 0.30936\n",
      "[100]\ttraining's auc: 0.851328\ttraining's binary_logloss: 0.295888\tvalid_1's auc: 0.83767\tvalid_1's binary_logloss: 0.304534\n",
      "[150]\ttraining's auc: 0.859379\ttraining's binary_logloss: 0.290026\tvalid_1's auc: 0.839486\tvalid_1's binary_logloss: 0.3029\n",
      "[200]\ttraining's auc: 0.865553\ttraining's binary_logloss: 0.285357\tvalid_1's auc: 0.840375\tvalid_1's binary_logloss: 0.302103\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's auc: 0.869109\ttraining's binary_logloss: 0.282712\tvalid_1's auc: 0.840553\tvalid_1's binary_logloss: 0.301836\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.839982\ttraining's binary_logloss: 0.304752\tvalid_1's auc: 0.82548\tvalid_1's binary_logloss: 0.310985\n",
      "[100]\ttraining's auc: 0.853102\ttraining's binary_logloss: 0.295004\tvalid_1's auc: 0.83161\tvalid_1's binary_logloss: 0.306571\n",
      "[150]\ttraining's auc: 0.861086\ttraining's binary_logloss: 0.289084\tvalid_1's auc: 0.833404\tvalid_1's binary_logloss: 0.305241\n",
      "[200]\ttraining's auc: 0.867321\ttraining's binary_logloss: 0.284348\tvalid_1's auc: 0.834017\tvalid_1's binary_logloss: 0.304678\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's auc: 0.868547\ttraining's binary_logloss: 0.283455\tvalid_1's auc: 0.834142\tvalid_1's binary_logloss: 0.304592\n",
      "*********************\n",
      "roc auc estimado:  0.8396256259184243\n",
      "roc auc varianza:  0.0006892940731700594\n",
      "total de variables : 2532\n",
      "variables con importancia acumulada al 99% : 1459\n",
      "variables con zero importancia : 798\n",
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838473\ttraining's binary_logloss: 0.304884\tvalid_1's auc: 0.829481\tvalid_1's binary_logloss: 0.311346\n",
      "[100]\ttraining's auc: 0.85112\ttraining's binary_logloss: 0.295551\tvalid_1's auc: 0.83608\tvalid_1's binary_logloss: 0.306475\n",
      "[150]\ttraining's auc: 0.858924\ttraining's binary_logloss: 0.289755\tvalid_1's auc: 0.838258\tvalid_1's binary_logloss: 0.304911\n",
      "[200]\ttraining's auc: 0.865453\ttraining's binary_logloss: 0.284973\tvalid_1's auc: 0.839366\tvalid_1's binary_logloss: 0.304151\n",
      "[250]\ttraining's auc: 0.870864\ttraining's binary_logloss: 0.280845\tvalid_1's auc: 0.840002\tvalid_1's binary_logloss: 0.303728\n",
      "[300]\ttraining's auc: 0.875804\ttraining's binary_logloss: 0.277048\tvalid_1's auc: 0.840527\tvalid_1's binary_logloss: 0.303375\n",
      "Early stopping, best iteration is:\n",
      "[327]\ttraining's auc: 0.87831\ttraining's binary_logloss: 0.275125\tvalid_1's auc: 0.840732\tvalid_1's binary_logloss: 0.303295\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838433\ttraining's binary_logloss: 0.304935\tvalid_1's auc: 0.829629\tvalid_1's binary_logloss: 0.31115\n",
      "[100]\ttraining's auc: 0.851229\ttraining's binary_logloss: 0.295448\tvalid_1's auc: 0.836472\tvalid_1's binary_logloss: 0.30603\n",
      "[150]\ttraining's auc: 0.859488\ttraining's binary_logloss: 0.289581\tvalid_1's auc: 0.838557\tvalid_1's binary_logloss: 0.304519\n",
      "[200]\ttraining's auc: 0.865873\ttraining's binary_logloss: 0.284833\tvalid_1's auc: 0.839443\tvalid_1's binary_logloss: 0.303845\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's auc: 0.869303\ttraining's binary_logloss: 0.282222\tvalid_1's auc: 0.839941\tvalid_1's binary_logloss: 0.30349\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838349\ttraining's binary_logloss: 0.305247\tvalid_1's auc: 0.833107\tvalid_1's binary_logloss: 0.308922\n",
      "[100]\ttraining's auc: 0.850848\ttraining's binary_logloss: 0.295867\tvalid_1's auc: 0.839135\tvalid_1's binary_logloss: 0.303943\n",
      "[150]\ttraining's auc: 0.858915\ttraining's binary_logloss: 0.290019\tvalid_1's auc: 0.840988\tvalid_1's binary_logloss: 0.302264\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's auc: 0.861185\ttraining's binary_logloss: 0.28837\tvalid_1's auc: 0.841372\tvalid_1's binary_logloss: 0.301955\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.83869\ttraining's binary_logloss: 0.305371\tvalid_1's auc: 0.831651\tvalid_1's binary_logloss: 0.309518\n",
      "[100]\ttraining's auc: 0.851438\ttraining's binary_logloss: 0.295889\tvalid_1's auc: 0.837662\tvalid_1's binary_logloss: 0.30461\n",
      "[150]\ttraining's auc: 0.859369\ttraining's binary_logloss: 0.290046\tvalid_1's auc: 0.839629\tvalid_1's binary_logloss: 0.30287\n",
      "[200]\ttraining's auc: 0.865974\ttraining's binary_logloss: 0.28513\tvalid_1's auc: 0.84034\tvalid_1's binary_logloss: 0.302169\n",
      "[250]\ttraining's auc: 0.871349\ttraining's binary_logloss: 0.281036\tvalid_1's auc: 0.840952\tvalid_1's binary_logloss: 0.301602\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's auc: 0.872059\ttraining's binary_logloss: 0.280489\tvalid_1's auc: 0.840977\tvalid_1's binary_logloss: 0.301594\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.840243\ttraining's binary_logloss: 0.30468\tvalid_1's auc: 0.825138\tvalid_1's binary_logloss: 0.311104\n",
      "[100]\ttraining's auc: 0.852963\ttraining's binary_logloss: 0.294941\tvalid_1's auc: 0.831179\tvalid_1's binary_logloss: 0.306479\n",
      "[150]\ttraining's auc: 0.860829\ttraining's binary_logloss: 0.289102\tvalid_1's auc: 0.832874\tvalid_1's binary_logloss: 0.305195\n",
      "[200]\ttraining's auc: 0.867455\ttraining's binary_logloss: 0.284275\tvalid_1's auc: 0.833568\tvalid_1's binary_logloss: 0.30459\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's auc: 0.86948\ttraining's binary_logloss: 0.282811\tvalid_1's auc: 0.833836\tvalid_1's binary_logloss: 0.304369\n",
      "*********************\n",
      "roc auc estimado:  0.8393800598275646\n",
      "roc auc varianza:  0.0006829157564354514\n",
      "total de variables : 1459\n",
      "variables con importancia acumulada al 99% : 1314\n",
      "variables con zero importancia : 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.83848\ttraining's binary_logloss: 0.30496\tvalid_1's auc: 0.830072\tvalid_1's binary_logloss: 0.311206\n",
      "[100]\ttraining's auc: 0.851438\ttraining's binary_logloss: 0.295314\tvalid_1's auc: 0.837142\tvalid_1's binary_logloss: 0.30594\n",
      "[150]\ttraining's auc: 0.859383\ttraining's binary_logloss: 0.289503\tvalid_1's auc: 0.839533\tvalid_1's binary_logloss: 0.304208\n",
      "[200]\ttraining's auc: 0.865539\ttraining's binary_logloss: 0.284822\tvalid_1's auc: 0.8405\tvalid_1's binary_logloss: 0.303507\n",
      "[250]\ttraining's auc: 0.871157\ttraining's binary_logloss: 0.280609\tvalid_1's auc: 0.841084\tvalid_1's binary_logloss: 0.303146\n",
      "Early stopping, best iteration is:\n",
      "[245]\ttraining's auc: 0.870715\ttraining's binary_logloss: 0.280983\tvalid_1's auc: 0.841082\tvalid_1's binary_logloss: 0.303127\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838422\ttraining's binary_logloss: 0.304985\tvalid_1's auc: 0.829796\tvalid_1's binary_logloss: 0.311189\n",
      "[100]\ttraining's auc: 0.851236\ttraining's binary_logloss: 0.295426\tvalid_1's auc: 0.836229\tvalid_1's binary_logloss: 0.30619\n",
      "[150]\ttraining's auc: 0.859467\ttraining's binary_logloss: 0.289405\tvalid_1's auc: 0.838585\tvalid_1's binary_logloss: 0.304515\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's auc: 0.863876\ttraining's binary_logloss: 0.286074\tvalid_1's auc: 0.839113\tvalid_1's binary_logloss: 0.303991\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838355\ttraining's binary_logloss: 0.305265\tvalid_1's auc: 0.833631\tvalid_1's binary_logloss: 0.308604\n",
      "[100]\ttraining's auc: 0.851075\ttraining's binary_logloss: 0.295819\tvalid_1's auc: 0.839453\tvalid_1's binary_logloss: 0.303679\n",
      "[150]\ttraining's auc: 0.858971\ttraining's binary_logloss: 0.290032\tvalid_1's auc: 0.841087\tvalid_1's binary_logloss: 0.302121\n",
      "[200]\ttraining's auc: 0.865593\ttraining's binary_logloss: 0.285287\tvalid_1's auc: 0.841778\tvalid_1's binary_logloss: 0.301381\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's auc: 0.869774\ttraining's binary_logloss: 0.282124\tvalid_1's auc: 0.841994\tvalid_1's binary_logloss: 0.301107\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838565\ttraining's binary_logloss: 0.305327\tvalid_1's auc: 0.831537\tvalid_1's binary_logloss: 0.309447\n",
      "[100]\ttraining's auc: 0.851241\ttraining's binary_logloss: 0.295969\tvalid_1's auc: 0.837635\tvalid_1's binary_logloss: 0.304603\n",
      "[150]\ttraining's auc: 0.859113\ttraining's binary_logloss: 0.290141\tvalid_1's auc: 0.839465\tvalid_1's binary_logloss: 0.302972\n",
      "[200]\ttraining's auc: 0.865382\ttraining's binary_logloss: 0.285441\tvalid_1's auc: 0.840178\tvalid_1's binary_logloss: 0.302231\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's auc: 0.865256\ttraining's binary_logloss: 0.285531\tvalid_1's auc: 0.840217\tvalid_1's binary_logloss: 0.302224\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.839994\ttraining's binary_logloss: 0.304811\tvalid_1's auc: 0.824977\tvalid_1's binary_logloss: 0.311206\n",
      "[100]\ttraining's auc: 0.853019\ttraining's binary_logloss: 0.294993\tvalid_1's auc: 0.831285\tvalid_1's binary_logloss: 0.306613\n",
      "[150]\ttraining's auc: 0.861\ttraining's binary_logloss: 0.28904\tvalid_1's auc: 0.833242\tvalid_1's binary_logloss: 0.305133\n",
      "[200]\ttraining's auc: 0.867214\ttraining's binary_logloss: 0.284363\tvalid_1's auc: 0.833913\tvalid_1's binary_logloss: 0.304533\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's auc: 0.870407\ttraining's binary_logloss: 0.281944\tvalid_1's auc: 0.834268\tvalid_1's binary_logloss: 0.304271\n",
      "*********************\n",
      "roc auc estimado:  0.8393581188747835\n",
      "roc auc varianza:  0.0006662303852742272\n",
      "total de variables : 1314\n",
      "variables con importancia acumulada al 99% : 1203\n",
      "variables con zero importancia : 3\n",
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838332\ttraining's binary_logloss: 0.304991\tvalid_1's auc: 0.829921\tvalid_1's binary_logloss: 0.311151\n",
      "[100]\ttraining's auc: 0.851397\ttraining's binary_logloss: 0.295384\tvalid_1's auc: 0.836447\tvalid_1's binary_logloss: 0.306183\n",
      "[150]\ttraining's auc: 0.859444\ttraining's binary_logloss: 0.289522\tvalid_1's auc: 0.838576\tvalid_1's binary_logloss: 0.304603\n",
      "[200]\ttraining's auc: 0.865827\ttraining's binary_logloss: 0.284838\tvalid_1's auc: 0.839727\tvalid_1's binary_logloss: 0.303886\n",
      "[250]\ttraining's auc: 0.871371\ttraining's binary_logloss: 0.280631\tvalid_1's auc: 0.840238\tvalid_1's binary_logloss: 0.303569\n",
      "Early stopping, best iteration is:\n",
      "[274]\ttraining's auc: 0.873673\ttraining's binary_logloss: 0.278788\tvalid_1's auc: 0.840544\tvalid_1's binary_logloss: 0.30335\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838406\ttraining's binary_logloss: 0.304973\tvalid_1's auc: 0.829843\tvalid_1's binary_logloss: 0.311105\n",
      "[100]\ttraining's auc: 0.851335\ttraining's binary_logloss: 0.295447\tvalid_1's auc: 0.836434\tvalid_1's binary_logloss: 0.306171\n",
      "[150]\ttraining's auc: 0.859134\ttraining's binary_logloss: 0.289621\tvalid_1's auc: 0.838267\tvalid_1's binary_logloss: 0.304646\n",
      "[200]\ttraining's auc: 0.865467\ttraining's binary_logloss: 0.284933\tvalid_1's auc: 0.839546\tvalid_1's binary_logloss: 0.303715\n",
      "[250]\ttraining's auc: 0.870968\ttraining's binary_logloss: 0.280825\tvalid_1's auc: 0.839931\tvalid_1's binary_logloss: 0.303384\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's auc: 0.870048\ttraining's binary_logloss: 0.281519\tvalid_1's auc: 0.839978\tvalid_1's binary_logloss: 0.303368\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838308\ttraining's binary_logloss: 0.305275\tvalid_1's auc: 0.833138\tvalid_1's binary_logloss: 0.308876\n",
      "[100]\ttraining's auc: 0.851014\ttraining's binary_logloss: 0.29589\tvalid_1's auc: 0.839221\tvalid_1's binary_logloss: 0.303773\n",
      "[150]\ttraining's auc: 0.859118\ttraining's binary_logloss: 0.290064\tvalid_1's auc: 0.840664\tvalid_1's binary_logloss: 0.302346\n",
      "[200]\ttraining's auc: 0.865293\ttraining's binary_logloss: 0.285454\tvalid_1's auc: 0.841266\tvalid_1's binary_logloss: 0.301682\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's auc: 0.868481\ttraining's binary_logloss: 0.283101\tvalid_1's auc: 0.841615\tvalid_1's binary_logloss: 0.301387\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838288\ttraining's binary_logloss: 0.305401\tvalid_1's auc: 0.831161\tvalid_1's binary_logloss: 0.309536\n",
      "[100]\ttraining's auc: 0.851327\ttraining's binary_logloss: 0.295896\tvalid_1's auc: 0.837729\tvalid_1's binary_logloss: 0.304485\n",
      "[150]\ttraining's auc: 0.859138\ttraining's binary_logloss: 0.290055\tvalid_1's auc: 0.839268\tvalid_1's binary_logloss: 0.302901\n",
      "[200]\ttraining's auc: 0.865811\ttraining's binary_logloss: 0.285321\tvalid_1's auc: 0.840007\tvalid_1's binary_logloss: 0.302268\n",
      "[250]\ttraining's auc: 0.871243\ttraining's binary_logloss: 0.281179\tvalid_1's auc: 0.840573\tvalid_1's binary_logloss: 0.301788\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's auc: 0.871811\ttraining's binary_logloss: 0.280751\tvalid_1's auc: 0.840681\tvalid_1's binary_logloss: 0.301721\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.83974\ttraining's binary_logloss: 0.304871\tvalid_1's auc: 0.824908\tvalid_1's binary_logloss: 0.311118\n",
      "[100]\ttraining's auc: 0.852793\ttraining's binary_logloss: 0.295102\tvalid_1's auc: 0.831035\tvalid_1's binary_logloss: 0.306572\n",
      "[150]\ttraining's auc: 0.860761\ttraining's binary_logloss: 0.289248\tvalid_1's auc: 0.83282\tvalid_1's binary_logloss: 0.305206\n",
      "[200]\ttraining's auc: 0.867277\ttraining's binary_logloss: 0.284432\tvalid_1's auc: 0.833711\tvalid_1's binary_logloss: 0.304547\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's auc: 0.867383\ttraining's binary_logloss: 0.284353\tvalid_1's auc: 0.833724\tvalid_1's binary_logloss: 0.304538\n",
      "*********************\n",
      "roc auc estimado:  0.839333312978189\n",
      "roc auc varianza:  0.0006937013744489198\n",
      "total de variables : 1203\n",
      "variables con importancia acumulada al 99% : 1131\n",
      "variables con zero importancia : 0\n"
     ]
    }
   ],
   "source": [
    "# eliminar variables con zero_importance\n",
    "while True:\n",
    "    test_probs, fi = cross_validation_lightgbm(train, y_train, test)\n",
    "    keep_columns, zero_importance = get_feature_selection(fi)\n",
    "    train = train[keep_columns]\n",
    "    test = test[keep_columns]\n",
    "    if len(zero_importance)==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "spiritual-indication",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838651\ttraining's binary_logloss: 0.304825\tvalid_1's auc: 0.83027\tvalid_1's binary_logloss: 0.310967\n",
      "[100]\ttraining's auc: 0.851202\ttraining's binary_logloss: 0.295509\tvalid_1's auc: 0.836648\tvalid_1's binary_logloss: 0.306163\n",
      "[150]\ttraining's auc: 0.859045\ttraining's binary_logloss: 0.289746\tvalid_1's auc: 0.839037\tvalid_1's binary_logloss: 0.304394\n",
      "[200]\ttraining's auc: 0.865655\ttraining's binary_logloss: 0.284863\tvalid_1's auc: 0.84009\tvalid_1's binary_logloss: 0.303597\n",
      "[250]\ttraining's auc: 0.871143\ttraining's binary_logloss: 0.280685\tvalid_1's auc: 0.840614\tvalid_1's binary_logloss: 0.303281\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's auc: 0.870581\ttraining's binary_logloss: 0.281146\tvalid_1's auc: 0.840623\tvalid_1's binary_logloss: 0.303267\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838819\ttraining's binary_logloss: 0.304788\tvalid_1's auc: 0.830154\tvalid_1's binary_logloss: 0.311124\n",
      "[100]\ttraining's auc: 0.851514\ttraining's binary_logloss: 0.295304\tvalid_1's auc: 0.836602\tvalid_1's binary_logloss: 0.306194\n",
      "[150]\ttraining's auc: 0.859295\ttraining's binary_logloss: 0.289421\tvalid_1's auc: 0.838604\tvalid_1's binary_logloss: 0.304567\n",
      "[200]\ttraining's auc: 0.865629\ttraining's binary_logloss: 0.28476\tvalid_1's auc: 0.839483\tvalid_1's binary_logloss: 0.303748\n",
      "[250]\ttraining's auc: 0.871238\ttraining's binary_logloss: 0.280531\tvalid_1's auc: 0.840149\tvalid_1's binary_logloss: 0.303345\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's auc: 0.872432\ttraining's binary_logloss: 0.279609\tvalid_1's auc: 0.840255\tvalid_1's binary_logloss: 0.303259\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838599\ttraining's binary_logloss: 0.305128\tvalid_1's auc: 0.833192\tvalid_1's binary_logloss: 0.30886\n",
      "[100]\ttraining's auc: 0.851415\ttraining's binary_logloss: 0.295667\tvalid_1's auc: 0.839387\tvalid_1's binary_logloss: 0.303801\n",
      "[150]\ttraining's auc: 0.859268\ttraining's binary_logloss: 0.28995\tvalid_1's auc: 0.840946\tvalid_1's binary_logloss: 0.302193\n",
      "[200]\ttraining's auc: 0.865611\ttraining's binary_logloss: 0.285351\tvalid_1's auc: 0.841736\tvalid_1's binary_logloss: 0.301455\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's auc: 0.864403\ttraining's binary_logloss: 0.286203\tvalid_1's auc: 0.84179\tvalid_1's binary_logloss: 0.301504\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838847\ttraining's binary_logloss: 0.305336\tvalid_1's auc: 0.831869\tvalid_1's binary_logloss: 0.309329\n",
      "[100]\ttraining's auc: 0.851368\ttraining's binary_logloss: 0.29595\tvalid_1's auc: 0.837799\tvalid_1's binary_logloss: 0.304332\n",
      "[150]\ttraining's auc: 0.859329\ttraining's binary_logloss: 0.290077\tvalid_1's auc: 0.83984\tvalid_1's binary_logloss: 0.302641\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's auc: 0.862199\ttraining's binary_logloss: 0.287985\tvalid_1's auc: 0.840292\tvalid_1's binary_logloss: 0.302237\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.83989\ttraining's binary_logloss: 0.304821\tvalid_1's auc: 0.82551\tvalid_1's binary_logloss: 0.310834\n",
      "[100]\ttraining's auc: 0.852868\ttraining's binary_logloss: 0.295095\tvalid_1's auc: 0.831492\tvalid_1's binary_logloss: 0.306403\n",
      "[150]\ttraining's auc: 0.860985\ttraining's binary_logloss: 0.289121\tvalid_1's auc: 0.833654\tvalid_1's binary_logloss: 0.304907\n",
      "[200]\ttraining's auc: 0.867272\ttraining's binary_logloss: 0.284428\tvalid_1's auc: 0.834437\tvalid_1's binary_logloss: 0.304293\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's auc: 0.867677\ttraining's binary_logloss: 0.28406\tvalid_1's auc: 0.834561\tvalid_1's binary_logloss: 0.304172\n",
      "*********************\n",
      "roc auc estimado:  0.8395185424641647\n",
      "roc auc varianza:  0.0006217131686264802\n"
     ]
    }
   ],
   "source": [
    "test_probs, fi = cross_validation_lightgbm(train, y_train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "induced-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de variables : 1131\n",
      "variables con importancia acumulada al 99% : 1063\n",
      "variables con zero importancia : 1\n"
     ]
    }
   ],
   "source": [
    "keep_columns_, zero_importance_ = get_feature_selection(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "defensive-ending",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838634\ttraining's binary_logloss: 0.304902\tvalid_1's auc: 0.830899\tvalid_1's binary_logloss: 0.31089\n",
      "[100]\ttraining's auc: 0.851427\ttraining's binary_logloss: 0.29545\tvalid_1's auc: 0.837155\tvalid_1's binary_logloss: 0.305996\n",
      "[150]\ttraining's auc: 0.859332\ttraining's binary_logloss: 0.289615\tvalid_1's auc: 0.839297\tvalid_1's binary_logloss: 0.304372\n",
      "[200]\ttraining's auc: 0.865726\ttraining's binary_logloss: 0.28498\tvalid_1's auc: 0.840176\tvalid_1's binary_logloss: 0.303716\n",
      "[250]\ttraining's auc: 0.871426\ttraining's binary_logloss: 0.280663\tvalid_1's auc: 0.840845\tvalid_1's binary_logloss: 0.303241\n",
      "Early stopping, best iteration is:\n",
      "[276]\ttraining's auc: 0.874015\ttraining's binary_logloss: 0.27869\tvalid_1's auc: 0.841115\tvalid_1's binary_logloss: 0.303115\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838459\ttraining's binary_logloss: 0.304879\tvalid_1's auc: 0.829254\tvalid_1's binary_logloss: 0.311286\n",
      "[100]\ttraining's auc: 0.851248\ttraining's binary_logloss: 0.295376\tvalid_1's auc: 0.836476\tvalid_1's binary_logloss: 0.306023\n",
      "[150]\ttraining's auc: 0.859085\ttraining's binary_logloss: 0.28959\tvalid_1's auc: 0.838662\tvalid_1's binary_logloss: 0.304344\n",
      "[200]\ttraining's auc: 0.865351\ttraining's binary_logloss: 0.284978\tvalid_1's auc: 0.839479\tvalid_1's binary_logloss: 0.303653\n",
      "[250]\ttraining's auc: 0.870922\ttraining's binary_logloss: 0.280742\tvalid_1's auc: 0.840024\tvalid_1's binary_logloss: 0.303217\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttraining's auc: 0.871229\ttraining's binary_logloss: 0.280519\tvalid_1's auc: 0.840105\tvalid_1's binary_logloss: 0.303182\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838517\ttraining's binary_logloss: 0.305277\tvalid_1's auc: 0.833366\tvalid_1's binary_logloss: 0.308868\n",
      "[100]\ttraining's auc: 0.851133\ttraining's binary_logloss: 0.295884\tvalid_1's auc: 0.839149\tvalid_1's binary_logloss: 0.303974\n",
      "[150]\ttraining's auc: 0.859109\ttraining's binary_logloss: 0.290115\tvalid_1's auc: 0.841061\tvalid_1's binary_logloss: 0.302252\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's auc: 0.862712\ttraining's binary_logloss: 0.287447\tvalid_1's auc: 0.841485\tvalid_1's binary_logloss: 0.301889\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.838757\ttraining's binary_logloss: 0.305326\tvalid_1's auc: 0.831431\tvalid_1's binary_logloss: 0.309425\n",
      "[100]\ttraining's auc: 0.85139\ttraining's binary_logloss: 0.295895\tvalid_1's auc: 0.837964\tvalid_1's binary_logloss: 0.304308\n",
      "[150]\ttraining's auc: 0.859155\ttraining's binary_logloss: 0.290124\tvalid_1's auc: 0.839789\tvalid_1's binary_logloss: 0.302676\n",
      "[200]\ttraining's auc: 0.86548\ttraining's binary_logloss: 0.285428\tvalid_1's auc: 0.840684\tvalid_1's binary_logloss: 0.301884\n",
      "[250]\ttraining's auc: 0.871139\ttraining's binary_logloss: 0.281239\tvalid_1's auc: 0.841225\tvalid_1's binary_logloss: 0.301453\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's auc: 0.87235\ttraining's binary_logloss: 0.280333\tvalid_1's auc: 0.841333\tvalid_1's binary_logloss: 0.301324\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.839899\ttraining's binary_logloss: 0.304817\tvalid_1's auc: 0.824986\tvalid_1's binary_logloss: 0.311244\n",
      "[100]\ttraining's auc: 0.852826\ttraining's binary_logloss: 0.295101\tvalid_1's auc: 0.831502\tvalid_1's binary_logloss: 0.306583\n",
      "[150]\ttraining's auc: 0.860818\ttraining's binary_logloss: 0.289158\tvalid_1's auc: 0.833136\tvalid_1's binary_logloss: 0.305172\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's auc: 0.865591\ttraining's binary_logloss: 0.285609\tvalid_1's auc: 0.833904\tvalid_1's binary_logloss: 0.30462\n",
      "*********************\n",
      "roc auc estimado:  0.839609653403813\n",
      "roc auc varianza:  0.0007023405473105417\n"
     ]
    }
   ],
   "source": [
    "test_probs_, fi_ = cross_validation_lightgbm(train[keep_columns_], y_train, test[keep_columns_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "guided-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de variables : 1063\n",
      "variables con importancia acumulada al 99% : 1011\n",
      "variables con zero importancia : 0\n"
     ]
    }
   ],
   "source": [
    "keep_columns__, zero_importance__ = get_feature_selection(fi_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "verbal-string",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1063), (396666, 1063))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[keep_columns_]\n",
    "test = test[keep_columns_]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "super-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_pickle('train_1063features.pkl')\n",
    "# test.to_pickle('test_1063features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "concrete-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train_1063features.pkl')\n",
    "test = pd.read_pickle('test_1063features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-technology",
   "metadata": {},
   "source": [
    "## Procesar SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "czech-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_train = pd.read_csv(f'{path}/se_train.csv', index_col = 'key_value')\n",
    "se_test = pd.read_csv(f'{path}/se_test.csv', index_col = 'key_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "small-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'sexo':'int32',\n",
    "         'est_cvl':'int32',\n",
    "         'sit_lab':'int32',\n",
    "         'cod_ocu':'int32',\n",
    "         'ctd_hijos':'int32',\n",
    "         'flg_sin_email':'int32',\n",
    "         'ctd_veh':'int32',\n",
    "         'lgr_vot':'int32',\n",
    "         'prv':'int32',\n",
    "         'dto':'int32',\n",
    "         'rgn':'int32',\n",
    "         'tip_lvledu':'int32'}\n",
    "se_train = se_train.astype(dict_)\n",
    "se_test = se_test.astype(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "universal-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(df, feature):\n",
    "    one_hot = pd.get_dummies(df[feature])\n",
    "    one_hot.columns = [feature+'_'+str(i) for i in one_hot.columns]\n",
    "    return one_hot\n",
    "one_hot_sexo_train = get_one_hot(se_train, 'sexo')\n",
    "one_hot_sexo_test = get_one_hot(se_test, 'sexo')\n",
    "one_hot_est_cvl_train = get_one_hot(se_train, 'est_cvl')\n",
    "one_hot_est_cvl_test = get_one_hot(se_test, 'est_cvl')\n",
    "one_hot_rgn_train = get_one_hot(se_train, 'rgn')\n",
    "one_hot_rgn_test = get_one_hot(se_test, 'rgn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "japanese-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(one_hot_sexo_train).join(one_hot_est_cvl_train).join(one_hot_rgn_train).join(se_train[['edad','ctd_veh']])\n",
    "test = test.join(one_hot_sexo_test).join(one_hot_est_cvl_test).join(one_hot_rgn_test).join(se_test[['edad','ctd_veh']])\n",
    "del se_train, se_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fifty-angel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.841931\ttraining's binary_logloss: 0.303466\tvalid_1's auc: 0.833694\tvalid_1's binary_logloss: 0.309563\n",
      "[100]\ttraining's auc: 0.855324\ttraining's binary_logloss: 0.293082\tvalid_1's auc: 0.840938\tvalid_1's binary_logloss: 0.303873\n",
      "[150]\ttraining's auc: 0.863482\ttraining's binary_logloss: 0.286824\tvalid_1's auc: 0.843654\tvalid_1's binary_logloss: 0.301808\n",
      "[200]\ttraining's auc: 0.869764\ttraining's binary_logloss: 0.282013\tvalid_1's auc: 0.844838\tvalid_1's binary_logloss: 0.300875\n",
      "[250]\ttraining's auc: 0.875494\ttraining's binary_logloss: 0.277675\tvalid_1's auc: 0.845456\tvalid_1's binary_logloss: 0.300431\n",
      "[300]\ttraining's auc: 0.880259\ttraining's binary_logloss: 0.273846\tvalid_1's auc: 0.845815\tvalid_1's binary_logloss: 0.300167\n",
      "Early stopping, best iteration is:\n",
      "[315]\ttraining's auc: 0.881755\ttraining's binary_logloss: 0.272682\tvalid_1's auc: 0.845894\tvalid_1's binary_logloss: 0.300122\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.842042\ttraining's binary_logloss: 0.303497\tvalid_1's auc: 0.833239\tvalid_1's binary_logloss: 0.309862\n",
      "[100]\ttraining's auc: 0.855479\ttraining's binary_logloss: 0.292997\tvalid_1's auc: 0.840787\tvalid_1's binary_logloss: 0.304015\n",
      "[150]\ttraining's auc: 0.863539\ttraining's binary_logloss: 0.286738\tvalid_1's auc: 0.843115\tvalid_1's binary_logloss: 0.302162\n",
      "[200]\ttraining's auc: 0.870118\ttraining's binary_logloss: 0.281798\tvalid_1's auc: 0.843936\tvalid_1's binary_logloss: 0.301425\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's auc: 0.874285\ttraining's binary_logloss: 0.278579\tvalid_1's auc: 0.844381\tvalid_1's binary_logloss: 0.301042\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.84212\ttraining's binary_logloss: 0.303727\tvalid_1's auc: 0.836298\tvalid_1's binary_logloss: 0.307614\n",
      "[100]\ttraining's auc: 0.85561\ttraining's binary_logloss: 0.293334\tvalid_1's auc: 0.843024\tvalid_1's binary_logloss: 0.301923\n",
      "[150]\ttraining's auc: 0.863665\ttraining's binary_logloss: 0.28712\tvalid_1's auc: 0.845088\tvalid_1's binary_logloss: 0.299989\n",
      "[200]\ttraining's auc: 0.870243\ttraining's binary_logloss: 0.282176\tvalid_1's auc: 0.845674\tvalid_1's binary_logloss: 0.29926\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's auc: 0.869914\ttraining's binary_logloss: 0.282447\tvalid_1's auc: 0.845734\tvalid_1's binary_logloss: 0.299238\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.841885\ttraining's binary_logloss: 0.303874\tvalid_1's auc: 0.8354\tvalid_1's binary_logloss: 0.307712\n",
      "[100]\ttraining's auc: 0.855536\ttraining's binary_logloss: 0.293546\tvalid_1's auc: 0.842351\tvalid_1's binary_logloss: 0.301903\n",
      "[150]\ttraining's auc: 0.863653\ttraining's binary_logloss: 0.287253\tvalid_1's auc: 0.844793\tvalid_1's binary_logloss: 0.299743\n",
      "[200]\ttraining's auc: 0.869961\ttraining's binary_logloss: 0.28233\tvalid_1's auc: 0.845661\tvalid_1's binary_logloss: 0.298794\n",
      "[250]\ttraining's auc: 0.875556\ttraining's binary_logloss: 0.278085\tvalid_1's auc: 0.84622\tvalid_1's binary_logloss: 0.29835\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's auc: 0.875345\ttraining's binary_logloss: 0.278226\tvalid_1's auc: 0.846237\tvalid_1's binary_logloss: 0.298355\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.843667\ttraining's binary_logloss: 0.303117\tvalid_1's auc: 0.829166\tvalid_1's binary_logloss: 0.30956\n",
      "[100]\ttraining's auc: 0.857353\ttraining's binary_logloss: 0.292393\tvalid_1's auc: 0.835682\tvalid_1's binary_logloss: 0.30442\n",
      "[150]\ttraining's auc: 0.86565\ttraining's binary_logloss: 0.28605\tvalid_1's auc: 0.838079\tvalid_1's binary_logloss: 0.302574\n",
      "[200]\ttraining's auc: 0.871975\ttraining's binary_logloss: 0.281096\tvalid_1's auc: 0.838816\tvalid_1's binary_logloss: 0.301932\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's auc: 0.874671\ttraining's binary_logloss: 0.278951\tvalid_1's auc: 0.839137\tvalid_1's binary_logloss: 0.301702\n",
      "*********************\n",
      "roc auc estimado:  0.8442881761857495\n",
      "roc auc varianza:  0.0006465481542519408\n"
     ]
    }
   ],
   "source": [
    "[test_probs,fi] = cross_validation_lightgbm(train, y_train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-recorder",
   "metadata": {},
   "source": [
    "## Procesar SUNAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fatal-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunat_train = pd.read_csv(f'{path}/sunat_train.csv')\n",
    "sunat_test = pd.read_csv(f'{path}/sunat_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incorporate-portable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292479, 18), (318821, 18))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### eliminar registros duplicados\n",
    "sunat_train.drop_duplicates(inplace=True)\n",
    "sunat_test.drop_duplicates(inplace=True)\n",
    "sunat_train.shape, sunat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "crude-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'tipcontribuyente': 'int32',\n",
    "         'tippersona': 'int32',\n",
    "         'ciiu': 'int32',\n",
    "         'ubigeo': 'int32',\n",
    "         'condiciondomicilio': 'int32',\n",
    "         'estadocontribuyente': 'int32',\n",
    "         'codvia': 'int32',\n",
    "         'codzona': 'int32',\n",
    "         'contabilidad': 'int32',\n",
    "         'facturacion': 'int32',\n",
    "         'domiciliado': 'int32',\n",
    "         'comercioexterior': 'int32',\n",
    "         'cargorele': 'int32',\n",
    "         'codentidadtributo': 'int32',\n",
    "         'estadotributo': 'int32'}\n",
    "sunat_train = sunat_train.astype(dict_)\n",
    "sunat_test = sunat_test.astype(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "martial-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sunat_train['diff_fech'] = sunat_train['fecbaja'] - sunat_train['fecalta']\n",
    "sunat_test['diff_fech'] = sunat_test['fecbaja'] - sunat_test['fecalta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "gross-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "moda=lambda x: calculate_mode(x)\n",
    "moda.__name__='mode'\n",
    "agg_sunat = {\n",
    "            'tipcontribuyente':['nunique',moda],\n",
    "           'tippersona':['nunique',moda],\n",
    "           'ciiu':['nunique', moda],\n",
    "           'ubigeo':['nunique',moda],\n",
    "           'condiciondomicilio':['nunique',moda],\n",
    "#            'estadocontribuyente':['nunique',moda],\n",
    "           'codvia':['nunique',moda],\n",
    "           'codzona':['nunique',moda],\n",
    "           'contabilidad':['nunique',moda],\n",
    "           'facturacion':['nunique',moda],\n",
    "           'domiciliado':['nunique',moda],\n",
    "           'comercioexterior':['nunique',moda],\n",
    "           'cargorele':['nunique',moda],\n",
    "           'codentidadtributo':['nunique',moda],\n",
    "           'estadotributo':['nunique',moda],\n",
    "           'fecalta':['mean','max', 'nunique','min','std'],\n",
    "           'fecbaja':['mean','max', 'nunique','min'], \n",
    "           'diff_fech':['mean','max', 'nunique','min'], \n",
    "            }\n",
    "sunat_train_agg = sunat_train.groupby('key_value').agg(agg_sunat)\n",
    "sunat_train_agg.columns = [i+'_'+j for i,j in sunat_train_agg.columns]\n",
    "sunat_test_agg = sunat_test.groupby('key_value').agg(agg_sunat)\n",
    "sunat_test_agg.columns = [i+'_'+j for i,j in sunat_test_agg.columns]\n",
    "# del sunat_train, sunat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sublime-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_estadocontribuyente_train = get_crosstab(sunat_train, 'key_value', 'estadocontribuyente')\n",
    "crosstab_estadocontribuyente_test = get_crosstab(sunat_test, 'key_value', 'estadocontribuyente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "naked-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358487, 1136) (396666, 1135)\n",
      "(358487, 1135) (396666, 1135)\n"
     ]
    }
   ],
   "source": [
    "train = train.join(crosstab_estadocontribuyente_train).join(sunat_train_agg)\n",
    "test = test.join(crosstab_estadocontribuyente_test).join(sunat_test_agg)\n",
    "train, test = get_keep_columns(train, test)\n",
    "del sunat_train_agg, sunat_test_agg, sunat_train, sunat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "single-leave",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.842815\ttraining's binary_logloss: 0.303136\tvalid_1's auc: 0.834673\tvalid_1's binary_logloss: 0.309239\n",
      "[100]\ttraining's auc: 0.856988\ttraining's binary_logloss: 0.292076\tvalid_1's auc: 0.843205\tvalid_1's binary_logloss: 0.302669\n",
      "[150]\ttraining's auc: 0.865499\ttraining's binary_logloss: 0.285566\tvalid_1's auc: 0.8461\tvalid_1's binary_logloss: 0.300411\n",
      "[200]\ttraining's auc: 0.872021\ttraining's binary_logloss: 0.280468\tvalid_1's auc: 0.847614\tvalid_1's binary_logloss: 0.299262\n",
      "[250]\ttraining's auc: 0.87767\ttraining's binary_logloss: 0.276098\tvalid_1's auc: 0.848302\tvalid_1's binary_logloss: 0.298766\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttraining's auc: 0.881251\ttraining's binary_logloss: 0.273243\tvalid_1's auc: 0.848566\tvalid_1's binary_logloss: 0.298533\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.842587\ttraining's binary_logloss: 0.303296\tvalid_1's auc: 0.833107\tvalid_1's binary_logloss: 0.30964\n",
      "[100]\ttraining's auc: 0.857005\ttraining's binary_logloss: 0.292273\tvalid_1's auc: 0.84203\tvalid_1's binary_logloss: 0.302981\n",
      "[150]\ttraining's auc: 0.865485\ttraining's binary_logloss: 0.28564\tvalid_1's auc: 0.844776\tvalid_1's binary_logloss: 0.300825\n",
      "[200]\ttraining's auc: 0.871854\ttraining's binary_logloss: 0.280564\tvalid_1's auc: 0.845758\tvalid_1's binary_logloss: 0.299993\n",
      "[250]\ttraining's auc: 0.877683\ttraining's binary_logloss: 0.276052\tvalid_1's auc: 0.846619\tvalid_1's binary_logloss: 0.299378\n",
      "Early stopping, best iteration is:\n",
      "[283]\ttraining's auc: 0.881245\ttraining's binary_logloss: 0.273318\tvalid_1's auc: 0.846965\tvalid_1's binary_logloss: 0.299146\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.842732\ttraining's binary_logloss: 0.303608\tvalid_1's auc: 0.837411\tvalid_1's binary_logloss: 0.307235\n",
      "[100]\ttraining's auc: 0.856765\ttraining's binary_logloss: 0.292705\tvalid_1's auc: 0.844827\tvalid_1's binary_logloss: 0.300966\n",
      "[150]\ttraining's auc: 0.865231\ttraining's binary_logloss: 0.286197\tvalid_1's auc: 0.847205\tvalid_1's binary_logloss: 0.298807\n",
      "[200]\ttraining's auc: 0.871953\ttraining's binary_logloss: 0.281064\tvalid_1's auc: 0.848134\tvalid_1's binary_logloss: 0.297881\n",
      "Early stopping, best iteration is:\n",
      "[229]\ttraining's auc: 0.875067\ttraining's binary_logloss: 0.278511\tvalid_1's auc: 0.848588\tvalid_1's binary_logloss: 0.297502\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.843051\ttraining's binary_logloss: 0.303443\tvalid_1's auc: 0.835683\tvalid_1's binary_logloss: 0.307638\n",
      "[100]\ttraining's auc: 0.857258\ttraining's binary_logloss: 0.292518\tvalid_1's auc: 0.843615\tvalid_1's binary_logloss: 0.301271\n",
      "[150]\ttraining's auc: 0.865644\ttraining's binary_logloss: 0.286026\tvalid_1's auc: 0.846375\tvalid_1's binary_logloss: 0.29908\n",
      "[200]\ttraining's auc: 0.872155\ttraining's binary_logloss: 0.280945\tvalid_1's auc: 0.847284\tvalid_1's binary_logloss: 0.29812\n",
      "[250]\ttraining's auc: 0.877827\ttraining's binary_logloss: 0.27648\tvalid_1's auc: 0.847807\tvalid_1's binary_logloss: 0.297637\n",
      "[300]\ttraining's auc: 0.882966\ttraining's binary_logloss: 0.272402\tvalid_1's auc: 0.848186\tvalid_1's binary_logloss: 0.297231\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's auc: 0.884087\ttraining's binary_logloss: 0.271536\tvalid_1's auc: 0.848246\tvalid_1's binary_logloss: 0.297175\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.844161\ttraining's binary_logloss: 0.303061\tvalid_1's auc: 0.82968\tvalid_1's binary_logloss: 0.309531\n",
      "[100]\ttraining's auc: 0.858526\ttraining's binary_logloss: 0.291779\tvalid_1's auc: 0.837016\tvalid_1's binary_logloss: 0.303724\n",
      "[150]\ttraining's auc: 0.867164\ttraining's binary_logloss: 0.285166\tvalid_1's auc: 0.839494\tvalid_1's binary_logloss: 0.301827\n",
      "[200]\ttraining's auc: 0.873904\ttraining's binary_logloss: 0.279902\tvalid_1's auc: 0.840792\tvalid_1's binary_logloss: 0.300867\n",
      "Early stopping, best iteration is:\n",
      "[213]\ttraining's auc: 0.875536\ttraining's binary_logloss: 0.278656\tvalid_1's auc: 0.841009\tvalid_1's binary_logloss: 0.300665\n",
      "*********************\n",
      "roc auc estimado:  0.8466946478555364\n",
      "roc auc varianza:  0.0007110244161166008\n"
     ]
    }
   ],
   "source": [
    "[test_probs, fi] = cross_validation_lightgbm(train, y_train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "athletic-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_pickle('train_1135features.pkl')\n",
    "# test.to_pickle('test_1135features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "proof-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train_1135features.pkl')\n",
    "test = pd.read_pickle('test_1135features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-fiber",
   "metadata": {},
   "source": [
    "## Aggregate Unstack de cod_instit_financiera and PRODUCTO de los 12 ultimos meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "saving-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc_train = pd.read_csv(f'{path}/rcc_train.csv')\n",
    "rcc_test = pd.read_csv(f'{path}/rcc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "controlled-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### inputar datos faltantes en la base de rcc_test\n",
    "rcc_test['cod_instit_financiera'].fillna(rcc_test['cod_instit_financiera'].value_counts().index[0], inplace=True)\n",
    "rcc_test['PRODUCTO'].fillna(rcc_test['PRODUCTO'].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "little-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'codmes': 'int32',\n",
    " 'key_value': 'int32',\n",
    " 'condicion': 'int32',\n",
    " 'tipo_credito': 'int32',\n",
    " 'cod_instit_financiera': 'int32',\n",
    " 'PRODUCTO': 'int32',\n",
    " 'RIESGO_DIRECTO': 'int32',\n",
    " 'COD_CLASIFICACION_DEUDOR': 'int32'}\n",
    "rcc_train = rcc_train.astype(dict_)\n",
    "rcc_test = rcc_test.astype(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efficient-module",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Sum\n",
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Unique\n",
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Min\n",
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Max\n",
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Std\n",
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Mean\n",
      "haciendo unstack de cod_instit_financiera desde 201703 con la funcion de agregacion Median\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Sum\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Unique\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Min\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Max\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Std\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Mean\n",
      "haciendo unstack de PRODUCTO desde 201703 con la funcion de agregacion Median\n"
     ]
    }
   ],
   "source": [
    "rcc_train_list=[]\n",
    "for feature in ['cod_instit_financiera','PRODUCTO']:\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Sum'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Unique'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Min'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Max'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Std'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Mean'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201703, 11, 'Median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "random-cherry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358487, 1057)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcc_train = pd.concat(rcc_train_list, axis=1)\n",
    "del rcc_train_list\n",
    "rcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "subjective-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Sum\n",
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Unique\n",
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Min\n",
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Max\n",
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Std\n",
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Mean\n",
      "haciendo unstack de cod_instit_financiera desde 201803 con la funcion de agregacion Median\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Sum\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Unique\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Min\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Max\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Std\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Mean\n",
      "haciendo unstack de PRODUCTO desde 201803 con la funcion de agregacion Median\n"
     ]
    }
   ],
   "source": [
    "rcc_test_list=[]\n",
    "for feature in ['cod_instit_financiera','PRODUCTO']:\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Sum'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Unique'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Min'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Max'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Std'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Mean'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201803, 11, 'Median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "close-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396666, 959)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcc_test = pd.concat(rcc_test_list, axis=1)\n",
    "del rcc_test_list\n",
    "rcc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "induced-stage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358487, 1057) (396666, 959)\n",
      "(358487, 959) (396666, 959)\n"
     ]
    }
   ],
   "source": [
    "rcc_train , rcc_test = get_keep_columns(rcc_train, rcc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "outdoor-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 2094), (396666, 2094))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.join(rcc_train)\n",
    "test = test.join(rcc_test)\n",
    "del rcc_train, rcc_test\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "amino-impression",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849474\ttraining's binary_logloss: 0.298747\tvalid_1's auc: 0.841043\tvalid_1's binary_logloss: 0.305141\n",
      "[100]\ttraining's auc: 0.862844\ttraining's binary_logloss: 0.287447\tvalid_1's auc: 0.848488\tvalid_1's binary_logloss: 0.298783\n",
      "[150]\ttraining's auc: 0.871171\ttraining's binary_logloss: 0.280715\tvalid_1's auc: 0.851142\tvalid_1's binary_logloss: 0.296634\n",
      "[200]\ttraining's auc: 0.877743\ttraining's binary_logloss: 0.27542\tvalid_1's auc: 0.852547\tvalid_1's binary_logloss: 0.29554\n",
      "[250]\ttraining's auc: 0.883317\ttraining's binary_logloss: 0.270831\tvalid_1's auc: 0.852967\tvalid_1's binary_logloss: 0.295191\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttraining's auc: 0.88478\ttraining's binary_logloss: 0.269647\tvalid_1's auc: 0.853141\tvalid_1's binary_logloss: 0.295091\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849287\ttraining's binary_logloss: 0.298722\tvalid_1's auc: 0.84057\tvalid_1's binary_logloss: 0.305054\n",
      "[100]\ttraining's auc: 0.862958\ttraining's binary_logloss: 0.287283\tvalid_1's auc: 0.848269\tvalid_1's binary_logloss: 0.298615\n",
      "[150]\ttraining's auc: 0.871258\ttraining's binary_logloss: 0.280528\tvalid_1's auc: 0.850739\tvalid_1's binary_logloss: 0.296519\n",
      "[200]\ttraining's auc: 0.877743\ttraining's binary_logloss: 0.275247\tvalid_1's auc: 0.851843\tvalid_1's binary_logloss: 0.295586\n",
      "[250]\ttraining's auc: 0.883348\ttraining's binary_logloss: 0.270656\tvalid_1's auc: 0.85246\tvalid_1's binary_logloss: 0.295023\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's auc: 0.885264\ttraining's binary_logloss: 0.269133\tvalid_1's auc: 0.852767\tvalid_1's binary_logloss: 0.29481\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.84937\ttraining's binary_logloss: 0.299207\tvalid_1's auc: 0.8435\tvalid_1's binary_logloss: 0.302799\n",
      "[100]\ttraining's auc: 0.863\ttraining's binary_logloss: 0.287695\tvalid_1's auc: 0.85042\tvalid_1's binary_logloss: 0.296275\n",
      "[150]\ttraining's auc: 0.871246\ttraining's binary_logloss: 0.281025\tvalid_1's auc: 0.852617\tvalid_1's binary_logloss: 0.294348\n",
      "[200]\ttraining's auc: 0.877691\ttraining's binary_logloss: 0.275761\tvalid_1's auc: 0.853503\tvalid_1's binary_logloss: 0.293484\n",
      "[250]\ttraining's auc: 0.883091\ttraining's binary_logloss: 0.271204\tvalid_1's auc: 0.854029\tvalid_1's binary_logloss: 0.292998\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's auc: 0.883675\ttraining's binary_logloss: 0.270725\tvalid_1's auc: 0.854072\tvalid_1's binary_logloss: 0.292964\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849059\ttraining's binary_logloss: 0.299288\tvalid_1's auc: 0.842256\tvalid_1's binary_logloss: 0.303467\n",
      "[100]\ttraining's auc: 0.862885\ttraining's binary_logloss: 0.287854\tvalid_1's auc: 0.849819\tvalid_1's binary_logloss: 0.296813\n",
      "[150]\ttraining's auc: 0.871213\ttraining's binary_logloss: 0.281114\tvalid_1's auc: 0.851921\tvalid_1's binary_logloss: 0.294792\n",
      "[200]\ttraining's auc: 0.877693\ttraining's binary_logloss: 0.275904\tvalid_1's auc: 0.852785\tvalid_1's binary_logloss: 0.293911\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttraining's auc: 0.880067\ttraining's binary_logloss: 0.274084\tvalid_1's auc: 0.853047\tvalid_1's binary_logloss: 0.29367\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.851242\ttraining's binary_logloss: 0.298298\tvalid_1's auc: 0.835152\tvalid_1's binary_logloss: 0.306056\n",
      "[100]\ttraining's auc: 0.865081\ttraining's binary_logloss: 0.286646\tvalid_1's auc: 0.841456\tvalid_1's binary_logloss: 0.300442\n",
      "[150]\ttraining's auc: 0.873265\ttraining's binary_logloss: 0.279764\tvalid_1's auc: 0.843496\tvalid_1's binary_logloss: 0.298611\n",
      "[200]\ttraining's auc: 0.879748\ttraining's binary_logloss: 0.274498\tvalid_1's auc: 0.844466\tvalid_1's binary_logloss: 0.297789\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's auc: 0.884151\ttraining's binary_logloss: 0.270888\tvalid_1's auc: 0.844879\tvalid_1's binary_logloss: 0.297418\n",
      "*********************\n",
      "roc auc estimado:  0.8516168658960651\n",
      "roc auc varianza:  0.0008218480457957318\n",
      "total de variables : 2094\n",
      "variables con importancia acumulada al 99% : 1338\n",
      "variables con zero importancia : 614\n",
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.848948\ttraining's binary_logloss: 0.298813\tvalid_1's auc: 0.840172\tvalid_1's binary_logloss: 0.305429\n",
      "[100]\ttraining's auc: 0.862551\ttraining's binary_logloss: 0.287456\tvalid_1's auc: 0.848313\tvalid_1's binary_logloss: 0.298915\n",
      "[150]\ttraining's auc: 0.870939\ttraining's binary_logloss: 0.280661\tvalid_1's auc: 0.851059\tvalid_1's binary_logloss: 0.296598\n",
      "[200]\ttraining's auc: 0.877389\ttraining's binary_logloss: 0.275494\tvalid_1's auc: 0.852339\tvalid_1's binary_logloss: 0.295596\n",
      "[250]\ttraining's auc: 0.883251\ttraining's binary_logloss: 0.270851\tvalid_1's auc: 0.852771\tvalid_1's binary_logloss: 0.295117\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttraining's auc: 0.88431\ttraining's binary_logloss: 0.269988\tvalid_1's auc: 0.852886\tvalid_1's binary_logloss: 0.295055\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849333\ttraining's binary_logloss: 0.298749\tvalid_1's auc: 0.840344\tvalid_1's binary_logloss: 0.305246\n",
      "[100]\ttraining's auc: 0.863174\ttraining's binary_logloss: 0.287294\tvalid_1's auc: 0.848187\tvalid_1's binary_logloss: 0.298721\n",
      "[150]\ttraining's auc: 0.871255\ttraining's binary_logloss: 0.280586\tvalid_1's auc: 0.850813\tvalid_1's binary_logloss: 0.29655\n",
      "[200]\ttraining's auc: 0.877744\ttraining's binary_logloss: 0.275283\tvalid_1's auc: 0.851935\tvalid_1's binary_logloss: 0.295612\n",
      "[250]\ttraining's auc: 0.883284\ttraining's binary_logloss: 0.2707\tvalid_1's auc: 0.852503\tvalid_1's binary_logloss: 0.295196\n",
      "Early stopping, best iteration is:\n",
      "[253]\ttraining's auc: 0.883666\ttraining's binary_logloss: 0.270419\tvalid_1's auc: 0.852524\tvalid_1's binary_logloss: 0.295172\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849213\ttraining's binary_logloss: 0.299335\tvalid_1's auc: 0.843629\tvalid_1's binary_logloss: 0.302694\n",
      "[100]\ttraining's auc: 0.862908\ttraining's binary_logloss: 0.2878\tvalid_1's auc: 0.850907\tvalid_1's binary_logloss: 0.296005\n",
      "[150]\ttraining's auc: 0.871055\ttraining's binary_logloss: 0.281095\tvalid_1's auc: 0.852786\tvalid_1's binary_logloss: 0.294063\n",
      "[200]\ttraining's auc: 0.87772\ttraining's binary_logloss: 0.275808\tvalid_1's auc: 0.853632\tvalid_1's binary_logloss: 0.293204\n",
      "[250]\ttraining's auc: 0.883299\ttraining's binary_logloss: 0.271253\tvalid_1's auc: 0.854018\tvalid_1's binary_logloss: 0.292761\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's auc: 0.882589\ttraining's binary_logloss: 0.271799\tvalid_1's auc: 0.854039\tvalid_1's binary_logloss: 0.292768\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849034\ttraining's binary_logloss: 0.299285\tvalid_1's auc: 0.842558\tvalid_1's binary_logloss: 0.303438\n",
      "[100]\ttraining's auc: 0.862927\ttraining's binary_logloss: 0.287881\tvalid_1's auc: 0.849988\tvalid_1's binary_logloss: 0.296689\n",
      "[150]\ttraining's auc: 0.871023\ttraining's binary_logloss: 0.281198\tvalid_1's auc: 0.85218\tvalid_1's binary_logloss: 0.294515\n",
      "[200]\ttraining's auc: 0.877616\ttraining's binary_logloss: 0.275898\tvalid_1's auc: 0.853153\tvalid_1's binary_logloss: 0.293552\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's auc: 0.878461\ttraining's binary_logloss: 0.275218\tvalid_1's auc: 0.853253\tvalid_1's binary_logloss: 0.293473\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.850747\ttraining's binary_logloss: 0.298645\tvalid_1's auc: 0.834333\tvalid_1's binary_logloss: 0.306411\n",
      "[100]\ttraining's auc: 0.864705\ttraining's binary_logloss: 0.286771\tvalid_1's auc: 0.841341\tvalid_1's binary_logloss: 0.300388\n",
      "[150]\ttraining's auc: 0.873107\ttraining's binary_logloss: 0.279919\tvalid_1's auc: 0.843219\tvalid_1's binary_logloss: 0.298699\n",
      "[200]\ttraining's auc: 0.879609\ttraining's binary_logloss: 0.274608\tvalid_1's auc: 0.844082\tvalid_1's binary_logloss: 0.297933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's auc: 0.879122\ttraining's binary_logloss: 0.274986\tvalid_1's auc: 0.844117\tvalid_1's binary_logloss: 0.29794\n",
      "*********************\n",
      "roc auc estimado:  0.8513995738147447\n",
      "roc auc varianza:  0.0008891522476088254\n",
      "total de variables : 1338\n",
      "variables con importancia acumulada al 99% : 1242\n",
      "variables con zero importancia : 0\n"
     ]
    }
   ],
   "source": [
    "# eliminar variables con zero_importance\n",
    "while True:\n",
    "    test_probs, fi = cross_validation_lightgbm(train, y_train, test)\n",
    "    keep_columns, zero_importance = get_feature_selection(fi)\n",
    "    train = train[keep_columns]\n",
    "    test = test[keep_columns]\n",
    "    if len(zero_importance)==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "difficult-integer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849467\ttraining's binary_logloss: 0.298653\tvalid_1's auc: 0.841334\tvalid_1's binary_logloss: 0.305017\n",
      "[100]\ttraining's auc: 0.862752\ttraining's binary_logloss: 0.287409\tvalid_1's auc: 0.849029\tvalid_1's binary_logloss: 0.298518\n",
      "[150]\ttraining's auc: 0.870825\ttraining's binary_logloss: 0.280815\tvalid_1's auc: 0.851775\tvalid_1's binary_logloss: 0.296306\n",
      "[200]\ttraining's auc: 0.877364\ttraining's binary_logloss: 0.275638\tvalid_1's auc: 0.852525\tvalid_1's binary_logloss: 0.295595\n",
      "[250]\ttraining's auc: 0.882944\ttraining's binary_logloss: 0.271075\tvalid_1's auc: 0.853165\tvalid_1's binary_logloss: 0.295049\n",
      "[300]\ttraining's auc: 0.887974\ttraining's binary_logloss: 0.266895\tvalid_1's auc: 0.853475\tvalid_1's binary_logloss: 0.294771\n",
      "Early stopping, best iteration is:\n",
      "[326]\ttraining's auc: 0.89053\ttraining's binary_logloss: 0.264784\tvalid_1's auc: 0.853623\tvalid_1's binary_logloss: 0.294682\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849218\ttraining's binary_logloss: 0.298665\tvalid_1's auc: 0.840849\tvalid_1's binary_logloss: 0.304953\n",
      "[100]\ttraining's auc: 0.862825\ttraining's binary_logloss: 0.287358\tvalid_1's auc: 0.848693\tvalid_1's binary_logloss: 0.298508\n",
      "[150]\ttraining's auc: 0.871164\ttraining's binary_logloss: 0.280624\tvalid_1's auc: 0.851421\tvalid_1's binary_logloss: 0.296351\n",
      "[200]\ttraining's auc: 0.877612\ttraining's binary_logloss: 0.275366\tvalid_1's auc: 0.852361\tvalid_1's binary_logloss: 0.295483\n",
      "[250]\ttraining's auc: 0.883315\ttraining's binary_logloss: 0.270737\tvalid_1's auc: 0.853138\tvalid_1's binary_logloss: 0.294899\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's auc: 0.883802\ttraining's binary_logloss: 0.270376\tvalid_1's auc: 0.85316\tvalid_1's binary_logloss: 0.294869\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849258\ttraining's binary_logloss: 0.299149\tvalid_1's auc: 0.843229\tvalid_1's binary_logloss: 0.302911\n",
      "[100]\ttraining's auc: 0.863031\ttraining's binary_logloss: 0.287744\tvalid_1's auc: 0.850181\tvalid_1's binary_logloss: 0.29656\n",
      "[150]\ttraining's auc: 0.871306\ttraining's binary_logloss: 0.281036\tvalid_1's auc: 0.852202\tvalid_1's binary_logloss: 0.294558\n",
      "[200]\ttraining's auc: 0.877668\ttraining's binary_logloss: 0.27583\tvalid_1's auc: 0.853065\tvalid_1's binary_logloss: 0.2937\n",
      "[250]\ttraining's auc: 0.883398\ttraining's binary_logloss: 0.271197\tvalid_1's auc: 0.853362\tvalid_1's binary_logloss: 0.293345\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's auc: 0.882597\ttraining's binary_logloss: 0.271826\tvalid_1's auc: 0.853406\tvalid_1's binary_logloss: 0.293368\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.849109\ttraining's binary_logloss: 0.299273\tvalid_1's auc: 0.84222\tvalid_1's binary_logloss: 0.303613\n",
      "[100]\ttraining's auc: 0.862847\ttraining's binary_logloss: 0.287814\tvalid_1's auc: 0.849842\tvalid_1's binary_logloss: 0.296792\n",
      "[150]\ttraining's auc: 0.871088\ttraining's binary_logloss: 0.281172\tvalid_1's auc: 0.851944\tvalid_1's binary_logloss: 0.294788\n",
      "[200]\ttraining's auc: 0.877705\ttraining's binary_logloss: 0.275844\tvalid_1's auc: 0.852906\tvalid_1's binary_logloss: 0.293844\n",
      "[250]\ttraining's auc: 0.883353\ttraining's binary_logloss: 0.27119\tvalid_1's auc: 0.853279\tvalid_1's binary_logloss: 0.29342\n",
      "Early stopping, best iteration is:\n",
      "[255]\ttraining's auc: 0.883925\ttraining's binary_logloss: 0.270738\tvalid_1's auc: 0.853328\tvalid_1's binary_logloss: 0.293392\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.850893\ttraining's binary_logloss: 0.298415\tvalid_1's auc: 0.834817\tvalid_1's binary_logloss: 0.306138\n",
      "[100]\ttraining's auc: 0.864699\ttraining's binary_logloss: 0.286837\tvalid_1's auc: 0.841457\tvalid_1's binary_logloss: 0.300531\n",
      "[150]\ttraining's auc: 0.872902\ttraining's binary_logloss: 0.280025\tvalid_1's auc: 0.843452\tvalid_1's binary_logloss: 0.298768\n",
      "[200]\ttraining's auc: 0.879275\ttraining's binary_logloss: 0.274777\tvalid_1's auc: 0.844078\tvalid_1's binary_logloss: 0.298109\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's auc: 0.878092\ttraining's binary_logloss: 0.275676\tvalid_1's auc: 0.844167\tvalid_1's binary_logloss: 0.298114\n",
      "*********************\n",
      "roc auc estimado:  0.8515723446808912\n",
      "roc auc varianza:  0.0008964163364301804\n"
     ]
    }
   ],
   "source": [
    "test_probs_, fi_ = cross_validation_lightgbm(train[keep_columns], y_train, test[keep_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "unique-voluntary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RIESGO_DIRECTO_1_saldoUnique_ult1meses               0.009520\n",
       "edad                                                 0.009003\n",
       "PRODUCTO_1_saldoStd_ult12meses                       0.008067\n",
       "ubigeo_mode                                          0.007729\n",
       "PRODUCTO_1_saldoMax_ult12meses                       0.007622\n",
       "PRODUCTO_3_saldoUnique_ult12meses                    0.006343\n",
       "RIESGO_DIRECTO_1_saldoStd_ult1meses                  0.006243\n",
       "PRODUCTO_1_saldoMean_ult12meses                      0.005783\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.005665\n",
       "sexo_0                                               0.005398\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.005121\n",
       "cod_instit_financiera_10_saldoStd_ult12meses         0.004941\n",
       "PRODUCTO_8_saldoSum_ult12meses                       0.004894\n",
       "PRODUCTO_0_saldoMin_ult12meses                       0.004785\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult2meses               0.004692\n",
       "RIESGO_DIRECTO_1_saldoMin_ult1meses                  0.004596\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.004583\n",
       "PRODUCTO_6_saldoMean_ult12meses                      0.004564\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult1meses               0.004547\n",
       "PRODUCTO_3_saldoMedian_ult12meses                    0.004499\n",
       "estadocontribuyente_0                                0.004489\n",
       "PRODUCTO_8_saldoUnique_ult12meses                    0.004438\n",
       "PRODUCTO_3_saldoMean_ult12meses                      0.004436\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult12meses              0.004304\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.004295\n",
       "ciiu_mode                                            0.004022\n",
       "PRODUCTO_3_saldoMin_ult12meses                       0.004005\n",
       "fecalta_min                                          0.003923\n",
       "PRODUCTO_6_saldoSum_ult12meses                       0.003883\n",
       "cod_instit_financiera_32_saldoStd_ult12meses         0.003780\n",
       "cod_instit_financiera_max_ult1mes                    0.003758\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMax_ult1meses        0.003698\n",
       "PRODUCTO_12_saldoUnique_ult12meses                   0.003671\n",
       "PRODUCTO_0_saldoStd_ult12meses                       0.003654\n",
       "PRODUCTO_8_saldoMin_ult12meses                       0.003619\n",
       "PRODUCTO_1_saldoMedian_ult12meses                    0.003596\n",
       "PRODUCTO_11_saldoStd_ult12meses                      0.003523\n",
       "PRODUCTO_4_saldoStd_ult12meses                       0.003520\n",
       "PRODUCTO_11_saldoMin_ult12meses                      0.003520\n",
       "RIESGO_DIRECTO_1_saldoMin_ult2meses                  0.003498\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.003361\n",
       "PRODUCTO_8_saldoMedian_ult12meses                    0.003360\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult12meses              0.003314\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult3meses               0.003168\n",
       "cod_instit_financiera_34_saldoUnique_ult12meses      0.003142\n",
       "PRODUCTO_2_saldoUnique_ult12meses                    0.003119\n",
       "tipo_credito_12_saldoMin_ult1meses                   0.003105\n",
       "PRODUCTO_6_saldoMin_ult12meses                       0.003072\n",
       "RIESGO_DIRECTO_1_saldoStd_ult2meses                  0.003060\n",
       "condicion_0_saldoUnique_ult12meses                   0.003053\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi_.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "specialized-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_.name='target'\n",
    "test_probs_.to_csv('../results/test_1242features_0.85157.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "junior-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[keep_columns].to_pickle('train_1242features.pkl')\n",
    "test[keep_columns].to_pickle('test_1242features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-yahoo",
   "metadata": {},
   "source": [
    "## Aggregate Unstack de cod_instit_financiera and PRODUCTO del ultimo mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "professional-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc_train = pd.read_csv(f'{path}/rcc_train.csv')\n",
    "rcc_test = pd.read_csv(f'{path}/rcc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dynamic-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### inputar datos faltantes en la base de rcc_test\n",
    "rcc_test['cod_instit_financiera'].fillna(rcc_test['cod_instit_financiera'].value_counts().index[0], inplace=True)\n",
    "rcc_test['PRODUCTO'].fillna(rcc_test['PRODUCTO'].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "widespread-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {'codmes': 'int32',\n",
    " 'key_value': 'int32',\n",
    " 'condicion': 'int32',\n",
    " 'tipo_credito': 'int32',\n",
    " 'cod_instit_financiera': 'int32',\n",
    " 'PRODUCTO': 'int32',\n",
    " 'RIESGO_DIRECTO': 'int32',\n",
    " 'COD_CLASIFICACION_DEUDOR': 'int32'}\n",
    "rcc_train = rcc_train.astype(dict_)\n",
    "rcc_test = rcc_test.astype(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "everyday-congo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Sum\n",
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Unique\n",
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Min\n",
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Max\n",
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Std\n",
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Mean\n",
      "haciendo unstack de cod_instit_financiera desde 201802 con la funcion de agregacion Median\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Sum\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Unique\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Min\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Max\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Std\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Mean\n",
      "haciendo unstack de PRODUCTO desde 201802 con la funcion de agregacion Median\n"
     ]
    }
   ],
   "source": [
    "rcc_train_list=[]\n",
    "for feature in ['cod_instit_financiera','PRODUCTO']:\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Sum'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Unique'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Min'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Max'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Std'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Mean'))\n",
    "    rcc_train_list.append(get_unstack(rcc_train, feature, 201802, 0, 'Median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "negative-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358487, 987)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcc_train = pd.concat(rcc_train_list, axis=1)\n",
    "del rcc_train_list\n",
    "rcc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "classical-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Sum\n",
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Unique\n",
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Min\n",
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Max\n",
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Std\n",
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Mean\n",
      "haciendo unstack de cod_instit_financiera desde 201902 con la funcion de agregacion Median\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Sum\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Unique\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Min\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Max\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Std\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Mean\n",
      "haciendo unstack de PRODUCTO desde 201902 con la funcion de agregacion Median\n"
     ]
    }
   ],
   "source": [
    "rcc_test_list=[]\n",
    "for feature in ['cod_instit_financiera','PRODUCTO']:\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Sum'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Unique'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Min'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Max'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Std'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Mean'))\n",
    "    rcc_test_list.append(get_unstack(rcc_test, feature, 201902, 0, 'Median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "greatest-horse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396666, 896)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcc_test = pd.concat(rcc_test_list, axis=1)\n",
    "del rcc_test_list\n",
    "rcc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abandoned-bread",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358487, 987) (396666, 896)\n",
      "(358487, 889) (396666, 889)\n"
     ]
    }
   ],
   "source": [
    "rcc_train , rcc_test = get_keep_columns(rcc_train, rcc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "communist-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train_1242features.pkl')\n",
    "test =pd.read_pickle('test_1242features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "agricultural-visit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 2131), (396666, 2131))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.join(rcc_train)\n",
    "test = test.join(rcc_test)\n",
    "del rcc_train, rcc_test\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "removed-details",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "differential-leonard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852444\ttraining's binary_logloss: 0.296276\tvalid_1's auc: 0.843457\tvalid_1's binary_logloss: 0.302985\n",
      "[100]\ttraining's auc: 0.865245\ttraining's binary_logloss: 0.285196\tvalid_1's auc: 0.850852\tvalid_1's binary_logloss: 0.296781\n",
      "[150]\ttraining's auc: 0.873169\ttraining's binary_logloss: 0.278708\tvalid_1's auc: 0.852872\tvalid_1's binary_logloss: 0.295104\n",
      "[200]\ttraining's auc: 0.879514\ttraining's binary_logloss: 0.273502\tvalid_1's auc: 0.85393\tvalid_1's binary_logloss: 0.2943\n",
      "[250]\ttraining's auc: 0.885342\ttraining's binary_logloss: 0.268774\tvalid_1's auc: 0.854694\tvalid_1's binary_logloss: 0.293784\n",
      "Early stopping, best iteration is:\n",
      "[271]\ttraining's auc: 0.887504\ttraining's binary_logloss: 0.266968\tvalid_1's auc: 0.854936\tvalid_1's binary_logloss: 0.293641\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852376\ttraining's binary_logloss: 0.296363\tvalid_1's auc: 0.843686\tvalid_1's binary_logloss: 0.30299\n",
      "[100]\ttraining's auc: 0.865225\ttraining's binary_logloss: 0.285158\tvalid_1's auc: 0.850513\tvalid_1's binary_logloss: 0.296838\n",
      "[150]\ttraining's auc: 0.873153\ttraining's binary_logloss: 0.278604\tvalid_1's auc: 0.852825\tvalid_1's binary_logloss: 0.294872\n",
      "[200]\ttraining's auc: 0.879496\ttraining's binary_logloss: 0.273445\tvalid_1's auc: 0.853677\tvalid_1's binary_logloss: 0.294211\n",
      "[250]\ttraining's auc: 0.885116\ttraining's binary_logloss: 0.2688\tvalid_1's auc: 0.854241\tvalid_1's binary_logloss: 0.293763\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's auc: 0.88552\ttraining's binary_logloss: 0.268472\tvalid_1's auc: 0.854302\tvalid_1's binary_logloss: 0.29372\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852414\ttraining's binary_logloss: 0.296753\tvalid_1's auc: 0.846452\tvalid_1's binary_logloss: 0.300292\n",
      "[100]\ttraining's auc: 0.865597\ttraining's binary_logloss: 0.285435\tvalid_1's auc: 0.853486\tvalid_1's binary_logloss: 0.294043\n",
      "[150]\ttraining's auc: 0.873369\ttraining's binary_logloss: 0.278953\tvalid_1's auc: 0.855284\tvalid_1's binary_logloss: 0.292236\n",
      "[200]\ttraining's auc: 0.879786\ttraining's binary_logloss: 0.273728\tvalid_1's auc: 0.855843\tvalid_1's binary_logloss: 0.2917\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's auc: 0.882348\ttraining's binary_logloss: 0.271601\tvalid_1's auc: 0.856042\tvalid_1's binary_logloss: 0.291465\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852207\ttraining's binary_logloss: 0.296661\tvalid_1's auc: 0.84484\tvalid_1's binary_logloss: 0.30132\n",
      "[100]\ttraining's auc: 0.865309\ttraining's binary_logloss: 0.285506\tvalid_1's auc: 0.851538\tvalid_1's binary_logloss: 0.295016\n",
      "[150]\ttraining's auc: 0.873396\ttraining's binary_logloss: 0.278838\tvalid_1's auc: 0.853491\tvalid_1's binary_logloss: 0.29323\n",
      "[200]\ttraining's auc: 0.879746\ttraining's binary_logloss: 0.273655\tvalid_1's auc: 0.854239\tvalid_1's binary_logloss: 0.292535\n",
      "[250]\ttraining's auc: 0.885445\ttraining's binary_logloss: 0.268936\tvalid_1's auc: 0.854768\tvalid_1's binary_logloss: 0.292046\n",
      "Early stopping, best iteration is:\n",
      "[279]\ttraining's auc: 0.888639\ttraining's binary_logloss: 0.266372\tvalid_1's auc: 0.854999\tvalid_1's binary_logloss: 0.29184\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.854264\ttraining's binary_logloss: 0.295823\tvalid_1's auc: 0.836686\tvalid_1's binary_logloss: 0.30429\n",
      "[100]\ttraining's auc: 0.867176\ttraining's binary_logloss: 0.284367\tvalid_1's auc: 0.842876\tvalid_1's binary_logloss: 0.298973\n",
      "[150]\ttraining's auc: 0.875334\ttraining's binary_logloss: 0.277685\tvalid_1's auc: 0.84483\tvalid_1's binary_logloss: 0.297498\n",
      "[200]\ttraining's auc: 0.88163\ttraining's binary_logloss: 0.272425\tvalid_1's auc: 0.845526\tvalid_1's binary_logloss: 0.296877\n",
      "Early stopping, best iteration is:\n",
      "[223]\ttraining's auc: 0.884485\ttraining's binary_logloss: 0.27018\tvalid_1's auc: 0.845697\tvalid_1's binary_logloss: 0.296711\n",
      "*********************\n",
      "roc auc estimado:  0.8532420247322343\n",
      "roc auc varianza:  0.0009214141644526705\n",
      "total de variables : 2131\n",
      "variables con importancia acumulada al 99% : 1415\n",
      "variables con zero importancia : 577\n",
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852396\ttraining's binary_logloss: 0.296255\tvalid_1's auc: 0.8436\tvalid_1's binary_logloss: 0.302924\n",
      "[100]\ttraining's auc: 0.865277\ttraining's binary_logloss: 0.285066\tvalid_1's auc: 0.851088\tvalid_1's binary_logloss: 0.296708\n",
      "[150]\ttraining's auc: 0.873221\ttraining's binary_logloss: 0.278504\tvalid_1's auc: 0.853091\tvalid_1's binary_logloss: 0.295015\n",
      "[200]\ttraining's auc: 0.879538\ttraining's binary_logloss: 0.273374\tvalid_1's auc: 0.854186\tvalid_1's binary_logloss: 0.29415\n",
      "Early stopping, best iteration is:\n",
      "[219]\ttraining's auc: 0.881817\ttraining's binary_logloss: 0.271573\tvalid_1's auc: 0.854389\tvalid_1's binary_logloss: 0.294006\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852507\ttraining's binary_logloss: 0.296183\tvalid_1's auc: 0.843991\tvalid_1's binary_logloss: 0.302689\n",
      "[100]\ttraining's auc: 0.865513\ttraining's binary_logloss: 0.284988\tvalid_1's auc: 0.85089\tvalid_1's binary_logloss: 0.296508\n",
      "[150]\ttraining's auc: 0.873605\ttraining's binary_logloss: 0.278296\tvalid_1's auc: 0.853378\tvalid_1's binary_logloss: 0.294479\n",
      "[200]\ttraining's auc: 0.879838\ttraining's binary_logloss: 0.273166\tvalid_1's auc: 0.854278\tvalid_1's binary_logloss: 0.293714\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's auc: 0.8839\ttraining's binary_logloss: 0.269836\tvalid_1's auc: 0.854598\tvalid_1's binary_logloss: 0.293462\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852257\ttraining's binary_logloss: 0.296851\tvalid_1's auc: 0.846965\tvalid_1's binary_logloss: 0.300025\n",
      "[100]\ttraining's auc: 0.865324\ttraining's binary_logloss: 0.285461\tvalid_1's auc: 0.853435\tvalid_1's binary_logloss: 0.293862\n",
      "[150]\ttraining's auc: 0.873401\ttraining's binary_logloss: 0.27888\tvalid_1's auc: 0.855374\tvalid_1's binary_logloss: 0.292082\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's auc: 0.877816\ttraining's binary_logloss: 0.2754\tvalid_1's auc: 0.855831\tvalid_1's binary_logloss: 0.291676\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852426\ttraining's binary_logloss: 0.296625\tvalid_1's auc: 0.844912\tvalid_1's binary_logloss: 0.30132\n",
      "[100]\ttraining's auc: 0.865493\ttraining's binary_logloss: 0.285398\tvalid_1's auc: 0.851482\tvalid_1's binary_logloss: 0.295057\n",
      "[150]\ttraining's auc: 0.873494\ttraining's binary_logloss: 0.278842\tvalid_1's auc: 0.853561\tvalid_1's binary_logloss: 0.29313\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's auc: 0.87795\ttraining's binary_logloss: 0.275278\tvalid_1's auc: 0.854237\tvalid_1's binary_logloss: 0.292526\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.8542\ttraining's binary_logloss: 0.295851\tvalid_1's auc: 0.837458\tvalid_1's binary_logloss: 0.304095\n",
      "[100]\ttraining's auc: 0.867405\ttraining's binary_logloss: 0.284336\tvalid_1's auc: 0.843432\tvalid_1's binary_logloss: 0.298714\n",
      "[150]\ttraining's auc: 0.875358\ttraining's binary_logloss: 0.27766\tvalid_1's auc: 0.845016\tvalid_1's binary_logloss: 0.297204\n",
      "[200]\ttraining's auc: 0.881803\ttraining's binary_logloss: 0.272383\tvalid_1's auc: 0.845758\tvalid_1's binary_logloss: 0.296688\n",
      "[250]\ttraining's auc: 0.88745\ttraining's binary_logloss: 0.267725\tvalid_1's auc: 0.846256\tvalid_1's binary_logloss: 0.296385\n",
      "Early stopping, best iteration is:\n",
      "[279]\ttraining's auc: 0.890326\ttraining's binary_logloss: 0.265194\tvalid_1's auc: 0.846441\tvalid_1's binary_logloss: 0.296267\n",
      "*********************\n",
      "roc auc estimado:  0.8531346713199813\n",
      "roc auc varianza:  0.0008230005776538714\n",
      "total de variables : 1415\n",
      "variables con importancia acumulada al 99% : 1320\n",
      "variables con zero importancia : 0\n"
     ]
    }
   ],
   "source": [
    "# eliminar variables con zero_importance\n",
    "while True:\n",
    "    test_probs, fi = cross_validation_lightgbm(train, y_train, test)\n",
    "    keep_columns, zero_importance = get_feature_selection(fi)\n",
    "    train = train[keep_columns]\n",
    "    test = test[keep_columns]\n",
    "    if len(zero_importance)==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "inappropriate-router",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852465\ttraining's binary_logloss: 0.296169\tvalid_1's auc: 0.843404\tvalid_1's binary_logloss: 0.302823\n",
      "[100]\ttraining's auc: 0.865319\ttraining's binary_logloss: 0.285035\tvalid_1's auc: 0.85101\tvalid_1's binary_logloss: 0.296508\n",
      "[150]\ttraining's auc: 0.873099\ttraining's binary_logloss: 0.278533\tvalid_1's auc: 0.853268\tvalid_1's binary_logloss: 0.294718\n",
      "[200]\ttraining's auc: 0.879707\ttraining's binary_logloss: 0.273318\tvalid_1's auc: 0.854022\tvalid_1's binary_logloss: 0.294056\n",
      "[250]\ttraining's auc: 0.885238\ttraining's binary_logloss: 0.268786\tvalid_1's auc: 0.854511\tvalid_1's binary_logloss: 0.293702\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's auc: 0.88885\ttraining's binary_logloss: 0.265847\tvalid_1's auc: 0.854905\tvalid_1's binary_logloss: 0.293443\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.85207\ttraining's binary_logloss: 0.296295\tvalid_1's auc: 0.843727\tvalid_1's binary_logloss: 0.302667\n",
      "[100]\ttraining's auc: 0.864997\ttraining's binary_logloss: 0.28516\tvalid_1's auc: 0.850819\tvalid_1's binary_logloss: 0.296441\n",
      "[150]\ttraining's auc: 0.872894\ttraining's binary_logloss: 0.27869\tvalid_1's auc: 0.852882\tvalid_1's binary_logloss: 0.294686\n",
      "[200]\ttraining's auc: 0.879319\ttraining's binary_logloss: 0.273464\tvalid_1's auc: 0.85398\tvalid_1's binary_logloss: 0.293806\n",
      "[250]\ttraining's auc: 0.885034\ttraining's binary_logloss: 0.268844\tvalid_1's auc: 0.854512\tvalid_1's binary_logloss: 0.29334\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's auc: 0.888196\ttraining's binary_logloss: 0.266213\tvalid_1's auc: 0.854742\tvalid_1's binary_logloss: 0.29319\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852565\ttraining's binary_logloss: 0.296623\tvalid_1's auc: 0.846616\tvalid_1's binary_logloss: 0.300183\n",
      "[100]\ttraining's auc: 0.865476\ttraining's binary_logloss: 0.285391\tvalid_1's auc: 0.853014\tvalid_1's binary_logloss: 0.294127\n",
      "[150]\ttraining's auc: 0.87339\ttraining's binary_logloss: 0.278849\tvalid_1's auc: 0.855061\tvalid_1's binary_logloss: 0.292292\n",
      "[200]\ttraining's auc: 0.879691\ttraining's binary_logloss: 0.273728\tvalid_1's auc: 0.855846\tvalid_1's binary_logloss: 0.291543\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's auc: 0.881718\ttraining's binary_logloss: 0.272108\tvalid_1's auc: 0.856051\tvalid_1's binary_logloss: 0.291387\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.852448\ttraining's binary_logloss: 0.296547\tvalid_1's auc: 0.845263\tvalid_1's binary_logloss: 0.301101\n",
      "[100]\ttraining's auc: 0.865436\ttraining's binary_logloss: 0.285419\tvalid_1's auc: 0.851865\tvalid_1's binary_logloss: 0.294844\n",
      "[150]\ttraining's auc: 0.873421\ttraining's binary_logloss: 0.278811\tvalid_1's auc: 0.853639\tvalid_1's binary_logloss: 0.293075\n",
      "[200]\ttraining's auc: 0.87977\ttraining's binary_logloss: 0.273612\tvalid_1's auc: 0.854416\tvalid_1's binary_logloss: 0.292223\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's auc: 0.88345\ttraining's binary_logloss: 0.270631\tvalid_1's auc: 0.854755\tvalid_1's binary_logloss: 0.291907\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttraining's auc: 0.85419\ttraining's binary_logloss: 0.295888\tvalid_1's auc: 0.837247\tvalid_1's binary_logloss: 0.304169\n",
      "[100]\ttraining's auc: 0.867305\ttraining's binary_logloss: 0.284381\tvalid_1's auc: 0.843265\tvalid_1's binary_logloss: 0.298749\n",
      "[150]\ttraining's auc: 0.875551\ttraining's binary_logloss: 0.277634\tvalid_1's auc: 0.844884\tvalid_1's binary_logloss: 0.29734\n",
      "[200]\ttraining's auc: 0.881898\ttraining's binary_logloss: 0.27236\tvalid_1's auc: 0.84569\tvalid_1's binary_logloss: 0.296586\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's auc: 0.885987\ttraining's binary_logloss: 0.269003\tvalid_1's auc: 0.846008\tvalid_1's binary_logloss: 0.296347\n",
      "*********************\n",
      "roc auc estimado:  0.853330422301886\n",
      "roc auc varianza:  0.000894862383652377\n"
     ]
    }
   ],
   "source": [
    "test_probs, fi = cross_validation_lightgbm(train, y_train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "scientific-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs.name='target'\n",
    "test_probs.to_csv('../results/lighgbm_with_1320features_0.85333.csv')   ####### score de 0.85577 en la tabla publica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "successful-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('../data/train_features1320_score_0.85577.pkl')\n",
    "test.to_pickle('../data/test_features1320_score_0.85577.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
