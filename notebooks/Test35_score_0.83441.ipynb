{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/interbank20/sample_submission.csv\n/kaggle/input/interbank20/y_train.csv\n/kaggle/input/interbank20/sunat_test.csv\n/kaggle/input/interbank20/rcc_test.csv\n/kaggle/input/interbank20/se_test.csv\n/kaggle/input/interbank20/sunat_train.csv\n/kaggle/input/interbank20/se_train.csv\n/kaggle/input/interbank20/censo_test.csv\n/kaggle/input/interbank20/productos.csv\n/kaggle/input/interbank20/censo_train.csv\n/kaggle/input/interbank20/rcc_train.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Load RCC"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"rcc_train = pd.read_csv('/kaggle/input/interbank20/rcc_train.csv')\nrcc_test = pd.read_csv('/kaggle/input/interbank20/rcc_test.csv')\ny_train = pd.read_csv('/kaggle/input/interbank20/y_train.csv', index_col='key_value')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bins = [-1, 0, 10, 20, 30, 60, 90, 180, 360, 720, float(\"inf\")]\n# rcc_train[\"condicion\"] = pd.cut(rcc_train.condicion, bins, labels = range(0,10)).astype('int32')\n# rcc_test[\"condicion\"] = pd.cut(rcc_test.condicion, bins, labels = range(0,10)).astype('int32')\nrcc_test['cod_instit_financiera'].fillna(rcc_test['cod_instit_financiera'].value_counts().index[0], inplace=True)\nrcc_test['PRODUCTO'].fillna(rcc_test['PRODUCTO'].value_counts().index[0], inplace=True)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_ = dict(zip(list(rcc_train.dtypes[rcc_train.dtypes == int].index), ['int32']*len(rcc_train.dtypes[rcc_train.dtypes == int].index)))\nrcc_train = rcc_train.astype(dict_)\nrcc_test = rcc_test.astype(dict_)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics as stat\nimport numpy as np\ndef calculate_mode(x):\n    try:\n        moda=stat.mode(x)\n    except:\n        moda=np.nan\n    return moda","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm \nimport gc\nlist_rcc_train_agg = []\n\nmoda=lambda x: calculate_mode(x)\nmoda.__name__='mode'\nagg_rcc = {'condicion':['max'],\n           'saldo':['max'],\n           'cod_instit_financiera':['nunique',moda],\n           'PRODUCTO':['nunique',moda],\n           'COD_CLASIFICACION_DEUDOR':['nunique','max','min','sum',moda]\n          }","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n,i in enumerate(tqdm(sorted(set(rcc_train.codmes),reverse=True))):\n#     if i in [201802,201712,201709,201703]:\n    if n in [0,1,2,3,4,5,11]:\n        for c in ['tipo_credito','RIESGO_DIRECTO','COD_CLASIFICACION_DEUDOR']:\n            print(f'haciendo {c}')\n            rcc_train_agg = rcc_train[rcc_train.codmes>=i].groupby(['key_value', c]).saldo.sum().unstack(level = 1, fill_value=0)\n            rcc_train_agg.columns = [f'{rcc_train_agg.columns.name}_{c}_saldo_ult{n+1}meses' for c in rcc_train_agg.columns]\n            list_rcc_train_agg.append(rcc_train_agg)\n            gc.collect()\n        for c in ['tipo_credito','RIESGO_DIRECTO','COD_CLASIFICACION_DEUDOR']:\n            print(f'haciendo {c}')\n            rcc_train_agg = rcc_train[rcc_train.codmes>=i].groupby(['key_value', c]).condicion.sum().unstack(level = 1, fill_value=0)\n            rcc_train_agg.columns = [f'{rcc_train_agg.columns.name}_{c}_condicion_ult{n+1}meses' for c in rcc_train_agg.columns]\n            list_rcc_train_agg.append(rcc_train_agg)\n            gc.collect()\n\n        print(f'haciendo agg ')\n        rcc_train_agg = rcc_train[rcc_train.codmes>=i].groupby('key_value').agg(agg_rcc)\n        rcc_train_agg.columns = [i+'_'+j+f'_ult{n+1}mes' for i,j in rcc_train_agg.columns]\n        list_rcc_train_agg.append(rcc_train_agg)\n        gc.collect()\n        \nrcc_train_ = pd.concat(list_rcc_train_agg, axis=1)\ndel rcc_train, list_rcc_train_agg","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13bdb78c612c4412a52faa076fd42fce"}},"metadata":{}},{"output_type":"stream","text":"haciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm \nlist_rcc_test_agg = []\nfor n,i in enumerate(tqdm(sorted(set(rcc_test.codmes),reverse=True))):\n#     if i in [201902,201812,201809,201803]:\n    if n in [0,1,2,3,4,5,11]:\n        for c in ['tipo_credito','RIESGO_DIRECTO','COD_CLASIFICACION_DEUDOR']:\n            print(f'haciendo {c}')\n            rcc_test_agg = rcc_test[rcc_test.codmes>=i].groupby(['key_value', c]).saldo.sum().unstack(level = 1, fill_value=0)\n            rcc_test_agg.columns = [f'{rcc_test_agg.columns.name}_{c}_saldo_ult{n+1}meses' for c in rcc_test_agg.columns]\n            list_rcc_test_agg.append(rcc_test_agg)\n            gc.collect()\n        for c in ['tipo_credito','RIESGO_DIRECTO','COD_CLASIFICACION_DEUDOR']:\n            print(f'haciendo {c}')\n            rcc_test_agg = rcc_test[rcc_test.codmes>=i].groupby(['key_value', c]).condicion.sum().unstack(level = 1, fill_value=0)\n            rcc_test_agg.columns = [f'{rcc_test_agg.columns.name}_{c}_condicion_ult{n+1}meses' for c in rcc_test_agg.columns]\n            list_rcc_test_agg.append(rcc_test_agg)\n            gc.collect()\n        print(f'haciendo agg')    \n        rcc_test_agg = rcc_test[rcc_test.codmes>=i].groupby('key_value').agg(agg_rcc)\n        rcc_test_agg.columns = [i+'_'+j+f'_ult{n+1}mes' for i,j in rcc_test_agg.columns]\n        list_rcc_test_agg.append(rcc_test_agg)\n        gc.collect()\n\nrcc_test_ = pd.concat(list_rcc_test_agg, axis=1)\ndel rcc_test, list_rcc_test_agg","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3447f355363d4a01a21e0980cb462d9f"}},"metadata":{}},{"output_type":"stream","text":"haciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo tipo_credito\nhaciendo RIESGO_DIRECTO\nhaciendo COD_CLASIFICACION_DEUDOR\nhaciendo agg\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rcc_train_.shape, rcc_test_.shape)\nkeep_columns = list(set(rcc_train_.columns).intersection(rcc_test_.columns))\nrcc_train_ = rcc_train_[keep_columns].copy()\nrcc_test_ = rcc_test_[keep_columns].copy()\nprint(rcc_train_.shape, rcc_test_.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(358487, 343) (396666, 357)\n(358487, 343) (396666, 343)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = rcc_train_.copy()\ntest = rcc_test_.copy()\ndel rcc_train_, rcc_test_","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [1,2,3,4,5,6,12]:\n    train[f'ratio_condicion_saldo_ult{i}mes'] = train[f'condicion_max_ult{i}mes']/train[f'saldo_max_ult{i}mes']\n    test[f'ratio_condicion_saldo_ult{i}mes'] = test[f'condicion_max_ult{i}mes']/test[f'saldo_max_ult{i}mes']","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### imputar datos categoricos\nvar_categ = [i for i in train.columns if 'mode' in i]\nfor i in var_categ:\n    train[i] = train[i].fillna(train[i].value_counts().index[0])\n    test[i] = test[i].fillna(train[i].value_counts().index[0])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### mean encoding\n### ojo, en el test hay missing values pero pocos\ntrain = pd.concat([train, y_train], axis=1)\nfor i in var_categ:\n    me = train.groupby([i])['target'].mean().to_dict() \n    train[f'{i}_me'] =  train[i].map(me) \n    test[f'{i}_me'] =  test[i].map(me)\n    ### imputar datos faltantes\n    test[f'{i}_me'] =  test[f'{i}_me'].fillna(train[f'{i}_me'].median())\n    \ntrain.drop('target', axis=1, inplace=True)\ntrain.drop(var_categ, axis=1, inplace=True)\ntest.drop(var_categ, axis=1, inplace=True)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load SE"},{"metadata":{"trusted":true},"cell_type":"code","source":"se_train = pd.read_csv('/kaggle/input/interbank20/se_train.csv', index_col='key_value')\nse_test = pd.read_csv('/kaggle/input/interbank20/se_test.csv', index_col='key_value')\n# edad y cod_ubi tienen valores nulos con cerca de 1% cada uno","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_ = {'sexo':'int32',\n 'est_cvl':'int32',\n 'sit_lab':'int32',\n 'cod_ocu':'int32',\n 'ctd_hijos':'int32',\n 'flg_sin_email':'int32',\n 'ctd_veh':'int32',\n 'lgr_vot':'int32',\n 'prv':'int32',\n 'dto':'int32',\n 'rgn':'int32',\n 'tip_lvledu':'int32'}\nse_train = se_train.astype(dict_)\nse_test = se_test.astype(dict_)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### imputar datos faltantes en la base se_[train/test]\nse_train['edad'].fillna(se_train['edad'].median(), inplace=True)\nse_test['edad'].fillna(se_train['edad'].median(), inplace=True)\nse_train['cod_ubi'].fillna(se_train['cod_ubi'].median(), inplace=True)\nse_test['cod_ubi'].fillna(se_train['cod_ubi'].median(), inplace=True)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_categ=['sit_lab','lgr_vot','sexo','rgn','tip_lvledu','flg_sin_email','prv','est_cvl','cod_ocu','dto']\n# var_caunti=['edad','ctd_hijos','ctd_veh','cod_ubi']\nse_train['target'] = y_train.loc[se_train.index]\nfor i in var_categ:\n    me = se_train.groupby([i])['target'].mean().to_dict() \n    se_train[f'{i}_me'] =  se_train[i].map(me) \n    se_test[f'{i}_me'] =  se_test[i].map(me)\n    ### imputar datos faltantes\n    se_test[f'{i}_me'] =  se_test[f'{i}_me'].fillna(se_train[f'{i}_me'].median())\nse_train.drop('target', axis=1, inplace=True)\nse_train.drop(var_categ, axis=1, inplace=True)\nse_test.drop(var_categ, axis=1, inplace=True)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.join(se_train) ### Ojo 57 valores perdidos\ntest = test.join(se_test)\ndel se_train, se_test","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### imputar valores faltantes\nvar_caunti = ['lgr_vot_me','sit_lab_me','cod_ubi','tip_lvledu_me','prv_me','rgn_me',\n 'ctd_hijos','edad','cod_ocu_me','ctd_veh','est_cvl_me','dto_me','flg_sin_email_me','sexo_me']\nfor i in var_caunti:\n    train[i] = train[i].fillna(train[i].median())\n    test[i] = test[i].fillna(train[i].median())\ngc.collect()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"24"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Load Sunat"},{"metadata":{"trusted":true},"cell_type":"code","source":"sunat_train = pd.read_csv('/kaggle/input/interbank20/sunat_train.csv')\nsunat_test = pd.read_csv('/kaggle/input/interbank20/sunat_test.csv')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### eliminar registros duplicados\nsunat_train.drop_duplicates(inplace=True)\nsunat_test.drop_duplicates(inplace=True)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_ = dict(zip(list(sunat_train.dtypes[sunat_train.dtypes == int].index), ['int32']*len(sunat_train.dtypes[sunat_train.dtypes == int].index)))\nsunat_train = sunat_train.astype(dict_)\nsunat_test = sunat_test.astype(dict_)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics as stat\nimport numpy as np\ndef calculate_mode(x):\n    try:\n        moda=stat.mode(x)\n    except:\n        moda=np.nan\n    return moda\nfrom tqdm.notebook import tqdm \nmoda=lambda x: calculate_mode(x)\nmoda.__name__='mode'\nagg_sunat = {'tipcontribuyente':['nunique',moda],\n           'tippersona':['nunique',moda],\n           'ciiu':['nunique', moda],\n           'ubigeo':['nunique',moda],\n           'condiciondomicilio':['nunique',moda],\n           'estadocontribuyente':['nunique',moda],\n           'codvia':['nunique',moda],\n           'codzona':['nunique',moda],\n           'contabilidad':['nunique',moda],\n           'facturacion':['nunique',moda],\n           'domiciliado':['nunique',moda],\n           'comercioexterior':['nunique',moda],\n           'cargorele':['nunique',moda],\n           'codentidadtributo':['nunique',moda],\n           'estadotributo':['nunique',moda],\n           'fecalta':['sum', 'nunique'],\n           'fecbaja':['sum', 'nunique'],\n          }","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sunat_train_ = sunat_train.groupby('key_value').agg(agg_sunat)\nsunat_train_.columns = [i+'_'+j for i,j in sunat_train_.columns]\nsunat_test_ = sunat_test.groupby('key_value').agg(agg_sunat)\nsunat_test_.columns = [i+'_'+j for i,j in sunat_test_.columns]\ndel sunat_train, sunat_test","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# var_categ = [i for i in sunat_train_.columns if 'mode' in i]\n# for i in var_categ:\n#     sunat_train_[i] = sunat_train_[i].fillna(sunat_train_[i].value_counts().index[0])\n#     sunat_test_[i] = sunat_test_[i].fillna(sunat_train_[i].value_counts().index[0])","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sunat_train_['target'] = y_train.loc[sunat_train_.index]\n# for i in var_categ:\n#     me = sunat_train_.groupby([i])['target'].mean().to_dict() \n#     sunat_train_[f'{i}_me'] =  sunat_train_[i].map(me) \n#     sunat_test_[f'{i}_me'] =  sunat_test_[i].map(me)\n#     ### imputar datos faltantes\n#     sunat_test_[f'{i}_me'] =  sunat_test_[f'{i}_me'].fillna(sunat_train_[f'{i}_me'].median())\n# sunat_train_.drop('target', axis=1, inplace=True)\n# sunat_train_.drop(var_categ, axis=1, inplace=True)\n# sunat_test_.drop(var_categ, axis=1, inplace=True)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.join(sunat_train_)\ntest = test.join(sunat_test_)\ntrain.shape, test.shape","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"((358487, 398), (396666, 398))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isna().sum().sort_values().tail(35)","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"RIESGO_DIRECTO_2_condicion_ult3meses         0\ncontabilidad_nunique                    142863\nfacturacion_nunique                     142863\ndomiciliado_nunique                     142863\ncomercioexterior_nunique                142863\nfecalta_sum                             142863\ncodentidadtributo_nunique               142863\nestadotributo_nunique                   142863\nfecalta_nunique                         142863\ncodzona_nunique                         142863\ncargorele_nunique                       142863\ncodvia_nunique                          142863\nubigeo_nunique                          142863\nestadocontribuyente_nunique             142863\nfecbaja_sum                             142863\ntipcontribuyente_nunique                142863\ntippersona_nunique                      142863\nciiu_nunique                            142863\nfecbaja_nunique                         142863\ncondiciondomicilio_nunique              142863\ncondiciondomicilio_mode                 146526\nestadotributo_mode                      150368\ncodentidadtributo_mode                  151505\nfacturacion_mode                        152047\nubigeo_mode                             152647\nestadocontribuyente_mode                154535\ncontabilidad_mode                       155309\ncomercioexterior_mode                   156001\ncodvia_mode                             156224\ncodzona_mode                            157212\ntippersona_mode                         161365\ndomiciliado_mode                        161430\nciiu_mode                               163155\ncargorele_mode                          163351\ntipcontribuyente_mode                   164486\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# var_aux = list(train.isna().sum().sort_values().tail(34).index)\n# var_categ = [i for i in var_aux if 'mode' in i]\n# var_cuanti = [i for i in var_aux if 'mode' not in i]\n# len(var_aux), len(var_categ), len(var_cuanti)\n\n# for i in var_cuanti:\n#     train[i] = train[i].fillna(train[i].median())\n#     test[i] = test[i].fillna(train[i].median())\n# for i in var_categ:\n#     train[i] = train[i].fillna(train[i].value_counts().index[0])\n#     test[i] = test[i].fillna(train[i].value_counts().index[0])","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# var_cuanti = ['fecbaja_nunique', 'tipcontribuyente_mode_me', 'tippersona_mode_me', 'ciiu_mode_me',\n# 'ubigeo_mode_me', 'condiciondomicilio_mode_me', 'estadocontribuyente_mode_me', \n# 'contabilidad_mode_me','codzona_mode_me', 'facturacion_mode_me', 'domiciliado_mode_me', \n# 'comercioexterior_mode_me', 'fecbaja_sum', 'cargorele_mode_me', 'codvia_mode_me', \n# 'fecalta_nunique', 'codvia_nunique', 'estadotributo_nunique', 'codentidadtributo_mode_me', \n# 'tipcontribuyente_nunique','tippersona_nunique', 'ciiu_nunique', 'ubigeo_nunique',\n# 'condiciondomicilio_nunique','fecalta_sum', 'estadocontribuyente_nunique',\n# 'contabilidad_nunique', 'facturacion_nunique','domiciliado_nunique', 'comercioexterior_nunique',\n# 'cargorele_nunique', 'codentidadtributo_nunique', 'codzona_nunique', 'estadotributo_mode_me']\n# for i in var_cuanti:\n#     train[i] = train[i].fillna(train[i].median())\n#     test[i] = test[i].fillna(train[i].median())","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"keep_columns = set(train.columns).intersection(test.columns)\ntrain=train[keep_columns].copy()\ntest=test[keep_columns].copy()\ntrain.shape, test.shape","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"((358487, 398), (396666, 398))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostClassifier\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# import numpy as np\n# folds = [train.index[t] for t, v in KFold(5).split(train)]\n# test_probs = []\n# train_probs = []\n# fi = []\n# for i, idx in enumerate(folds):\n#     print(\"*\"*10, i, \"*\"*10)\n#     Xt = train.loc[idx]\n#     yt = y_train.loc[Xt.index]\n\n#     Xv = train.drop(Xt.index)\n#     yv = y_train.loc[Xv.index]\n\n#     learner = CatBoostClassifier(n_estimators=1000,  eval_metric = 'AUC', max_depth = 6)\n#     learner.fit(Xt, yt,  early_stopping_rounds=10, \n#                 eval_set=[(Xt, yt), (Xv, yv)], verbose=50) # cat_features = var_categ_index,\n#     test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n#     train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n#     fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n#     gc.collect()\n# test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n# train_probs = pd.concat(train_probs)\n# fi = pd.concat(fi, axis=1).mean(axis=1)\n# print(\"*\" * 21)\n# print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n# print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fi.sort_values(ascending=False).head(50)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from lightgbm import LGBMClassifier\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# import numpy as np\n# folds = [train.index[t] for t, v in KFold(5).split(train)]\n# test_probs = []\n# train_probs = []\n# fi = []\n# for i, idx in enumerate(folds):\n#     print(\"*\"*10, i, \"*\"*10)\n#     Xt = train.loc[idx]\n#     yt = y_train.loc[Xt.index]\n\n#     Xv = train.drop(Xt.index)\n#     yv = y_train.loc[Xv.index]\n\n#     learner = LGBMClassifier(n_estimators=1000, max_depth = 6, boosting_type='gbdt', min_child_samples=1000)\n#     learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n#                 eval_set=[(Xt, yt), (Xv, yv)], verbose=50)\n#     test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n#     train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n#     fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n\n# test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n# train_probs = pd.concat(train_probs)\n# fi = pd.concat(fi, axis=1).mean(axis=1)\n# print(\"*\" * 21)\n# print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n# print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  ","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fi.sort_values(ascending=False).head(50)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostClassifier\n# from sklearn.model_selection import ParameterGrid\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import KFold\n# folds = [train.index[t] for t, v in KFold(5).split(train)]\n# params = ParameterGrid({\"min_child_samples\": [150, 250, 500, 1000], \"boosting_type\": [\"Plain\"]}) # Ordered\n# best_score = 0\n# best_probs = []\n# for param in params:\n#     test_probs = []\n#     train_probs = []\n#     p  = \"///\".join([f\"{k}={v}\" for k, v in param.items()])\n#     print(\"*\"*10, p, \"*\"*10)\n#     for i, idx in enumerate(folds):\n#         Xt = train.loc[idx]\n#         yt = y_train.loc[Xt.index]\n\n#         Xv = train.drop(Xt.index)\n#         yv = y_train.loc[Xv.index]\n\n#         learner = CatBoostClassifier(n_estimators=1000,  eval_metric = 'AUC', **param)\n#         learner.fit(Xt, yt,  early_stopping_rounds=10, \n#                     eval_set=[(Xt, yt), (Xv, yv)], verbose=100) \n\n#         test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n#         train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n\n#     test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n#     train_probs = pd.concat(train_probs)\n#     score = roc_auc_score(y_train, train_probs.loc[y_train.index])\n#     print(f\"roc auc estimado para {p}: {score}\")\n#     if score > best_score:\n#         print(\"*\"*10, f\"{p} es el nuevo mejor modelo\", \"*\"*10)\n#         best_score = score\n#         best_probs = test_probs","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc auc estimado para boosting_type=Ordered///min_child_samples=150: 0.839757753147848\n# ********** boosting_type=Ordered///min_child_samples=150 es el nuevo mejor modelo **********\n\n# roc auc estimado para boosting_type=Plain///min_child_samples=150: 0.8407009481328498\n# ********** boosting_type=Plain///min_child_samples=150 es el nuevo mejor modelo **********\n\n# roc auc estimado para boosting_type=Plain///min_child_samples=250: 0.8407009481328498\n\n# roc auc estimado para boosting_type=Plain///min_child_samples=500: 0.8407009481328498\n\n# roc auc estimado para boosting_type=Plain///min_child_samples=1000: 0.8407009481328498","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import ParameterGrid\n# folds = [train.index[t] for t, v in KFold(5).split(train)]\n\n# params = ParameterGrid({\"min_child_samples\": [150, 250, 500, 1000], \"boosting_type\": [\"gbdt\", \"goss\"]})\n# best_score = 0\n# best_probs = []\n# for param in params:\n#     test_probs = []\n#     train_probs = []\n#     p  = \"///\".join([f\"{k}={v}\" for k, v in param.items()])\n#     print(\"*\"*10, p, \"*\"*10)\n#     for i, idx in enumerate(folds):\n#         Xt = train.loc[idx]\n#         yt = y_train.loc[Xt.index]\n\n#         Xv = train.drop(Xt.index)\n#         yv = y_train.loc[Xv.index]\n\n#         learner = LGBMClassifier(n_estimators=1000, **param)\n#         learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n#                     eval_set=[(Xt, yt), (Xv, yv)], verbose=False)\n#         test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n#         train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n\n#     test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n#     train_probs = pd.concat(train_probs)\n#     score = roc_auc_score(y_train, train_probs.loc[y_train.index])\n#     print(f\"roc auc estimado para {p}: {score}\")\n#     if score > best_score:\n#         print(\"*\"*10, f\"{p} es el nuevo mejor modelo\", \"*\"*10)\n#         best_score = score\n#         best_probs = test_probs","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc auc estimado:  0.860778375567941  # roc auc estimado:  0.8287296558597061 benchmark\n\n# roc auc estimado:  0.8235666881996343 solo considerando rcc, inputando datos categoricos. con 4 mes\n# roc auc varianza:  0.0005453571957666847\n\n# roc auc estimado:  0.8236751116856392 solo considerando rcc, inputando datos categoricos. con 6 mes\n# roc auc varianza:  0.0007266775450365375\n\n# roc auc estimado:  0.8240426706542976 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0006480438484228306\n\n# roc auc estimado:  0.8358995025496325   solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.000799546878111712  y incluyendo se sin imputar datos\n\n# roc auc estimado:  0.8362318848230975    solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0006670589830583723 y incluyendo la base se imputando edad y cod_ubi\n\n# roc auc estimado:  0.8357779560666587  solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0008281941487650447 y incluyendo la base se imputando edad y cod_ubi. y en base final \n\n# roc auc estimado:  0.8386997825126665  solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0007378701891037694 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding\n\n# roc auc estimado:  0.8390378213410135 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0007879483415566218 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding. Impuntando la base final\n#### 0.83049 es el score en el leaderboard\n\n# roc auc estimado:  0.860778375567941 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0007522563589463705 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding. \n#                                         Add censo sin imputar datos\n#### Hay un sobreajuste de los datos (0.81290)\n\n# roc auc estimado:  0.8601038804961594 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0007408029176933889 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding. \n#                                         Add censo. Inputando datos en la base final \n####  Hay un sobreajuste de los datos (0.81335)\n\n# roc auc estimado:  0.8403745150148406 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0007145134831505686 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat, sin imputar datos \n#### 0.83169 es el score en el leaderboard\n\n# roc auc estimado:  0.8404409620195707 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0007187836690898979 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat, imputando datos en la base final\n\n# roc auc estimado:  0.8424448270443908 solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  0.0006541668625712339 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat con Mean Encoding. Inputando en la base final\n#### 0.82922 es el score en el leaderboard\n\n# roc auc estimado:  0.8400602964442501 solo considerando rcc, inputando datos categoricos. con 12 mes. Mean_encoding\n# roc auc varianza:  0.0007915113545841123 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat, sin imputar datos \n\n# roc auc estimado:  0.8404655548713938 solo considerando rcc, inputando datos categoricos. con 12 mes. Mean_encoding\n# roc auc varianza:  0.0007525289304731753 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat, sin imputar datos y eliminando COD_CLASIFICACION_DEUDOR_sum_ult2mes\n\n# roc auc estimado:  0.835370939961718 solo considerando rcc, inputando datos categoricos. con 12 mes. Mean_encoding\n# roc auc varianza:  0.0007997947306923314 y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat, sin imputar datos y eliminando COD_CLASIFICACION_DEUDOR_sum_ult2mes\n#                                          eliminando variables correlacionadas con 211 variables\n\n# roc auc estimado:  **************** solo considerando rcc, inputando datos categoricos. con 6 mes. Mean_encoding\n# roc auc varianza:  **************** y incluyendo la base se imputando edad y cod_ubi con Mean Encoding.\n#                                         Add sunat, sin imputar datos. Con modelo ensamblado de CatBoost y LightGBM\n#### 0.83292 score en el leaderboard","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nlearner_ = CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth = 6)\nlearner_.fit(train, y_train,  early_stopping_rounds=10, verbose = 50)","execution_count":41,"outputs":[{"output_type":"stream","text":"Learning rate set to 0.126968\n0:\ttotal: 222ms\tremaining: 3m 41s\n50:\ttotal: 9.01s\tremaining: 2m 47s\n100:\ttotal: 17.8s\tremaining: 2m 38s\n150:\ttotal: 25.9s\tremaining: 2m 25s\n200:\ttotal: 34.4s\tremaining: 2m 16s\n250:\ttotal: 42.7s\tremaining: 2m 7s\n300:\ttotal: 51.6s\tremaining: 1m 59s\n350:\ttotal: 1m\tremaining: 1m 51s\n400:\ttotal: 1m 8s\tremaining: 1m 41s\n450:\ttotal: 1m 16s\tremaining: 1m 33s\n500:\ttotal: 1m 25s\tremaining: 1m 24s\n550:\ttotal: 1m 33s\tremaining: 1m 16s\n600:\ttotal: 1m 41s\tremaining: 1m 7s\n650:\ttotal: 1m 49s\tremaining: 58.8s\n700:\ttotal: 1m 58s\tremaining: 50.6s\n750:\ttotal: 2m 6s\tremaining: 42.1s\n800:\ttotal: 2m 15s\tremaining: 33.6s\n850:\ttotal: 2m 24s\tremaining: 25.2s\n900:\ttotal: 2m 32s\tremaining: 16.7s\n950:\ttotal: 2m 40s\tremaining: 8.27s\n999:\ttotal: 2m 48s\tremaining: 0us\n","name":"stdout"},{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x7f354fe60150>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nlearner2 = LGBMClassifier(n_estimators=1000, max_depth=6, boosting_type='gbdt', min_child_samples=1000)\nlearner2.fit(train, y_train, eval_metric=\"auc\", verbose=50)","execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(**kwargs)\n","name":"stderr"},{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"LGBMClassifier(max_depth=6, min_child_samples=1000, n_estimators=1000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probs_ = pd.Series(learner_.predict_proba(test)[:, -1], index=test.index, name=\"target\")\ntest_probs2 = pd.Series(learner2.predict_proba(test)[:, -1], index=test.index, name=\"target\")\ntest_probs_mean = test_probs_*0.5 + test_probs2*0.5\ntest_probs_mean.name = 'target'","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probs_mean.name = \"target\"\ntest_probs_mean.to_csv(\"test35.csv\")","execution_count":44,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href = 'test35.csv'>Download csv</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner_ = CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth = 8)\nlearner_.fit(train, y_train,  early_stopping_rounds=10, verbose = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi_ = pd.Series(learner_.feature_importances_ / learner_.feature_importances_.sum(), index=train.columns)\nfi_.sort_values(ascending=False).head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learner_ = learner2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probs_ = pd.Series(learner_.predict_proba(test)[:, -1], index=test.index, name=\"target\")\ntest_probs_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_probs_.name = \"target\"\ntest_probs_.to_csv(\"test30.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=test30.csv>Download csv</a>"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}