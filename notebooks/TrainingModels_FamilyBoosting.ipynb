{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "through-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "friendly-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data'\n",
    "y_train = pd.read_csv(f'{path}/y_train.csv', index_col = 'key_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "iraqi-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind='pie', autopct='%1.0f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-appreciation",
   "metadata": {},
   "source": [
    "## Entrenando LGBM con hiperparÃ¡metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "living-trademark",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1320), (396666, 1320))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_features1320_score_0.85577.pkl') \n",
    "test = pd.read_pickle('../data/test_features1320_score_0.85577.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "burning-germany",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.865319\ttraining's binary_logloss: 0.285035\tvalid_1's auc: 0.85101\tvalid_1's binary_logloss: 0.296508\n",
      "[200]\ttraining's auc: 0.879707\ttraining's binary_logloss: 0.273318\tvalid_1's auc: 0.854022\tvalid_1's binary_logloss: 0.294056\n",
      "Early stopping, best iteration is:\n",
      "[284]\ttraining's auc: 0.88885\ttraining's binary_logloss: 0.265847\tvalid_1's auc: 0.854905\tvalid_1's binary_logloss: 0.293443\n",
      "********** 1 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.864997\ttraining's binary_logloss: 0.28516\tvalid_1's auc: 0.850819\tvalid_1's binary_logloss: 0.296441\n",
      "[200]\ttraining's auc: 0.879319\ttraining's binary_logloss: 0.273464\tvalid_1's auc: 0.85398\tvalid_1's binary_logloss: 0.293806\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's auc: 0.888196\ttraining's binary_logloss: 0.266213\tvalid_1's auc: 0.854742\tvalid_1's binary_logloss: 0.29319\n",
      "********** 2 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.865476\ttraining's binary_logloss: 0.285391\tvalid_1's auc: 0.853014\tvalid_1's binary_logloss: 0.294127\n",
      "[200]\ttraining's auc: 0.879691\ttraining's binary_logloss: 0.273728\tvalid_1's auc: 0.855846\tvalid_1's binary_logloss: 0.291543\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's auc: 0.881718\ttraining's binary_logloss: 0.272108\tvalid_1's auc: 0.856051\tvalid_1's binary_logloss: 0.291387\n",
      "********** 3 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.865436\ttraining's binary_logloss: 0.285419\tvalid_1's auc: 0.851865\tvalid_1's binary_logloss: 0.294844\n",
      "[200]\ttraining's auc: 0.87977\ttraining's binary_logloss: 0.273612\tvalid_1's auc: 0.854416\tvalid_1's binary_logloss: 0.292223\n",
      "Early stopping, best iteration is:\n",
      "[231]\ttraining's auc: 0.88345\ttraining's binary_logloss: 0.270631\tvalid_1's auc: 0.854755\tvalid_1's binary_logloss: 0.291907\n",
      "********** 4 **********\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\ttraining's auc: 0.867305\ttraining's binary_logloss: 0.284381\tvalid_1's auc: 0.843265\tvalid_1's binary_logloss: 0.298749\n",
      "[200]\ttraining's auc: 0.881898\ttraining's binary_logloss: 0.27236\tvalid_1's auc: 0.84569\tvalid_1's binary_logloss: 0.296586\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's auc: 0.885987\ttraining's binary_logloss: 0.269003\tvalid_1's auc: 0.846008\tvalid_1's binary_logloss: 0.296347\n",
      "*********************\n",
      "roc auc estimado:  0.853330422301886\n",
      "roc auc varianza:  0.000894862383652377\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = LGBMClassifier(n_estimators=1000, boosting_type='gbdt',min_child_samples=1500, colsample_bytree=0.8,\n",
    "                   subsample=0.8, max_bin=200, learning_rate=0.1)\n",
    "    \n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chronic-absorption",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCTO_1_saldoMean_ult1meses                       0.008535\n",
       "PRODUCTO_1_saldoMax_ult1meses                        0.008169\n",
       "edad                                                 0.008121\n",
       "ubigeo_mode                                          0.007866\n",
       "PRODUCTO_1_saldoSum_ult1meses                        0.005791\n",
       "PRODUCTO_1_saldoMedian_ult1meses                     0.005591\n",
       "sexo_0                                               0.004987\n",
       "PRODUCTO_3_saldoUnique_ult12meses                    0.004789\n",
       "estadocontribuyente_0                                0.004754\n",
       "RIESGO_DIRECTO_1_saldoStd_ult1meses                  0.004300\n",
       "PRODUCTO_0_saldoMin_ult12meses                       0.004208\n",
       "cod_instit_financiera_10_saldoStd_ult1meses          0.004180\n",
       "PRODUCTO_6_saldoSum_ult12meses                       0.004148\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.004094\n",
       "PRODUCTO_4_saldoStd_ult12meses                       0.004014\n",
       "PRODUCTO_3_saldoMean_ult1meses                       0.003921\n",
       "PRODUCTO_1_saldoStd_ult12meses                       0.003868\n",
       "PRODUCTO_1_saldoMin_ult1meses                        0.003810\n",
       "PRODUCTO_0_saldoStd_ult12meses                       0.003758\n",
       "RIESGO_DIRECTO_1_saldoMin_ult1meses                  0.003740\n",
       "PRODUCTO_3_saldoMedian_ult1meses                     0.003723\n",
       "ciiu_mode                                            0.003681\n",
       "PRODUCTO_8_saldoSum_ult12meses                       0.003653\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.003616\n",
       "PRODUCTO_6_saldoMax_ult1meses                        0.003499\n",
       "PRODUCTO_12_saldoMin_ult1meses                       0.003497\n",
       "PRODUCTO_0_saldoStd_ult1meses                        0.003476\n",
       "condicion_0_saldoUnique_ult12meses                   0.003456\n",
       "PRODUCTO_3_saldoMedian_ult12meses                    0.003450\n",
       "cod_instit_financiera_34_saldoUnique_ult12meses      0.003448\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult12meses              0.003408\n",
       "PRODUCTO_0_saldoMax_ult1meses                        0.003345\n",
       "PRODUCTO_6_saldoMean_ult12meses                      0.003316\n",
       "PRODUCTO_0_saldoMin_ult1meses                        0.003315\n",
       "fecalta_mean                                         0.003293\n",
       "PRODUCTO_6_saldoMin_ult12meses                       0.003255\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.003224\n",
       "PRODUCTO_3_saldoMin_ult1meses                        0.003200\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.003182\n",
       "PRODUCTO_8_saldoUnique_ult12meses                    0.003165\n",
       "PRODUCTO_1_saldoStd_ult1meses                        0.003143\n",
       "PRODUCTO_11_saldoMax_ult1meses                       0.003094\n",
       "PRODUCTO_8_saldoMin_ult12meses                       0.003082\n",
       "ctd_veh                                              0.002986\n",
       "fecalta_min                                          0.002957\n",
       "PRODUCTO_2_saldoUnique_ult12meses                    0.002945\n",
       "cod_instit_financiera_max_ult1mes                    0.002937\n",
       "PRODUCTO_3_saldoMin_ult12meses                       0.002796\n",
       "PRODUCTO_8_saldoMedian_ult12meses                    0.002793\n",
       "RIESGO_DIRECTO_1_saldoStd_ult12meses                 0.002789\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "horizontal-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adolescent-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_lightgbm = train_probs\n",
    "test_probs_lightgbm = test_probs\n",
    "train_probs_lightgbm.to_pickle('train_probs_lightgbm.pkl')\n",
    "test_probs_lightgbm.to_pickle('test_probs_lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-regard",
   "metadata": {},
   "source": [
    "## Catboost con parametros casi estandar\n",
    "### CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "helpful-radical",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1320), (396666, 1320))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_features1320_score_0.85577.pkl') \n",
    "test = pd.read_pickle('../data/test_features1320_score_0.85577.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "peripheral-sharing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7424907\ttest1: 0.7439484\tbest: 0.7439484 (0)\ttotal: 871ms\tremaining: 14m 29s\n",
      "100:\ttest: 0.8471984\ttest1: 0.8422880\tbest: 0.8422880 (100)\ttotal: 54.7s\tremaining: 8m 6s\n",
      "200:\ttest: 0.8576204\ttest1: 0.8475353\tbest: 0.8475353 (200)\ttotal: 1m 47s\tremaining: 7m 5s\n",
      "300:\ttest: 0.8651702\ttest1: 0.8496751\tbest: 0.8496775 (299)\ttotal: 2m 39s\tremaining: 6m 11s\n",
      "400:\ttest: 0.8713331\ttest1: 0.8509214\tbest: 0.8509214 (400)\ttotal: 3m 30s\tremaining: 5m 14s\n",
      "500:\ttest: 0.8763042\ttest1: 0.8515765\tbest: 0.8515909 (498)\ttotal: 4m 19s\tremaining: 4m 18s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.851979197\n",
      "bestIteration = 561\n",
      "\n",
      "Shrink model to first 562 iterations.\n",
      "********** 1 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7257203\ttest1: 0.7278298\tbest: 0.7278298 (0)\ttotal: 633ms\tremaining: 10m 31s\n",
      "100:\ttest: 0.8471016\ttest1: 0.8432364\tbest: 0.8432364 (100)\ttotal: 58s\tremaining: 8m 36s\n",
      "200:\ttest: 0.8573899\ttest1: 0.8484976\tbest: 0.8484976 (200)\ttotal: 1m 53s\tremaining: 7m 30s\n",
      "300:\ttest: 0.8648135\ttest1: 0.8510036\tbest: 0.8510036 (300)\ttotal: 2m 50s\tremaining: 6m 36s\n",
      "400:\ttest: 0.8705795\ttest1: 0.8521491\tbest: 0.8521491 (400)\ttotal: 3m 53s\tremaining: 5m 48s\n",
      "500:\ttest: 0.8758610\ttest1: 0.8528688\tbest: 0.8528688 (500)\ttotal: 4m 54s\tremaining: 4m 53s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.852892271\n",
      "bestIteration = 504\n",
      "\n",
      "Shrink model to first 505 iterations.\n",
      "********** 2 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7280854\ttest1: 0.7329040\tbest: 0.7329040 (0)\ttotal: 641ms\tremaining: 10m 40s\n",
      "100:\ttest: 0.8467483\ttest1: 0.8465781\tbest: 0.8465781 (100)\ttotal: 1m 8s\tremaining: 10m 13s\n",
      "200:\ttest: 0.8570986\ttest1: 0.8514691\tbest: 0.8514691 (200)\ttotal: 2m 15s\tremaining: 8m 59s\n",
      "300:\ttest: 0.8644403\ttest1: 0.8534645\tbest: 0.8534645 (300)\ttotal: 3m 18s\tremaining: 7m 40s\n",
      "400:\ttest: 0.8703062\ttest1: 0.8543948\tbest: 0.8544409 (397)\ttotal: 4m 21s\tremaining: 6m 30s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8544408733\n",
      "bestIteration = 397\n",
      "\n",
      "Shrink model to first 398 iterations.\n",
      "********** 3 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.7403539\ttest1: 0.7404733\tbest: 0.7404733 (0)\ttotal: 706ms\tremaining: 11m 45s\n",
      "100:\ttest: 0.8472247\ttest1: 0.8441165\tbest: 0.8441165 (100)\ttotal: 1m 10s\tremaining: 10m 27s\n",
      "200:\ttest: 0.8578175\ttest1: 0.8495305\tbest: 0.8495446 (199)\ttotal: 2m 17s\tremaining: 9m 4s\n",
      "300:\ttest: 0.8653937\ttest1: 0.8516978\tbest: 0.8517073 (299)\ttotal: 3m 20s\tremaining: 7m 45s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8517073281\n",
      "bestIteration = 299\n",
      "\n",
      "Shrink model to first 300 iterations.\n",
      "********** 4 **********\n",
      "Learning rate set to 0.128212\n",
      "0:\ttest: 0.6908205\ttest1: 0.6774929\tbest: 0.6774929 (0)\ttotal: 828ms\tremaining: 13m 46s\n",
      "100:\ttest: 0.8494862\ttest1: 0.8367014\tbest: 0.8367014 (100)\ttotal: 1m 11s\tremaining: 10m 36s\n",
      "200:\ttest: 0.8598161\ttest1: 0.8416830\tbest: 0.8416830 (200)\ttotal: 2m 14s\tremaining: 8m 53s\n",
      "300:\ttest: 0.8672451\ttest1: 0.8434598\tbest: 0.8434657 (299)\ttotal: 3m 19s\tremaining: 7m 43s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.8438188644\n",
      "bestIteration = 325\n",
      "\n",
      "Shrink model to first 326 iterations.\n",
      "*********************\n",
      "roc auc estimado:  0.8509935538080539\n",
      "roc auc varianza:  0.0009001924581872921\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index]\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index]\n",
    "\n",
    "    learner = CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth=6)\n",
    "    \n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, \n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sharp-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "israeli-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_catboost = train_probs\n",
    "test_probs_catboost = test_probs\n",
    "train_probs_catboost.to_pickle('train_probs_catboost.pkl')\n",
    "test_probs_catboost.to_pickle('test_probs_catboost.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-bermuda",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelo XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "interim-history",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1320), (396666, 1320))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_features1320_score_0.85577.pkl') \n",
    "test = pd.read_pickle('../data/test_features1320_score_0.85577.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "healthy-siemens",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\envs\\venv_datathon\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.71867\tvalidation_1-auc:0.72320\n",
      "[100]\tvalidation_0-auc:0.86630\tvalidation_1-auc:0.84686\n",
      "[159]\tvalidation_0-auc:0.87726\tvalidation_1-auc:0.84776\n",
      "********** 1 **********\n",
      "[0]\tvalidation_0-auc:0.72019\tvalidation_1-auc:0.71819\n",
      "[100]\tvalidation_0-auc:0.86656\tvalidation_1-auc:0.84752\n",
      "[112]\tvalidation_0-auc:0.86884\tvalidation_1-auc:0.84768\n",
      "********** 2 **********\n",
      "[0]\tvalidation_0-auc:0.71867\tvalidation_1-auc:0.72510\n",
      "[100]\tvalidation_0-auc:0.86763\tvalidation_1-auc:0.85002\n",
      "[175]\tvalidation_0-auc:0.88030\tvalidation_1-auc:0.85072\n",
      "********** 3 **********\n",
      "[0]\tvalidation_0-auc:0.72175\tvalidation_1-auc:0.72340\n",
      "[100]\tvalidation_0-auc:0.86695\tvalidation_1-auc:0.84898\n",
      "[130]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.84919\n",
      "********** 4 **********\n",
      "[0]\tvalidation_0-auc:0.72201\tvalidation_1-auc:0.70930\n",
      "[100]\tvalidation_0-auc:0.86989\tvalidation_1-auc:0.84073\n",
      "[143]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.84112\n",
      "*********************\n",
      "roc auc estimado:  0.8475722843014554\n",
      "roc auc varianza:  0.0007953881946119579\n"
     ]
    }
   ],
   "source": [
    "from xgboost  import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = XGBClassifier(n_estimators=1000, booster='gbtree', colsample_bytree=0.8, \n",
    "                            subsample = 0.8, max_depth=4,  learning_rate=0.3)\n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt), (Xv, yv)], verbose=100)\n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "informed-airfare",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCTO_12_saldoMin_ult1meses                      0.075974\n",
       "RIESGO_DIRECTO_2_saldoMean_ult1meses                0.052980\n",
       "RIESGO_DIRECTO_2_saldoMin_ult2meses                 0.045184\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMedian_ult1meses    0.042137\n",
       "COD_CLASIFICACION_DEUDOR_5_saldoMin_ult1meses       0.022472\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoStd_ult2meses       0.020933\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult4meses       0.020831\n",
       "PRODUCTO_12_saldoMax_ult1meses                      0.017672\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoUnique_ult4meses    0.016055\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMedian_ult4meses    0.015935\n",
       "tipo_credito_11_saldoMean_ult1meses                 0.015827\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoUnique_ult2meses    0.015041\n",
       "condicion_1_saldoMax_ult2meses                      0.013716\n",
       "RIESGO_DIRECTO_2_saldoMedian_ult1meses              0.012992\n",
       "RIESGO_DIRECTO_2_saldoMean_ult2meses                0.012878\n",
       "PRODUCTO_0_saldoMedian_ult1meses                    0.011044\n",
       "cod_instit_financiera_max_ult1mes                   0.009952\n",
       "cod_instit_financiera_46_saldoStd_ult1meses         0.009233\n",
       "RIESGO_DIRECTO_2_saldoMin_ult3meses                 0.007910\n",
       "cod_instit_financiera_32_saldoMin_ult1meses         0.007830\n",
       "cod_instit_financiera_55_saldoMax_ult12meses        0.007511\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoStd_ult3meses       0.007428\n",
       "PRODUCTO_3_saldoMean_ult1meses                      0.006868\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses             0.006712\n",
       "cod_instit_financiera_32_saldoUnique_ult12meses     0.006598\n",
       "cod_instit_financiera_32_saldoUnique_ult1meses      0.005916\n",
       "tipo_credito_12_saldoSum_ult1meses                  0.005893\n",
       "PRODUCTO_0_saldoSum_ult1meses                       0.005792\n",
       "PRODUCTO_2_saldoUnique_ult12meses                   0.005712\n",
       "cod_instit_financiera_max_ult3mes                   0.005619\n",
       "COD_CLASIFICACION_DEUDOR_3_saldoStd_ult5meses       0.005449\n",
       "PRODUCTO_0_saldoMin_ult1meses                       0.005286\n",
       "condicion_1_saldoMean_ult5meses                     0.005113\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMedian_ult6meses    0.004680\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                 0.004363\n",
       "cod_instit_financiera_46_saldoMin_ult1meses         0.004276\n",
       "cod_instit_financiera_32_saldoStd_ult1meses         0.004008\n",
       "condicion_1_saldoMean_ult1meses                     0.004004\n",
       "PRODUCTO_3_saldoMedian_ult1meses                    0.003703\n",
       "PRODUCTO_6_saldoMean_ult1meses                      0.003401\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMedian_ult7meses    0.003233\n",
       "PRODUCTO_3_saldoUnique_ult12meses                   0.003214\n",
       "PRODUCTO_nunique_ult2mes                            0.002794\n",
       "cod_instit_financiera_61_saldoUnique_ult12meses     0.002718\n",
       "PRODUCTO_6_saldoMin_ult12meses                      0.002563\n",
       "PRODUCTO_8_saldoMin_ult12meses                      0.002486\n",
       "PRODUCTO_6_saldoMax_ult1meses                       0.002484\n",
       "RIESGO_DIRECTO_1_saldoStd_ult1meses                 0.002482\n",
       "PRODUCTO_7_saldoMax_ult12meses                      0.002470\n",
       "condicion_1_saldoMax_ult3meses                      0.002427\n",
       "dtype: float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broke-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_xgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "outside-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_lightgbm_cf = train_probs\n",
    "test_probs_lightgbm_cf= test_probs\n",
    "train_probs_lightgbm_cf.to_pickle('train_probs_xgb.pkl')\n",
    "test_probs_lightgbm_cf.to_pickle('test_probs_xgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-transport",
   "metadata": {},
   "source": [
    "## Entrenando Neural Network Artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "finnish-sunday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1072), (396666, 1072))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_1072features_score_0.85381.pkl') \n",
    "test = pd.read_pickle('../data/test_1072features_score_0.85381.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "minor-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 722), (396666, 722))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### eliminar variable cuyo porcentaje de valores nulos es mayor al 90%\n",
    "aux = train.isna().sum()/len(train)\n",
    "drop_columns = list(aux[aux>=0.9].index)\n",
    "train.drop(drop_columns, axis=1, inplace=True)\n",
    "test.drop(drop_columns, axis=1, inplace=True)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "equivalent-rolling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7950576708840491"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.read_pickle('fi_lightgbm.pkl')\n",
    "fi.loc[train.columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "catholic-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_missing_values = list(train.isna().sum()[train.isna().sum()>0].index)\n",
    "len(var_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pursuant-jackson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 101, 95, 85, 103, 98, 79, 73)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_mode =[i for i in var_missing_values if \"mode\" in i]\n",
    "var_std =[i for i in var_missing_values if \"Std\" in i or \"std\" in i]\n",
    "var_unique =[i for i in var_missing_values if \"Unique\" in i or \"unique\" in i ]\n",
    "var_mean =[i for i in var_missing_values if \"Mean\" in i or \"mean\" in i]\n",
    "var_median =[i for i in var_missing_values if \"Median\" in i or \"median\" in i]\n",
    "var_sum =[i for i in var_missing_values if \"Sum\" in i or \"sum\" in i]\n",
    "var_max =[i for i in var_missing_values if \"Max\" in i or \"max\" in i]\n",
    "var_min =[i for i in var_missing_values if \"Min\" in i or \"min\" in i]\n",
    "len(var_mode), len(var_std), len(var_unique), len(var_mean), len(var_median), len(var_sum),len(var_max), len(var_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stable-ecuador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_total = var_mode+var_std+var_unique+var_mean+var_median+var_sum+var_max+var_min\n",
    "var_rest = list(set(var_missing_values).difference(var_total))\n",
    "len(set(var_total)), len(set(var_rest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-supplier",
   "metadata": {},
   "source": [
    "#### imputacion tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "surprising-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in var_mode:\n",
    "    train[i] = train[i].fillna(train[i].value_counts().index[0])\n",
    "    test[i] = test[i].fillna(train[i].value_counts().index[0])\n",
    "for i in var_std:\n",
    "    train[i] = train[i].fillna(0)   \n",
    "    test[i] = test[i].fillna(0)   \n",
    "for i in var_unique:\n",
    "    train[i] = train[i].fillna(0)   \n",
    "    test[i] = test[i].fillna(0)   \n",
    "for i in var_mean:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_median:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_sum:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_max:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_min:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_rest:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "useful-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "proved-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot(y_train):\n",
    "    one_hot =[]\n",
    "    for i in y_train.values:\n",
    "        aux=[]\n",
    "        for j in [0,1]:\n",
    "            if i==j:\n",
    "                aux.append(1)\n",
    "            else:\n",
    "                aux.append(0)\n",
    "        one_hot.append(aux)\n",
    "    return  np.array(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adult-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_keras(one_hot):\n",
    "    model_rnn = Sequential()\n",
    "    model_rnn.add(Dense(128,input_dim=len(train.columns),activation=\"relu\"))\n",
    "    model_rnn.add(Dropout(0.5))\n",
    "    model_rnn.add(Dense(len(one_hot[0]),activation=\"sigmoid\")) # sigmoid\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "#     sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    model_rnn.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['AUC'])\n",
    "    return model_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "first-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "premium-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_scaled, index=train.index, columns=train.columns)\n",
    "test = pd.DataFrame(test_scaled, index=test.index, columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pending-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 5s 13ms/step - loss: 0.3936 - auc: 0.9037\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3390 - auc: 0.9281\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3310 - auc: 0.9314\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3271 - auc: 0.9327\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3226 - auc: 0.9343\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3202 - auc: 0.9355\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3210 - auc: 0.9348\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3172 - auc: 0.9363\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3172 - auc: 0.9362\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3172 - auc: 0.9366\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3162 - auc: 0.9369\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3162 - auc: 0.9368\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3128 - auc: 0.9382\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3142 - auc: 0.9378\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3135 - auc: 0.9384\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3136 - auc: 0.9380\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3137 - auc: 0.9384\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3119 - auc: 0.9387: 3s - loss: 0.3136\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3146 - auc: 0.9379\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3142 - auc: 0.9388\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3124 - auc: 0.9395\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 4s 16ms/step - loss: 0.3139 - auc: 0.9387\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 5s 16ms/step - loss: 0.3106 - auc: 0.9395\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3101 - auc: 0.9402\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3102 - auc: 0.9393\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3124 - auc: 0.9393\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3088 - auc: 0.9404\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3083 - auc: 0.9403\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3089 - auc: 0.9399\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3095 - auc: 0.9398: 1s\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3077 - auc: 0.9403\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3079 - auc: 0.9406\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3069 - auc: 0.9407\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3099 - auc: 0.9403\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3093 - auc: 0.9397\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3063 - auc: 0.9411\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3077 - auc: 0.9413\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3047 - auc: 0.9415\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3068 - auc: 0.9406\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3170 - auc: 0.9403\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3087 - auc: 0.9415\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3095 - auc: 0.9399\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3068 - auc: 0.9410\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 4s 16ms/step - loss: 0.3083 - auc: 0.9410: 0s - loss: 0.30\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3056 - auc: 0.9414\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3090 - auc: 0.9409\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3055 - auc: 0.9420\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3055 - auc: 0.9414: 0s - loss: 0.3055 - auc: 0.94\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3039 - auc: 0.9419\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3054 - auc: 0.9420\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3030 - auc: 0.9426\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3080 - auc: 0.9419\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3049 - auc: 0.9419\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3073 - auc: 0.9416\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3061 - auc: 0.9414\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3040 - auc: 0.9420\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3072 - auc: 0.9422\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3039 - auc: 0.9424\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3034 - auc: 0.9422\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3043 - auc: 0.9420\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3026 - auc: 0.9427\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3046 - auc: 0.9422\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3044 - auc: 0.9422\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3035 - auc: 0.9423\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3043 - auc: 0.9421\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3035 - auc: 0.9425\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3066 - auc: 0.9423\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3078 - auc: 0.9421\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3044 - auc: 0.9420\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3041 - auc: 0.9422\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3029 - auc: 0.9429\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3058 - auc: 0.9415\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3052 - auc: 0.9420\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3039 - auc: 0.9422: 0s - loss: 0.3039 - auc: 0\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3045 - auc: 0.9423\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3045 - auc: 0.9421\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3030 - auc: 0.9426\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3062 - auc: 0.9424\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3052 - auc: 0.9419\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3027 - auc: 0.9428\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3061 - auc: 0.9422\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3041 - auc: 0.9421\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3048 - auc: 0.9422\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3042 - auc: 0.9421\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3052 - auc: 0.9423\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3031 - auc: 0.9430\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3031 - auc: 0.9430\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3035 - auc: 0.9428\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3030 - auc: 0.9428\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3000 - auc: 0.9438\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3038 - auc: 0.9426\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3050 - auc: 0.9427\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3038 - auc: 0.9428\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3046 - auc: 0.9432\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3042 - auc: 0.9432\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3042 - auc: 0.9433\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3013 - auc: 0.9434\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3023 - auc: 0.9429\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3017 - auc: 0.9435\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3026 - auc: 0.9432\n",
      "roc_auc estimado en fold 0 : 0.8360332421473019\n",
      "********** 1 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 5s 16ms/step - loss: 0.4054 - auc: 0.8986\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3412 - auc: 0.9273\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3281 - auc: 0.9323\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3256 - auc: 0.9330\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3227 - auc: 0.9343\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3192 - auc: 0.9356\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3205 - auc: 0.9356\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3195 - auc: 0.9356\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3168 - auc: 0.9363\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3158 - auc: 0.9373\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3147 - auc: 0.9374\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3124 - auc: 0.9383\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3147 - auc: 0.9377\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3152 - auc: 0.9378\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3142 - auc: 0.9377\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3122 - auc: 0.9384\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3093 - auc: 0.9397\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3108 - auc: 0.9393\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3117 - auc: 0.9389\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3110 - auc: 0.9392: 1s - los\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3099 - auc: 0.9396\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3104 - auc: 0.9392\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3120 - auc: 0.9387\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3113 - auc: 0.9388\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3092 - auc: 0.9396\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3084 - auc: 0.9402\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3095 - auc: 0.9395\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3092 - auc: 0.9401\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3097 - auc: 0.9403\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.3073 - auc: 0.9406\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3069 - auc: 0.9407\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3089 - auc: 0.9402\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 5s 18ms/step - loss: 0.3073 - auc: 0.9406\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3075 - auc: 0.9410\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.3068 - auc: 0.9411: 5s - los - ETA: 2s - loss: 0.30\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 5s 18ms/step - loss: 0.3104 - auc: 0.9406\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3082 - auc: 0.9402\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3067 - auc: 0.9410\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 5s 18ms/step - loss: 0.3049 - auc: 0.9414\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.3072 - auc: 0.9407\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3058 - auc: 0.9414\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.3088 - auc: 0.9403\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 5s 17ms/step - loss: 0.3060 - auc: 0.9414\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3069 - auc: 0.9409\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3068 - auc: 0.9412\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 5s 19ms/step - loss: 0.3057 - auc: 0.9413\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - ETA: 0s - loss: 0.3041 - auc: 0.942 - 3s 10ms/step - loss: 0.3042 - auc: 0.9420\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.3062 - auc: 0.9413\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 9ms/step - loss: 0.3049 - auc: 0.9417\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3059 - auc: 0.9414\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 10ms/step - loss: 0.3050 - auc: 0.9416\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3048 - auc: 0.9419\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3038 - auc: 0.9423\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3038 - auc: 0.9422\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3030 - auc: 0.9424\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3029 - auc: 0.9424\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3083 - auc: 0.9414\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3066 - auc: 0.9413\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3050 - auc: 0.9432\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3061 - auc: 0.9415\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3052 - auc: 0.9422\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3029 - auc: 0.9425\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3043 - auc: 0.9427\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3039 - auc: 0.9426\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3038 - auc: 0.9427\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3069 - auc: 0.9413\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3056 - auc: 0.9423\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3034 - auc: 0.9427\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3024 - auc: 0.9428\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3031 - auc: 0.9430\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3047 - auc: 0.9422\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3017 - auc: 0.9429\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3038 - auc: 0.9426\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3042 - auc: 0.9422\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3025 - auc: 0.9426\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3036 - auc: 0.9425\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3033 - auc: 0.9426\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3033 - auc: 0.9424\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3011 - auc: 0.9431\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3033 - auc: 0.9434\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3009 - auc: 0.9435\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3034 - auc: 0.9425\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3012 - auc: 0.9433\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.2999 - auc: 0.9436\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3022 - auc: 0.9432\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3006 - auc: 0.9433\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3021 - auc: 0.9435\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3019 - auc: 0.9433\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3015 - auc: 0.9431\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3027 - auc: 0.9431\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3011 - auc: 0.9432\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3011 - auc: 0.9436\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3025 - auc: 0.9432\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3006 - auc: 0.9441\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3006 - auc: 0.9440\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3000 - auc: 0.9439\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3006 - auc: 0.9438\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3017 - auc: 0.9430\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3010 - auc: 0.9432\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3027 - auc: 0.9429\n",
      "roc_auc estimado en fold 1 : 0.8381936279311161\n",
      "********** 2 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.4027 - auc: 0.9001\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3382 - auc: 0.9287\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3290 - auc: 0.9318\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3265 - auc: 0.9328\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3242 - auc: 0.9339\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3204 - auc: 0.9351\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3211 - auc: 0.9348\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3165 - auc: 0.9367\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3183 - auc: 0.9360\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3188 - auc: 0.9358\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3152 - auc: 0.9374\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3134 - auc: 0.9378\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3154 - auc: 0.9373\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3166 - auc: 0.9368\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3154 - auc: 0.9374\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3152 - auc: 0.9379\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3151 - auc: 0.9376\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3130 - auc: 0.9385\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3143 - auc: 0.9381\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3116 - auc: 0.9392\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3150 - auc: 0.9376\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3112 - auc: 0.9390\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3116 - auc: 0.9389\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3114 - auc: 0.9392\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3148 - auc: 0.9382\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3111 - auc: 0.9390\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3097 - auc: 0.9397\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3097 - auc: 0.9396\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3103 - auc: 0.9397\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3097 - auc: 0.9396\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3079 - auc: 0.9404\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3087 - auc: 0.9403\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3091 - auc: 0.9402\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3070 - auc: 0.9408\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3081 - auc: 0.9405\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3072 - auc: 0.9405\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3089 - auc: 0.9402\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3083 - auc: 0.9403\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3085 - auc: 0.9405\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3055 - auc: 0.9414\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3066 - auc: 0.9412\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3080 - auc: 0.9406\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3077 - auc: 0.9409\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3069 - auc: 0.9414\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3108 - auc: 0.9406\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3049 - auc: 0.9416\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3074 - auc: 0.9407\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3057 - auc: 0.9413\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3045 - auc: 0.9418\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3117 - auc: 0.9413\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3023 - auc: 0.9426\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3071 - auc: 0.9412\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3072 - auc: 0.9413\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3049 - auc: 0.9417\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3082 - auc: 0.9412\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3042 - auc: 0.9420\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3041 - auc: 0.9421\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3059 - auc: 0.9413\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3066 - auc: 0.9417\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3056 - auc: 0.9419\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3061 - auc: 0.9413\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3070 - auc: 0.9413\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3036 - auc: 0.9424\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3042 - auc: 0.9420\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3045 - auc: 0.9419\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3038 - auc: 0.9423\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3056 - auc: 0.9418\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3058 - auc: 0.9417\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3057 - auc: 0.9416\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3062 - auc: 0.9414\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3062 - auc: 0.9415\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3049 - auc: 0.9420\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3040 - auc: 0.9424\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3032 - auc: 0.9429\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3060 - auc: 0.9412\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3050 - auc: 0.9426\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3025 - auc: 0.9426\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3033 - auc: 0.9424\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3040 - auc: 0.9422\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3027 - auc: 0.9427\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3054 - auc: 0.9418\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3032 - auc: 0.9431\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3019 - auc: 0.9426\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3070 - auc: 0.9421\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3042 - auc: 0.9422\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3061 - auc: 0.9421\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3019 - auc: 0.9430\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3051 - auc: 0.9420\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3031 - auc: 0.9424\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3040 - auc: 0.9424\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3026 - auc: 0.9430\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3016 - auc: 0.9433\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3009 - auc: 0.9434\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3034 - auc: 0.9425\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3039 - auc: 0.9425\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3042 - auc: 0.9423\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3038 - auc: 0.9427\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3023 - auc: 0.9430\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3034 - auc: 0.9427\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3060 - auc: 0.9425\n",
      "roc_auc estimado en fold 2 : 0.8405311702509702\n",
      "********** 3 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3994 - auc: 0.9019\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3372 - auc: 0.9289\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3312 - auc: 0.9311\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3228 - auc: 0.9344\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3230 - auc: 0.9341\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3209 - auc: 0.9349\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3186 - auc: 0.9358\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3189 - auc: 0.9360\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3171 - auc: 0.9363\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3165 - auc: 0.9366\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3156 - auc: 0.9372\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3159 - auc: 0.9372\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3141 - auc: 0.9377\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3149 - auc: 0.9375\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3159 - auc: 0.9372\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3140 - auc: 0.9379\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3137 - auc: 0.9383\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3115 - auc: 0.9387\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3141 - auc: 0.9380\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3111 - auc: 0.9393\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3112 - auc: 0.9389\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3098 - auc: 0.9396\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3140 - auc: 0.9385\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3110 - auc: 0.9393\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3107 - auc: 0.9392\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3085 - auc: 0.9401\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3098 - auc: 0.9397\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3084 - auc: 0.9402\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3103 - auc: 0.9398\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3088 - auc: 0.9400\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3080 - auc: 0.9406\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3078 - auc: 0.9405\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3083 - auc: 0.9404\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3076 - auc: 0.9405\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3083 - auc: 0.9406\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3073 - auc: 0.9407\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3096 - auc: 0.9402\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3096 - auc: 0.9404\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3058 - auc: 0.9415\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3058 - auc: 0.9412\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3058 - auc: 0.9413\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3051 - auc: 0.9414\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3068 - auc: 0.9412\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3090 - auc: 0.9404\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3074 - auc: 0.9406\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3061 - auc: 0.9413\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3060 - auc: 0.9413\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 3s 11ms/step - loss: 0.3084 - auc: 0.9410\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3070 - auc: 0.9419\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3048 - auc: 0.9420\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3055 - auc: 0.9413\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3052 - auc: 0.9418\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3059 - auc: 0.9414\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3073 - auc: 0.9411\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3040 - auc: 0.9421\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3054 - auc: 0.9415\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.3079 - auc: 0.9412\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3044 - auc: 0.9420\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3057 - auc: 0.9420\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3036 - auc: 0.9422\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3015 - auc: 0.9430\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3063 - auc: 0.9416\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3055 - auc: 0.9416\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3055 - auc: 0.9418\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3020 - auc: 0.9429\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3028 - auc: 0.9426\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3029 - auc: 0.9426\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3032 - auc: 0.9424\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3033 - auc: 0.9427\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3033 - auc: 0.9422\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3046 - auc: 0.9421\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3043 - auc: 0.9421\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3062 - auc: 0.9417\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3034 - auc: 0.9424\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 4s 16ms/step - loss: 0.3045 - auc: 0.9421\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3031 - auc: 0.9427\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3036 - auc: 0.9424\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3039 - auc: 0.9425\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3021 - auc: 0.9432\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3040 - auc: 0.9421\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3043 - auc: 0.9425\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3006 - auc: 0.9434\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3033 - auc: 0.9426\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3042 - auc: 0.9424\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3007 - auc: 0.9434\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3060 - auc: 0.9418\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3036 - auc: 0.9425\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3025 - auc: 0.9430: 0s - loss: 0.3024 - auc: 0.9\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 5s 16ms/step - loss: 0.3022 - auc: 0.9431\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3011 - auc: 0.9435\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3048 - auc: 0.9425\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3027 - auc: 0.9430\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3016 - auc: 0.9436\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3014 - auc: 0.9434\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3026 - auc: 0.9429\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.2989 - auc: 0.9441\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3045 - auc: 0.9427\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3021 - auc: 0.9429\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3013 - auc: 0.9433\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3017 - auc: 0.9433\n",
      "roc_auc estimado en fold 3 : 0.8374331205695641\n",
      "********** 4 **********\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 5s 14ms/step - loss: 0.4105 - auc: 0.8947\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3363 - auc: 0.9293\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3282 - auc: 0.9328\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3270 - auc: 0.9334\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3197 - auc: 0.9353\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3211 - auc: 0.9354\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3174 - auc: 0.9362\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3189 - auc: 0.9368\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3161 - auc: 0.9375\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3159 - auc: 0.9372\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3134 - auc: 0.9382\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3110 - auc: 0.9389\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3158 - auc: 0.9374\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3141 - auc: 0.9379\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3133 - auc: 0.9381\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3114 - auc: 0.9390\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3114 - auc: 0.9389\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3120 - auc: 0.9386\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3121 - auc: 0.9390\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3109 - auc: 0.9392\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3110 - auc: 0.9393\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3092 - auc: 0.9399\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3109 - auc: 0.9392\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3076 - auc: 0.9406\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3077 - auc: 0.9407\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3087 - auc: 0.9401\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3104 - auc: 0.9398\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3098 - auc: 0.9397\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3086 - auc: 0.9401\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3096 - auc: 0.9397\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3083 - auc: 0.9403\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3075 - auc: 0.9406\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3072 - auc: 0.9410\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3075 - auc: 0.9409\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3079 - auc: 0.9407\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3057 - auc: 0.9415\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3052 - auc: 0.9414\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3090 - auc: 0.9404\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3057 - auc: 0.9413\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3061 - auc: 0.9416\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3060 - auc: 0.9413\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3025 - auc: 0.9425\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3063 - auc: 0.9414\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3039 - auc: 0.9420\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3059 - auc: 0.9415\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3054 - auc: 0.9417\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3043 - auc: 0.9420\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3071 - auc: 0.9412\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3037 - auc: 0.9421\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3052 - auc: 0.9416\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3040 - auc: 0.9424\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3022 - auc: 0.9426\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3060 - auc: 0.9415\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3040 - auc: 0.9421\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3029 - auc: 0.9425\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3032 - auc: 0.9424\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3056 - auc: 0.9420\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3014 - auc: 0.9432\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3037 - auc: 0.9424\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3044 - auc: 0.9424\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3041 - auc: 0.9421\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3026 - auc: 0.9425\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3027 - auc: 0.9429\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3028 - auc: 0.9428\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3018 - auc: 0.9430\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3036 - auc: 0.9427\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3024 - auc: 0.9433\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3038 - auc: 0.9425\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3045 - auc: 0.9422\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3018 - auc: 0.9430\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3032 - auc: 0.9425\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3044 - auc: 0.9423\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3022 - auc: 0.9429\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3031 - auc: 0.9426\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3007 - auc: 0.9435\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3019 - auc: 0.9435\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3004 - auc: 0.9440\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3004 - auc: 0.9434\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3016 - auc: 0.9430\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3036 - auc: 0.9425\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3057 - auc: 0.9423\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3018 - auc: 0.9430\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3000 - auc: 0.9439\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3028 - auc: 0.9428\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3006 - auc: 0.9438\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3018 - auc: 0.9436\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.3007 - auc: 0.9435\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3012 - auc: 0.9434\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3024 - auc: 0.9433\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 4s 15ms/step - loss: 0.3001 - auc: 0.9439\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3019 - auc: 0.9430\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3022 - auc: 0.9433\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.2998 - auc: 0.9438\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.2998 - auc: 0.9439\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3004 - auc: 0.9439\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 3s 12ms/step - loss: 0.3022 - auc: 0.9437\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.2995 - auc: 0.9442\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 3s 12ms/step - loss: 0.2979 - auc: 0.9448\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 4s 12ms/step - loss: 0.2996 - auc: 0.9443\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.3009 - auc: 0.9436\n",
      "roc_auc estimado en fold 4 : 0.8303349442370902\n",
      "*********************\n",
      "roc auc estimado:  0.8345968107570514\n",
      "roc auc varianza:  0.0011019752674203027\n"
     ]
    }
   ],
   "source": [
    "# https://keras.rstudio.com/reference/fit.html\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index]\n",
    "    yt = get_one_hot(yt)\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index]\n",
    "    yv = get_one_hot(yv)\n",
    "    \n",
    "    learner = get_model_keras(yv)\n",
    "    \n",
    "    num_epochs = 100\n",
    "    num_batch_size = 1024\n",
    "#     num_steps_per_epoch = len(Xt)//batch_size      steps_per_epoch = num_steps_per_epoch\n",
    "    num_validation_steps = 10\n",
    "    learner.fit(Xt, yt ,epochs=num_epochs, batch_size=num_batch_size, \n",
    "                        validation_steps=num_validation_steps)    \n",
    "    \n",
    "    test_probs.append(pd.Series(learner.predict(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    print(f'roc_auc estimado en fold {i} : {roc_auc_score(yv[:,-1],learner.predict(Xv)[:,-1])}')\n",
    "#     fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "# fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "########     num_batch_size = 512   \n",
    "###  num_epochs = 7   0.818\n",
    "###  num_epochs = 15  0.82300\n",
    "###  num_epochs = 30  0.82598\n",
    "###  num_epochs = 50  0.82720 , num_batch_size = 1028 \n",
    "###  num_epochs = 50   0.829800 , num_batch_size = 1028 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "speaking-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_rnn = train_probs\n",
    "test_probs_rnn = test_probs\n",
    "train_probs_rnn.to_pickle('train_probs_rnn.pkl')\n",
    "test_probs_rnn.to_pickle('test_probs_rnn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-poison",
   "metadata": {},
   "source": [
    "## Entrenando GradientBosstingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dependent-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1072), (396666, 1072))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_1072features_score_0.85381.pkl') \n",
    "test = pd.read_pickle('../data/test_1072features_score_0.85381.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "italian-spelling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 722), (396666, 722))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### eliminar variable cuyo porcentaje de valores nulos es mayor al 90%\n",
    "aux = train.isna().sum()/len(train)\n",
    "drop_columns = list(aux[aux>=0.9].index)\n",
    "train.drop(drop_columns, axis=1, inplace=True)\n",
    "test.drop(drop_columns, axis=1, inplace=True)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "environmental-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "659"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_missing_values = list(train.isna().sum()[train.isna().sum()>0].index)\n",
    "len(var_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "informed-saturday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 101, 95, 85, 103, 98, 79, 73)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_mode =[i for i in var_missing_values if \"mode\" in i]\n",
    "var_std =[i for i in var_missing_values if \"Std\" in i or \"std\" in i]\n",
    "var_unique =[i for i in var_missing_values if \"Unique\" in i or \"unique\" in i ]\n",
    "var_mean =[i for i in var_missing_values if \"Mean\" in i or \"mean\" in i]\n",
    "var_median =[i for i in var_missing_values if \"Median\" in i or \"median\" in i]\n",
    "var_sum =[i for i in var_missing_values if \"Sum\" in i or \"sum\" in i]\n",
    "var_max =[i for i in var_missing_values if \"Max\" in i or \"max\" in i]\n",
    "var_min =[i for i in var_missing_values if \"Min\" in i or \"min\" in i]\n",
    "len(var_mode), len(var_std), len(var_unique), len(var_mean), len(var_median), len(var_sum),len(var_max), len(var_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prescription-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(645, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_total = var_mode+var_std+var_unique+var_mean+var_median+var_sum+var_max+var_min\n",
    "var_rest = list(set(var_missing_values).difference(var_total))\n",
    "len(set(var_total)), len(set(var_rest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-cargo",
   "metadata": {},
   "source": [
    "#### imputacion tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "instant-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in var_mode:\n",
    "    train[i] = train[i].fillna(train[i].value_counts().index[0])\n",
    "    test[i] = test[i].fillna(train[i].value_counts().index[0])\n",
    "for i in var_std:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_unique:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_mean:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_median:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_sum:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_max:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_min:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   \n",
    "for i in var_rest:\n",
    "    train[i] = train[i].fillna(train[i].median())   \n",
    "    test[i] = test[i].fillna(train[i].median())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "hollywood-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train)\n",
    "train_scaled = scaler.transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "arbitrary-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_scaled, index=train.index, columns=train.columns)\n",
    "test = pd.DataFrame(test_scaled, index=test.index, columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "modular-feedback",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** 0 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7815           0.0915          278.93m\n",
      "         2           0.7452           0.0350          272.83m\n",
      "         3           0.7239           0.0209          278.99m\n",
      "         4           0.7068           0.0132          284.68m\n",
      "         5           0.6972           0.0129          285.99m\n",
      "         6           0.6839           0.0107          282.11m\n",
      "         7           0.6758           0.0063          278.90m\n",
      "         8           0.6695           0.0043          277.24m\n",
      "         9           0.6643           0.0058          274.54m\n",
      "        10           0.6571           0.0051          275.34m\n",
      "        20           0.6294           0.0008          271.47m\n",
      "********** 1 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7829           0.0869          243.62m\n",
      "         2           0.7470           0.0367          241.60m\n",
      "         3           0.7212           0.0209          239.88m\n",
      "         4           0.7057           0.0160          239.24m\n",
      "         5           0.6973           0.0121          238.84m\n",
      "         6           0.6870           0.0072          238.58m\n",
      "         7           0.6749           0.0071          239.80m\n",
      "         8           0.6695           0.0069          239.98m\n",
      "         9           0.6641           0.0038          240.91m\n",
      "        10           0.6631           0.0026          243.35m\n",
      "        20           0.6308           0.0010          245.55m\n",
      "********** 2 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7756           0.0927          296.61m\n",
      "         2           0.7466           0.0321          294.32m\n",
      "         3           0.7264           0.0198          282.29m\n",
      "         4           0.7061           0.0156          278.53m\n",
      "         5           0.6956           0.0122          274.09m\n",
      "         6           0.6842           0.0089          272.27m\n",
      "         7           0.6752           0.0074          272.12m\n",
      "         8           0.6699           0.0065          271.04m\n",
      "         9           0.6640           0.0052          270.10m\n",
      "        10           0.6611           0.0030          269.82m\n",
      "        20           0.6314           0.0005          251.58m\n",
      "********** 3 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7757           0.0926          259.77m\n",
      "         2           0.7442           0.0326          250.36m\n",
      "         3           0.7227           0.0194          246.69m\n",
      "         4           0.7054           0.0142          247.33m\n",
      "         5           0.6956           0.0116          253.07m\n",
      "         6           0.6838           0.0077          252.33m\n",
      "         7           0.6776           0.0063          252.63m\n",
      "         8           0.6694           0.0062          250.43m\n",
      "         9           0.6658           0.0051          248.78m\n",
      "        10           0.6620           0.0030          249.98m\n",
      "        20           0.6306           0.0007          259.14m\n",
      "********** 4 **********\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.7765           0.0967          281.01m\n",
      "         2           0.7439           0.0333          271.62m\n",
      "         3           0.7241           0.0208          268.09m\n",
      "         4           0.7074           0.0141          266.66m\n",
      "         5           0.6970           0.0106          264.30m\n",
      "         6           0.6864           0.0105          262.66m\n",
      "         7           0.6763           0.0074          260.52m\n",
      "         8           0.6698           0.0052          259.02m\n",
      "         9           0.6637           0.0035          258.72m\n",
      "        10           0.6573           0.0044          257.60m\n",
      "        20           0.6302           0.0020          261.55m\n",
      "*********************\n",
      "roc auc estimado:  0.8229558030026232\n",
      "roc auc varianza:  0.000867757340876575\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.fit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "folds = [train.index[t] for t, v in KFold(5).split(train)]\n",
    "test_probs = []\n",
    "train_probs = []\n",
    "fi = []\n",
    "for i, idx in enumerate(folds):\n",
    "    print(\"*\"*10, i, \"*\"*10)\n",
    "    Xt = train.loc[idx]\n",
    "    yt = y_train.loc[Xt.index].target\n",
    "\n",
    "    Xv = train.drop(Xt.index)\n",
    "    yv = y_train.loc[Xv.index].target\n",
    "\n",
    "    learner = GradientBoostingClassifier(n_estimators=500, learning_rate=0.3, subsample=0.8,\n",
    "                                         max_depth=5, verbose=1, max_features=0.82, random_state=407,\n",
    "                                         n_iter_no_change = 10, tol=0.01, validation_fraction = 0.2)\n",
    "   \n",
    "    learner.fit(Xt, yt)        \n",
    "    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n",
    "    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n",
    "    fi.append(pd.Series(learner.feature_importances_ / learner.feature_importances_.sum(), index=Xt.columns))\n",
    "\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n",
    "train_probs = pd.concat(train_probs)\n",
    "fi = pd.concat(fi, axis=1).mean(axis=1)\n",
    "print(\"*\" * 21)\n",
    "print(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))\n",
    "print(\"roc auc varianza: \", np.std([roc_auc_score(y_train.loc[folds[i]], train_probs.iloc[folds[i]]) for i in range(len(folds))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "right-learning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRODUCTO_6_saldoMax_ult1meses                        0.110742\n",
       "PRODUCTO_6_saldoStd_ult1meses                        0.086564\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult1meses     0.048600\n",
       "tipo_credito_11_saldoMean_ult1meses                  0.029850\n",
       "RIESGO_DIRECTO_1_saldoSum_ult1meses                  0.028807\n",
       "tipo_credito_12_saldoSum_ult1meses                   0.026034\n",
       "PRODUCTO_6_saldoMean_ult1meses                       0.022871\n",
       "PRODUCTO_2_saldoSum_ult1meses                        0.020884\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult4meses              0.020172\n",
       "RIESGO_DIRECTO_1_saldoMean_ult1meses                 0.017078\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult2meses     0.016885\n",
       "cod_instit_financiera_32_saldoUnique_ult1meses       0.015936\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoSum_ult7meses        0.013079\n",
       "tipo_credito_12_saldoMin_ult1meses                   0.011971\n",
       "RIESGO_DIRECTO_1_saldoMax_ult12meses                 0.011764\n",
       "PRODUCTO_3_saldoMean_ult1meses                       0.011302\n",
       "tipo_credito_11_saldoMean_ult3meses                  0.011149\n",
       "RIESGO_DIRECTO_1_saldoMean_ult2meses                 0.010793\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult1meses              0.009875\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult3meses              0.009506\n",
       "tipo_credito_12_saldoStd_ult2meses                   0.009391\n",
       "cod_instit_financiera_55_saldoUnique_ult1meses       0.009063\n",
       "RIESGO_DIRECTO_1_saldoUnique_ult1meses               0.009057\n",
       "PRODUCTO_6_saldoMin_ult1meses                        0.008944\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMedian_ult7meses     0.008764\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult12meses    0.008534\n",
       "RIESGO_DIRECTO_-1_saldoSum_ult1meses                 0.007979\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult1meses              0.007655\n",
       "tipo_credito_12_saldoStd_ult3meses                   0.007641\n",
       "condicion_1_saldoMax_ult6meses                       0.006992\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoUnique_ult7meses     0.006897\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoMean_ult1meses       0.006800\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult2meses              0.006726\n",
       "PRODUCTO_7_saldoMax_ult1meses                        0.006456\n",
       "RIESGO_DIRECTO_-1_saldoMedian_ult2meses              0.006393\n",
       "PRODUCTO_15_saldoStd_ult1meses                       0.006299\n",
       "condicion_1_saldoMin_ult6meses                       0.006268\n",
       "condicion_0_saldoUnique_ult12meses                   0.006128\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoMax_ult1meses        0.006126\n",
       "PRODUCTO_7_saldoUnique_ult1meses                     0.005979\n",
       "RIESGO_DIRECTO_1_saldoMedian_ult1meses               0.005660\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMin_ult9meses        0.005417\n",
       "PRODUCTO_8_saldoMin_ult1meses                        0.005339\n",
       "edad                                                 0.005257\n",
       "COD_CLASIFICACION_DEUDOR_1_saldoMin_ult10meses       0.005239\n",
       "tipo_credito_10_saldoUnique_ult4meses                0.005087\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoSum_ult1meses        0.005023\n",
       "COD_CLASIFICACION_DEUDOR_0_saldoUnique_ult3meses     0.004685\n",
       "cod_instit_financiera_55_saldoMax_ult1meses          0.004674\n",
       "RIESGO_DIRECTO_-1_saldoUnique_ult5meses              0.004628\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alert-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_pickle('fi_gbc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "signal-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probs_gbc = train_probs\n",
    "test_probs_gbc = test_probs\n",
    "train_probs_gbc.to_pickle('train_probs_gbc.pkl')\n",
    "test_probs_gbc.to_pickle('test_probs_gbc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eastern-cursor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    722\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-haiti",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-tsunami",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-berry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-values",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-blair",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-wilderness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "after-peoples",
   "metadata": {},
   "source": [
    "### Test ensamble CB and LGBM (Promedio Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "returning-drain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((358487, 1136), (396666, 1136))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_pickle('../data/train_score_0.84862.pkl') \n",
    "test = pd.read_pickle('../data/test_score_0.84862.pkl')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "alternative-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8187536048650496"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.read_pickle('fi_lightgbm.pkl')\n",
    "fi.sort_values(ascending=False).head(600).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "human-interface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=6,\n",
       "               min_child_samples=1000, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "fi = pd.read_pickle('fi_lightgbm.pkl')\n",
    "features_importances_250_lightgbm = list(fi.sort_values(ascending=False).head(600).index)\n",
    "learner_lightgbm = LGBMClassifier(n_estimators=1000, max_depth=6, boosting_type='gbdt', min_child_samples=1000)\n",
    "learner_lightgbm.fit(train[features_importances_250_lightgbm], y_train.target, eval_metric=\"auc\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "unsigned-african",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f3099e7910>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "fi = pd.read_pickle('fi_catboost_v2.pkl')\n",
    "features_importances_250_catboost = list(fi.sort_values(ascending=False).head(600).index)\n",
    "learner_catboost = CatBoostClassifier(n_estimators=1000, eval_metric = 'AUC', max_depth = 6)\n",
    "learner_catboost.fit(train[features_importances_250_catboost], y_train,  early_stopping_rounds=10, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "lesbian-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396666,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs_catboost = pd.Series(learner_catboost.predict_proba(test[features_importances_250_catboost])[:, -1], index=test.index, name=\"target\")\n",
    "test_probs_lightgbm = pd.Series(learner_lightgbm.predict_proba(test[features_importances_250_lightgbm])[:, -1], index=test.index, name=\"target\")\n",
    "test_probs_mean = test_probs_catboost*0.4 + test_probs_lightgbm*0.6\n",
    "test_probs_mean.name = 'target'\n",
    "test_probs_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "military-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_mean.to_csv(\"../results/test_simpleEnsamble_CB_LGBM.csv\") ## ### score de 0.84900 en la tabla publica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "geographic-chocolate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_value\n",
       "0         0.046411\n",
       "1         0.082767\n",
       "2         0.054280\n",
       "3         0.569868\n",
       "4         0.136302\n",
       "            ...   \n",
       "396661    0.070589\n",
       "396662    0.175882\n",
       "396663    0.200699\n",
       "396664    0.058848\n",
       "396665    0.069094\n",
       "Name: target, Length: 396666, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stacking = pd.read_csv(\"../results/stacking_3models_LGBM2_GBC_0.84805.csv\", index_col = 'key_value')\n",
    "test_stacking = pd.Series(test_stacking['target'], index=test_stacking.index)\n",
    "test_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "solar-hanging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_value\n",
       "0         0.024140\n",
       "1         0.079244\n",
       "2         0.039947\n",
       "3         0.446672\n",
       "4         0.169947\n",
       "            ...   \n",
       "396661    0.068474\n",
       "396662    0.201868\n",
       "396663    0.213891\n",
       "396664    0.049055\n",
       "396665    0.052579\n",
       "Name: target, Length: 396666, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs_mean_ = test_probs_mean*0.5 + test_stacking*0.5\n",
    "test_probs_mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "thirty-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_mean_.to_csv(\"../results/emsamble_simple_and_stacking.csv\") ## ### score de 0.85042 en la tabla publica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "mysterious-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_value\n",
       "0         0.028594\n",
       "1         0.079948\n",
       "2         0.042814\n",
       "3         0.471311\n",
       "4         0.163218\n",
       "            ...   \n",
       "396661    0.068897\n",
       "396662    0.196671\n",
       "396663    0.211253\n",
       "396664    0.051013\n",
       "396665    0.055882\n",
       "Name: target, Length: 396666, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_probs_mean_2 = test_probs_mean*0.4 + test_stacking*0.6\n",
    "test_probs_mean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "heavy-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_mean_2.to_csv(\"../results/emsamble_simple_and_stacking_v2.csv\") ## ### score de 0.85042 en la tabla publica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
